	.section	__TEXT,__text,regular,pure_instructions
	.macosx_version_min 10, 15
	.section	__TEXT,__literal16,16byte_literals
	.p2align	4               ## -- Begin function mobilenetv3_wrapper
LCPI0_0:
	.quad	112                     ## 0x70
	.quad	112                     ## 0x70
LCPI0_1:
	.quad	1                       ## 0x1
	.quad	16                      ## 0x10
LCPI0_2:
	.quad	224                     ## 0xe0
	.quad	224                     ## 0xe0
LCPI0_3:
	.quad	1                       ## 0x1
	.quad	3                       ## 0x3
LCPI0_4:
	.quad	3                       ## 0x3
	.quad	3                       ## 0x3
LCPI0_5:
	.quad	16                      ## 0x10
	.quad	3                       ## 0x3
LCPI0_6:
	.quad	4                       ## 0x4
	.quad	1                       ## 0x1
LCPI0_7:
	.quad	4                       ## 0x4
	.quad	4                       ## 0x4
LCPI0_8:
	.quad	1                       ## 0x1
	.quad	1                       ## 0x1
LCPI0_9:
	.quad	2                       ## 0x2
	.quad	2                       ## 0x2
LCPI0_10:
	.long	1077936128              ## float 3
	.long	1077936128              ## float 3
	.long	1077936128              ## float 3
	.long	1077936128              ## float 3
LCPI0_11:
	.long	1086324736              ## float 6
	.long	1086324736              ## float 6
	.long	1086324736              ## float 6
	.long	1086324736              ## float 6
LCPI0_12:
	.quad	16                      ## 0x10
	.quad	16                      ## 0x10
LCPI0_13:
	.quad	56                      ## 0x38
	.quad	56                      ## 0x38
LCPI0_14:
	.quad	16                      ## 0x10
	.quad	1                       ## 0x1
LCPI0_18:
	.quad	1                       ## 0x1
	.quad	72                      ## 0x48
LCPI0_19:
	.quad	72                      ## 0x48
	.quad	16                      ## 0x10
LCPI0_20:
	.quad	28                      ## 0x1c
	.quad	28                      ## 0x1c
LCPI0_21:
	.quad	72                      ## 0x48
	.quad	1                       ## 0x1
LCPI0_22:
	.quad	1                       ## 0x1
	.quad	24                      ## 0x18
LCPI0_23:
	.quad	24                      ## 0x18
	.quad	72                      ## 0x48
LCPI0_24:
	.quad	1                       ## 0x1
	.quad	88                      ## 0x58
LCPI0_25:
	.quad	88                      ## 0x58
	.quad	24                      ## 0x18
LCPI0_26:
	.quad	88                      ## 0x58
	.quad	1                       ## 0x1
LCPI0_27:
	.quad	24                      ## 0x18
	.quad	88                      ## 0x58
LCPI0_28:
	.quad	1                       ## 0x1
	.quad	96                      ## 0x60
LCPI0_29:
	.quad	96                      ## 0x60
	.quad	24                      ## 0x18
LCPI0_30:
	.quad	14                      ## 0xe
	.quad	14                      ## 0xe
LCPI0_31:
	.quad	5                       ## 0x5
	.quad	5                       ## 0x5
LCPI0_32:
	.quad	96                      ## 0x60
	.quad	1                       ## 0x1
LCPI0_33:
	.quad	1                       ## 0x1
	.quad	40                      ## 0x28
LCPI0_34:
	.quad	40                      ## 0x28
	.quad	96                      ## 0x60
LCPI0_35:
	.quad	1                       ## 0x1
	.quad	240                     ## 0xf0
LCPI0_36:
	.quad	240                     ## 0xf0
	.quad	40                      ## 0x28
LCPI0_37:
	.quad	240                     ## 0xf0
	.quad	1                       ## 0x1
LCPI0_38:
	.quad	1                       ## 0x1
	.quad	60                      ## 0x3c
LCPI0_39:
	.quad	240                     ## 0xf0
	.quad	60                      ## 0x3c
LCPI0_40:
	.quad	60                      ## 0x3c
	.quad	240                     ## 0xf0
LCPI0_41:
	.quad	40                      ## 0x28
	.quad	240                     ## 0xf0
LCPI0_42:
	.quad	1                       ## 0x1
	.quad	120                     ## 0x78
LCPI0_43:
	.quad	120                     ## 0x78
	.quad	40                      ## 0x28
LCPI0_44:
	.quad	120                     ## 0x78
	.quad	1                       ## 0x1
LCPI0_45:
	.quad	1                       ## 0x1
	.quad	30                      ## 0x1e
LCPI0_46:
	.quad	120                     ## 0x78
	.quad	30                      ## 0x1e
LCPI0_47:
	.quad	30                      ## 0x1e
	.quad	120                     ## 0x78
LCPI0_48:
	.quad	1                       ## 0x1
	.quad	48                      ## 0x30
LCPI0_49:
	.quad	48                      ## 0x30
	.quad	120                     ## 0x78
LCPI0_50:
	.quad	1                       ## 0x1
	.quad	144                     ## 0x90
LCPI0_51:
	.quad	144                     ## 0x90
	.quad	48                      ## 0x30
LCPI0_52:
	.quad	144                     ## 0x90
	.quad	1                       ## 0x1
LCPI0_53:
	.quad	1                       ## 0x1
	.quad	36                      ## 0x24
LCPI0_54:
	.quad	144                     ## 0x90
	.quad	36                      ## 0x24
LCPI0_55:
	.quad	36                      ## 0x24
	.quad	144                     ## 0x90
LCPI0_56:
	.quad	48                      ## 0x30
	.quad	144                     ## 0x90
LCPI0_57:
	.quad	1                       ## 0x1
	.quad	288                     ## 0x120
LCPI0_58:
	.quad	288                     ## 0x120
	.quad	48                      ## 0x30
LCPI0_59:
	.quad	7                       ## 0x7
	.quad	7                       ## 0x7
LCPI0_60:
	.quad	288                     ## 0x120
	.quad	1                       ## 0x1
LCPI0_61:
	.quad	288                     ## 0x120
	.quad	72                      ## 0x48
LCPI0_62:
	.quad	72                      ## 0x48
	.quad	288                     ## 0x120
LCPI0_63:
	.quad	96                      ## 0x60
	.quad	288                     ## 0x120
LCPI0_64:
	.quad	1                       ## 0x1
	.quad	576                     ## 0x240
LCPI0_65:
	.quad	576                     ## 0x240
	.quad	96                      ## 0x60
LCPI0_66:
	.quad	576                     ## 0x240
	.quad	1                       ## 0x1
LCPI0_67:
	.quad	576                     ## 0x240
	.quad	144                     ## 0x90
LCPI0_68:
	.quad	144                     ## 0x90
	.quad	576                     ## 0x240
LCPI0_69:
	.quad	96                      ## 0x60
	.quad	576                     ## 0x240
LCPI0_70:
	.quad	1                       ## 0x1
	.quad	1280                    ## 0x500
LCPI0_71:
	.quad	1280                    ## 0x500
	.quad	576                     ## 0x240
LCPI0_72:
	.quad	3                       ## 0x3
	.quad	4                       ## 0x4
LCPI0_73:
	.quad	1280                    ## 0x500
	.quad	1                       ## 0x1
LCPI0_74:
	.quad	2                       ## 0x2
	.quad	3                       ## 0x3
LCPI0_75:
	.quad	1000                    ## 0x3e8
	.quad	1                       ## 0x1
LCPI0_76:
	.quad	1                       ## 0x1
	.quad	1000                    ## 0x3e8
LCPI0_77:
	.quad	2                       ## 0x2
	.quad	1                       ## 0x1
LCPI0_78:
	.quad	1280                    ## 0x500
	.quad	1280                    ## 0x500
LCPI0_79:
	.space	16
	.section	__TEXT,__literal4,4byte_literals
	.p2align	2
LCPI0_15:
	.long	1077936128              ## float 3
LCPI0_16:
	.long	1086324736              ## float 6
LCPI0_17:
	.long	1065353216              ## float 1
	.section	__TEXT,__text,regular,pure_instructions
	.globl	_mobilenetv3_wrapper
	.p2align	4, 0x90
_mobilenetv3_wrapper:                   ## @mobilenetv3_wrapper
## %bb.0:                               ## %wrapBB
	pushq	%rbp
	movq	%rsp, %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$1984, %rsp             ## imm = 0x7C0
	movq	%rsp, %rbx
	movq	(%rdi), %rax
	movq	8(%rdi), %rcx
	movq	%rcx, 1152(%rbx)        ## 8-byte Spill
	movq	16(%rdi), %rcx
	movq	%rcx, 1160(%rbx)        ## 8-byte Spill
	movq	24(%rdi), %rcx
	movq	%rcx, 1056(%rbx)        ## 8-byte Spill
	movq	32(%rdi), %rcx
	movq	%rcx, 1032(%rbx)        ## 8-byte Spill
	movq	40(%rdi), %rcx
	movq	%rcx, 968(%rbx)         ## 8-byte Spill
	movq	48(%rdi), %rcx
	movq	%rcx, 928(%rbx)         ## 8-byte Spill
	movq	56(%rdi), %rcx
	movq	%rcx, 888(%rbx)         ## 8-byte Spill
	movq	64(%rdi), %rcx
	movq	%rcx, 864(%rbx)         ## 8-byte Spill
	movq	72(%rdi), %rcx
	movq	%rcx, 816(%rbx)         ## 8-byte Spill
	movq	80(%rdi), %rcx
	movq	%rcx, 808(%rbx)         ## 8-byte Spill
	movdqu	176(%rdi), %xmm0
	movups	192(%rdi), %xmm1
	movups	208(%rdi), %xmm2
	movaps	%xmm2, 1168(%rbx)       ## 16-byte Spill
	movups	224(%rdi), %xmm2
	movaps	%xmm2, 1184(%rbx)       ## 16-byte Spill
	movups	240(%rdi), %xmm2
	movaps	%xmm2, 1200(%rbx)       ## 16-byte Spill
	movups	256(%rdi), %xmm2
	movaps	%xmm2, 1216(%rbx)       ## 16-byte Spill
	movups	272(%rdi), %xmm2
	movaps	%xmm2, 1232(%rbx)       ## 16-byte Spill
	movups	288(%rdi), %xmm2
	movaps	%xmm2, 1248(%rbx)       ## 16-byte Spill
	movups	304(%rdi), %xmm2
	movaps	%xmm2, 1264(%rbx)       ## 16-byte Spill
	movups	320(%rdi), %xmm2
	movaps	%xmm2, 1280(%rbx)       ## 16-byte Spill
	movups	336(%rdi), %xmm2
	movaps	%xmm2, 1296(%rbx)       ## 16-byte Spill
	movups	352(%rdi), %xmm2
	movaps	%xmm2, 1312(%rbx)       ## 16-byte Spill
	movups	368(%rdi), %xmm2
	movaps	%xmm2, 1328(%rbx)       ## 16-byte Spill
	movups	384(%rdi), %xmm2
	movaps	%xmm2, 1344(%rbx)       ## 16-byte Spill
	movups	400(%rdi), %xmm2
	movaps	%xmm2, 1360(%rbx)       ## 16-byte Spill
	movups	416(%rdi), %xmm2
	movaps	%xmm2, 1376(%rbx)       ## 16-byte Spill
	movq	88(%rdi), %rcx
	movq	%rcx, 776(%rbx)         ## 8-byte Spill
	movq	96(%rdi), %rcx
	movq	%rcx, 760(%rbx)         ## 8-byte Spill
	movq	104(%rdi), %rcx
	movq	%rcx, 728(%rbx)         ## 8-byte Spill
	movq	112(%rdi), %rcx
	movq	%rcx, 712(%rbx)         ## 8-byte Spill
	movq	120(%rdi), %rcx
	movq	%rcx, 688(%rbx)         ## 8-byte Spill
	movq	128(%rdi), %rcx
	movq	%rcx, 672(%rbx)         ## 8-byte Spill
	movq	136(%rdi), %rcx
	movq	%rcx, 640(%rbx)         ## 8-byte Spill
	movq	144(%rdi), %rcx
	movq	%rcx, 632(%rbx)         ## 8-byte Spill
	movq	152(%rdi), %rcx
	movq	%rcx, 576(%rbx)         ## 8-byte Spill
	movq	160(%rdi), %rcx
	movq	%rcx, 568(%rbx)         ## 8-byte Spill
	movq	168(%rdi), %rcx
	movq	%rcx, 1144(%rbx)        ## 8-byte Spill
	movq	752(%rdi), %rcx
	movq	%rcx, 312(%rbx)         ## 8-byte Spill
	movq	760(%rdi), %rcx
	movq	%rcx, 1040(%rbx)        ## 8-byte Spill
	movq	768(%rdi), %rcx
	movq	%rcx, 440(%rbx)         ## 8-byte Spill
	movq	776(%rdi), %rcx
	movq	%rcx, 64(%rbx)          ## 8-byte Spill
	movq	784(%rdi), %rcx
	movq	%rcx, 704(%rbx)         ## 8-byte Spill
	movq	792(%rdi), %r14
	movq	800(%rdi), %rcx
	movq	%rcx, 1080(%rbx)        ## 8-byte Spill
	movq	808(%rdi), %rcx
	movq	%rcx, 552(%rbx)         ## 8-byte Spill
	movq	816(%rdi), %rcx
	movq	%rcx, 560(%rbx)         ## 8-byte Spill
	movq	824(%rdi), %rcx
	movq	%rcx, 472(%rbx)         ## 8-byte Spill
	movq	832(%rdi), %rcx
	movq	%rcx, 344(%rbx)         ## 8-byte Spill
	movq	840(%rdi), %rcx
	movq	%rcx, 1096(%rbx)        ## 8-byte Spill
	movq	848(%rdi), %rcx
	movq	%rcx, 768(%rbx)         ## 8-byte Spill
	movq	856(%rdi), %rcx
	movq	%rcx, 1016(%rbx)        ## 8-byte Spill
	movq	864(%rdi), %rcx
	movq	%rcx, 584(%rbx)         ## 8-byte Spill
	movq	872(%rdi), %r15
	movq	880(%rdi), %rcx
	movq	%rcx, 1112(%rbx)        ## 8-byte Spill
	movq	888(%rdi), %rcx
	movq	%rcx, 416(%rbx)         ## 8-byte Spill
	movq	896(%rdi), %rcx
	movq	%rcx, 736(%rbx)         ## 8-byte Spill
	movq	904(%rdi), %rcx
	movq	%rcx, 1072(%rbx)        ## 8-byte Spill
	movq	912(%rdi), %rcx
	movq	%rcx, 752(%rbx)         ## 8-byte Spill
	movq	920(%rdi), %rcx
	movq	%rcx, 136(%rbx)         ## 8-byte Spill
	movq	928(%rdi), %rcx
	movq	%rcx, 1064(%rbx)        ## 8-byte Spill
	movq	936(%rdi), %rcx
	movq	%rcx, 320(%rbx)         ## 8-byte Spill
	movq	944(%rdi), %rcx
	movq	%rcx, 240(%rbx)         ## 8-byte Spill
	movq	952(%rdi), %rcx
	movq	%rcx, 272(%rbx)         ## 8-byte Spill
	movq	960(%rdi), %rcx
	movq	%rcx, 112(%rbx)         ## 8-byte Spill
	movq	968(%rdi), %rcx
	movq	%rcx, 368(%rbx)         ## 8-byte Spill
	movq	976(%rdi), %rcx
	movq	%rcx, 528(%rbx)         ## 8-byte Spill
	movq	984(%rdi), %rcx
	movq	%rcx, 32(%rbx)          ## 8-byte Spill
	movq	992(%rdi), %rcx
	movq	%rcx, 784(%rbx)         ## 8-byte Spill
	movq	1000(%rdi), %rcx
	movq	%rcx, 408(%rbx)         ## 8-byte Spill
	movq	1008(%rdi), %rcx
	movq	%rcx, 872(%rbx)         ## 8-byte Spill
	movq	1016(%rdi), %rcx
	movq	%rcx, 208(%rbx)         ## 8-byte Spill
	movq	1024(%rdi), %rcx
	movq	%rcx, 352(%rbx)         ## 8-byte Spill
	movq	1032(%rdi), %rcx
	movq	%rcx, 904(%rbx)         ## 8-byte Spill
	movq	1040(%rdi), %rcx
	movq	%rcx, 80(%rbx)          ## 8-byte Spill
	movq	1048(%rdi), %rcx
	movq	%rcx, 224(%rbx)         ## 8-byte Spill
	movq	1056(%rdi), %rcx
	movq	%rcx, 840(%rbx)         ## 8-byte Spill
	movq	1064(%rdi), %rcx
	movq	%rcx, 128(%rbx)         ## 8-byte Spill
	movq	1072(%rdi), %rcx
	movq	%rcx, 96(%rbx)          ## 8-byte Spill
	movq	1080(%rdi), %rcx
	movq	%rcx, 448(%rbx)         ## 8-byte Spill
	movq	1088(%rdi), %rcx
	movq	%rcx, 616(%rbx)         ## 8-byte Spill
	movq	1096(%rdi), %rcx
	movq	%rcx, 624(%rbx)         ## 8-byte Spill
	movq	1104(%rdi), %rcx
	movq	%rcx, 656(%rbx)         ## 8-byte Spill
	movq	1112(%rdi), %rcx
	movq	%rcx, 176(%rbx)         ## 8-byte Spill
	movq	1120(%rdi), %rcx
	movq	%rcx, 304(%rbx)         ## 8-byte Spill
	movq	1128(%rdi), %rcx
	movq	%rcx, 680(%rbx)         ## 8-byte Spill
	movq	1136(%rdi), %rcx
	movq	%rcx, 328(%rbx)         ## 8-byte Spill
	movq	1144(%rdi), %rcx
	movq	%rcx, 696(%rbx)         ## 8-byte Spill
	movq	1152(%rdi), %rcx
	movq	%rcx, 600(%rbx)         ## 8-byte Spill
	movq	1160(%rdi), %rcx
	movq	%rcx, 984(%rbx)         ## 8-byte Spill
	movq	1168(%rdi), %rcx
	movq	%rcx, 152(%rbx)         ## 8-byte Spill
	movq	1176(%rdi), %rcx
	movq	%rcx, 648(%rbx)         ## 8-byte Spill
	movq	1184(%rdi), %rcx
	movq	%rcx, 720(%rbx)         ## 8-byte Spill
	movq	1192(%rdi), %rcx
	movq	%rcx, 16(%rbx)          ## 8-byte Spill
	movq	1200(%rdi), %rcx
	movq	%rcx, 360(%rbx)         ## 8-byte Spill
	movq	1208(%rdi), %r12
	movq	1216(%rdi), %rcx
	movq	%rcx, 376(%rbx)         ## 8-byte Spill
	movq	1224(%rdi), %rcx
	movq	%rcx, 160(%rbx)         ## 8-byte Spill
	movq	1232(%rdi), %rcx
	movq	%rcx, 832(%rbx)         ## 8-byte Spill
	movq	1240(%rdi), %rcx
	movq	%rcx, 384(%rbx)         ## 8-byte Spill
	movq	1248(%rdi), %rcx
	movq	%rcx, 144(%rbx)         ## 8-byte Spill
	movq	1256(%rdi), %rcx
	movq	%rcx, 400(%rbx)         ## 8-byte Spill
	movq	1264(%rdi), %rcx
	movq	%rcx, 744(%rbx)         ## 8-byte Spill
	movq	1272(%rdi), %rcx
	movq	%rcx, 168(%rbx)         ## 8-byte Spill
	movq	1280(%rdi), %rcx
	movq	%rcx, 936(%rbx)         ## 8-byte Spill
	movq	1288(%rdi), %rcx
	movq	%rcx, 48(%rbx)          ## 8-byte Spill
	movq	1296(%rdi), %rcx
	movq	%rcx, 424(%rbx)         ## 8-byte Spill
	movq	1304(%rdi), %rcx
	movq	%rcx, 912(%rbx)         ## 8-byte Spill
	movq	1312(%rdi), %r13
	movq	1320(%rdi), %rcx
	movq	%rcx, 184(%rbx)         ## 8-byte Spill
	movq	1328(%rdi), %rcx
	movq	%rcx, 792(%rbx)         ## 8-byte Spill
	movq	1336(%rdi), %rcx
	movq	%rcx, 976(%rbx)         ## 8-byte Spill
	movq	1344(%rdi), %rcx
	movq	%rcx, 800(%rbx)         ## 8-byte Spill
	movq	1352(%rdi), %rcx
	movq	%rcx, 336(%rbx)         ## 8-byte Spill
	movq	1360(%rdi), %rcx
	movq	%rcx, 592(%rbx)         ## 8-byte Spill
	movq	1368(%rdi), %rcx
	movq	%rcx, 464(%rbx)         ## 8-byte Spill
	movq	1376(%rdi), %rcx
	movq	%rcx, 824(%rbx)         ## 8-byte Spill
	movq	1384(%rdi), %rcx
	movq	%rcx, 480(%rbx)         ## 8-byte Spill
	movq	1392(%rdi), %rcx
	movq	%rcx, 432(%rbx)         ## 8-byte Spill
	movq	1400(%rdi), %rcx
	movq	%rcx, 664(%rbx)         ## 8-byte Spill
	movq	1408(%rdi), %rcx
	movq	%rcx, 920(%rbx)         ## 8-byte Spill
	movq	1416(%rdi), %rcx
	movq	%rcx, 296(%rbx)         ## 8-byte Spill
	movq	1424(%rdi), %rcx
	movq	%rcx, 608(%rbx)         ## 8-byte Spill
	movq	1432(%rdi), %rcx
	movq	%rcx, 192(%rbx)         ## 8-byte Spill
	movq	1440(%rdi), %rcx
	movq	%rcx, 488(%rbx)         ## 8-byte Spill
	movq	1448(%rdi), %rcx
	movq	%rcx, 856(%rbx)         ## 8-byte Spill
	movq	1456(%rdi), %rcx
	movq	%rcx, 880(%rbx)         ## 8-byte Spill
	movq	1464(%rdi), %rcx
	movq	%rcx, 392(%rbx)         ## 8-byte Spill
	movq	1472(%rdi), %rcx
	movq	%rcx, 496(%rbx)         ## 8-byte Spill
	movq	1480(%rdi), %rcx
	movq	%rcx, 256(%rbx)         ## 8-byte Spill
	movq	1488(%rdi), %rcx
	movq	%rcx, 960(%rbx)         ## 8-byte Spill
	movq	1496(%rdi), %rcx
	movq	%rcx, 896(%rbx)         ## 8-byte Spill
	movq	1504(%rdi), %rcx
	movq	%rcx, 944(%rbx)         ## 8-byte Spill
	movq	1512(%rdi), %rcx
	movq	%rcx, 952(%rbx)         ## 8-byte Spill
	movq	1520(%rdi), %rcx
	movq	%rcx, 504(%rbx)         ## 8-byte Spill
	movq	1528(%rdi), %rcx
	movq	%rcx, 520(%rbx)         ## 8-byte Spill
	movq	1536(%rdi), %rcx
	movq	%rcx, 848(%rbx)         ## 8-byte Spill
	movq	1544(%rdi), %rcx
	movq	%rcx, 992(%rbx)         ## 8-byte Spill
	movq	1552(%rdi), %rcx
	movq	%rcx, 1000(%rbx)        ## 8-byte Spill
	movq	1560(%rdi), %rcx
	movq	%rcx, 456(%rbx)         ## 8-byte Spill
	movq	1568(%rdi), %rcx
	movq	%rcx, 1008(%rbx)        ## 8-byte Spill
	movq	1576(%rdi), %rcx
	movq	%rcx, 1024(%rbx)        ## 8-byte Spill
	movq	1584(%rdi), %rcx
	movq	%rcx, 1048(%rbx)        ## 8-byte Spill
	movq	1592(%rdi), %rcx
	movq	%rcx, 512(%rbx)         ## 8-byte Spill
	movq	1600(%rdi), %rcx
	movq	%rcx, 1088(%rbx)        ## 8-byte Spill
	movq	1608(%rdi), %rcx
	movq	%rcx, 1104(%rbx)        ## 8-byte Spill
	movq	1616(%rdi), %rcx
	movq	%rcx, 1120(%rbx)        ## 8-byte Spill
	movq	1624(%rdi), %rcx
	movq	%rcx, 1128(%rbx)        ## 8-byte Spill
	movq	1632(%rdi), %rcx
	movq	%rcx, 1136(%rbx)        ## 8-byte Spill
	movups	432(%rdi), %xmm2
	movaps	%xmm2, 1392(%rbx)       ## 16-byte Spill
	movups	448(%rdi), %xmm2
	movaps	%xmm2, 1408(%rbx)       ## 16-byte Spill
	movups	464(%rdi), %xmm2
	movaps	%xmm2, 1424(%rbx)       ## 16-byte Spill
	movups	480(%rdi), %xmm2
	movaps	%xmm2, 1440(%rbx)       ## 16-byte Spill
	movups	496(%rdi), %xmm2
	movaps	%xmm2, 1456(%rbx)       ## 16-byte Spill
	movups	512(%rdi), %xmm2
	movaps	%xmm2, 1472(%rbx)       ## 16-byte Spill
	movups	528(%rdi), %xmm2
	movaps	%xmm2, 1488(%rbx)       ## 16-byte Spill
	movups	544(%rdi), %xmm2
	movaps	%xmm2, 1504(%rbx)       ## 16-byte Spill
	movups	560(%rdi), %xmm2
	movaps	%xmm2, 1520(%rbx)       ## 16-byte Spill
	movups	576(%rdi), %xmm2
	movaps	%xmm2, 1536(%rbx)       ## 16-byte Spill
	movups	592(%rdi), %xmm2
	movaps	%xmm2, 1552(%rbx)       ## 16-byte Spill
	movups	608(%rdi), %xmm2
	movaps	%xmm2, 1568(%rbx)       ## 16-byte Spill
	movups	624(%rdi), %xmm2
	movaps	%xmm2, 1584(%rbx)       ## 16-byte Spill
	movups	640(%rdi), %xmm2
	movaps	%xmm2, 1600(%rbx)       ## 16-byte Spill
	movups	656(%rdi), %xmm2
	movaps	%xmm2, 1616(%rbx)       ## 16-byte Spill
	movups	672(%rdi), %xmm2
	movaps	%xmm2, 1632(%rbx)       ## 16-byte Spill
	movups	688(%rdi), %xmm2
	movaps	%xmm2, 1648(%rbx)       ## 16-byte Spill
	movups	704(%rdi), %xmm2
	movaps	%xmm2, 1664(%rbx)       ## 16-byte Spill
	movups	720(%rdi), %xmm2
	movaps	%xmm2, 1680(%rbx)       ## 16-byte Spill
	movups	736(%rdi), %xmm2
	movaps	%xmm2, 1696(%rbx)       ## 16-byte Spill
	movaps	LCPI0_0(%rip), %xmm2    ## xmm2 = [112,112]
	movups	%xmm2, 1864(%rbx)
	movaps	LCPI0_1(%rip), %xmm2    ## xmm2 = [1,16]
	movups	%xmm2, 1848(%rbx)
	movaps	LCPI0_2(%rip), %xmm2    ## xmm2 = [224,224]
	movups	%xmm2, 1896(%rbx)
	movaps	LCPI0_3(%rip), %xmm2    ## xmm2 = [1,3]
	movups	%xmm2, 1880(%rbx)
	movaps	LCPI0_5(%rip), %xmm2    ## xmm2 = [16,3]
	movups	%xmm2, 1912(%rbx)
	movq	%r15, 1728(%rbx)
	movq	%rax, 1736(%rbx)
	movups	%xmm1, 1744(%rbx)
	pshufd	$78, %xmm0, %xmm0       ## xmm0 = xmm0[2,3,0,1]
	movdqa	%xmm0, 1712(%rbx)       ## 16-byte Spill
	movl	$101058054, 204(%rbx)   ## imm = 0x6060606
	movaps	LCPI0_4(%rip), %xmm0    ## xmm0 = [3,3]
	movups	%xmm0, 1928(%rbx)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movaps	%xmm0, 1776(%rbx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movaps	%xmm0, 1760(%rbx)
	movq	$16, 1944(%rbx)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, 1808(%rbx)
	movaps	LCPI0_9(%rip), %xmm1    ## xmm1 = [2,2]
	movups	%xmm1, 1792(%rbx)
	movups	%xmm0, 1824(%rbx)
	movq	$1, 1840(%rbx)
	subq	$8, %rsp
	leaq	1792(%rbx), %rax
	leaq	1728(%rbx), %rsi
	leaq	1760(%rbx), %rdx
	leaq	1848(%rbx), %rcx
	leaq	204(%rbx), %r8
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%rax
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	528(%rbx), %rax         ## 8-byte Reload
	addq	$416, %rax              ## imm = 0x1A0
	addq	$416, %r15              ## imm = 0x1A0
	xorl	%ecx, %ecx
	movaps	LCPI0_10(%rip), %xmm5   ## xmm5 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	LCPI0_11(%rip), %xmm6   ## xmm6 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	.p2align	4, 0x90
LBB0_1:                                 ## %cond1.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_2 Depth 2
	movq	$-50176, %rdx           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_2:                                 ## %cond4.preheader.i
                                        ##   Parent Loop BB0_1 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	49760(%r15,%rdx), %xmm0
	movups	49776(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 49776(%rax,%rdx)
	movups	%xmm2, 49760(%rax,%rdx)
	movups	49792(%r15,%rdx), %xmm0
	movups	49808(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 49808(%rax,%rdx)
	movups	%xmm2, 49792(%rax,%rdx)
	movups	49824(%r15,%rdx), %xmm0
	movups	49840(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 49840(%rax,%rdx)
	movups	%xmm2, 49824(%rax,%rdx)
	movups	49856(%r15,%rdx), %xmm0
	movups	49872(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 49872(%rax,%rdx)
	movups	%xmm2, 49856(%rax,%rdx)
	movups	49888(%r15,%rdx), %xmm0
	movups	49904(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 49904(%rax,%rdx)
	movups	%xmm2, 49888(%rax,%rdx)
	movups	49920(%r15,%rdx), %xmm0
	movups	49936(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 49936(%rax,%rdx)
	movups	%xmm2, 49920(%rax,%rdx)
	movups	49952(%r15,%rdx), %xmm0
	movups	49968(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 49968(%rax,%rdx)
	movups	%xmm2, 49952(%rax,%rdx)
	movups	49984(%r15,%rdx), %xmm0
	movups	50000(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 50000(%rax,%rdx)
	movups	%xmm2, 49984(%rax,%rdx)
	movups	50016(%r15,%rdx), %xmm0
	movups	50032(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 50032(%rax,%rdx)
	movups	%xmm2, 50016(%rax,%rdx)
	movups	50048(%r15,%rdx), %xmm0
	movups	50064(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 50064(%rax,%rdx)
	movups	%xmm2, 50048(%rax,%rdx)
	movups	50080(%r15,%rdx), %xmm0
	movups	50096(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 50096(%rax,%rdx)
	movups	%xmm2, 50080(%rax,%rdx)
	movups	50112(%r15,%rdx), %xmm0
	movups	50128(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 50128(%rax,%rdx)
	movups	%xmm2, 50112(%rax,%rdx)
	movups	50144(%r15,%rdx), %xmm0
	movups	50160(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 50160(%rax,%rdx)
	movups	%xmm2, 50144(%rax,%rdx)
	movups	50176(%r15,%rdx), %xmm0
	movups	50192(%r15,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 50192(%rax,%rdx)
	movups	%xmm2, 50176(%rax,%rdx)
	addq	$448, %rdx              ## imm = 0x1C0
	jne	LBB0_2
## %bb.3:                               ## %exit3.i
                                        ##   in Loop: Header=BB0_1 Depth=1
	incq	%rcx
	addq	$50176, %rax            ## imm = 0xC400
	addq	$50176, %r15            ## imm = 0xC400
	cmpq	$16, %rcx
	jne	LBB0_1
## %bb.4:                               ## %exit.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r15
	leaq	-16(%r15), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, %rsp
	movq	%r14, -32(%r9)
	movb	$6, -16(%r15)
	movaps	LCPI0_0(%rip), %xmm0    ## xmm0 = [112,112]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_1(%rip), %xmm0    ## xmm0 = [1,16]
	movups	%xmm0, -112(%rdi)
	movq	528(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r15)
	movups	%xmm1, -64(%rdi)
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r15)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_12(%rip), %xmm0   ## xmm0 = [16,16]
	movups	%xmm0, -48(%rdi)
	movaps	1168(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r15)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$16, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r10
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_5:                                 ## %cond13.preheader.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	50176(%r14,%rax), %xmm0
	movups	50192(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50192(%r12,%rax)
	movups	%xmm2, 50176(%r12,%rax)
	movups	50208(%r14,%rax), %xmm0
	movups	50224(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50224(%r12,%rax)
	movups	%xmm2, 50208(%r12,%rax)
	movups	50240(%r14,%rax), %xmm0
	movups	50256(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50256(%r12,%rax)
	movups	%xmm2, 50240(%r12,%rax)
	movups	50272(%r14,%rax), %xmm0
	movups	50288(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50288(%r12,%rax)
	movups	%xmm2, 50272(%r12,%rax)
	movups	50304(%r14,%rax), %xmm0
	movups	50320(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50320(%r12,%rax)
	movups	%xmm2, 50304(%r12,%rax)
	movups	50336(%r14,%rax), %xmm0
	movups	50352(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50352(%r12,%rax)
	movups	%xmm2, 50336(%r12,%rax)
	movups	50368(%r14,%rax), %xmm0
	movups	50384(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50384(%r12,%rax)
	movups	%xmm2, 50368(%r12,%rax)
	movups	50400(%r14,%rax), %xmm0
	movups	50416(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50416(%r12,%rax)
	movups	%xmm2, 50400(%r12,%rax)
	movups	50432(%r14,%rax), %xmm0
	movups	50448(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50448(%r12,%rax)
	movups	%xmm2, 50432(%r12,%rax)
	movups	50464(%r14,%rax), %xmm0
	movups	50480(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50480(%r12,%rax)
	movups	%xmm2, 50464(%r12,%rax)
	movups	50496(%r14,%rax), %xmm0
	movups	50512(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50512(%r12,%rax)
	movups	%xmm2, 50496(%r12,%rax)
	movups	50528(%r14,%rax), %xmm0
	movups	50544(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50544(%r12,%rax)
	movups	%xmm2, 50528(%r12,%rax)
	movups	50560(%r14,%rax), %xmm0
	movups	50576(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50576(%r12,%rax)
	movups	%xmm2, 50560(%r12,%rax)
	movups	50592(%r14,%rax), %xmm0
	movups	50608(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 50608(%r12,%rax)
	movups	%xmm2, 50592(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_5
## %bb.6:                               ## %cond13.preheader.1.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	movq	960(%rbx), %r15         ## 8-byte Reload
	.p2align	4, 0x90
LBB0_7:                                 ## %cond13.preheader.1.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	100352(%r14,%rax), %xmm0
	movups	100368(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100368(%r12,%rax)
	movups	%xmm2, 100352(%r12,%rax)
	movups	100384(%r14,%rax), %xmm0
	movups	100400(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100400(%r12,%rax)
	movups	%xmm2, 100384(%r12,%rax)
	movups	100416(%r14,%rax), %xmm0
	movups	100432(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100432(%r12,%rax)
	movups	%xmm2, 100416(%r12,%rax)
	movups	100448(%r14,%rax), %xmm0
	movups	100464(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100464(%r12,%rax)
	movups	%xmm2, 100448(%r12,%rax)
	movups	100480(%r14,%rax), %xmm0
	movups	100496(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100496(%r12,%rax)
	movups	%xmm2, 100480(%r12,%rax)
	movups	100512(%r14,%rax), %xmm0
	movups	100528(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100528(%r12,%rax)
	movups	%xmm2, 100512(%r12,%rax)
	movups	100544(%r14,%rax), %xmm0
	movups	100560(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100560(%r12,%rax)
	movups	%xmm2, 100544(%r12,%rax)
	movups	100576(%r14,%rax), %xmm0
	movups	100592(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100592(%r12,%rax)
	movups	%xmm2, 100576(%r12,%rax)
	movups	100608(%r14,%rax), %xmm0
	movups	100624(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100624(%r12,%rax)
	movups	%xmm2, 100608(%r12,%rax)
	movups	100640(%r14,%rax), %xmm0
	movups	100656(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100656(%r12,%rax)
	movups	%xmm2, 100640(%r12,%rax)
	movups	100672(%r14,%rax), %xmm0
	movups	100688(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100688(%r12,%rax)
	movups	%xmm2, 100672(%r12,%rax)
	movups	100704(%r14,%rax), %xmm0
	movups	100720(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100720(%r12,%rax)
	movups	%xmm2, 100704(%r12,%rax)
	movups	100736(%r14,%rax), %xmm0
	movups	100752(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100752(%r12,%rax)
	movups	%xmm2, 100736(%r12,%rax)
	movups	100768(%r14,%rax), %xmm0
	movups	100784(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 100784(%r12,%rax)
	movups	%xmm2, 100768(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_7
## %bb.8:                               ## %cond13.preheader.2.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_9:                                 ## %cond13.preheader.2.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	150528(%r14,%rax), %xmm0
	movups	150544(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150544(%r12,%rax)
	movups	%xmm2, 150528(%r12,%rax)
	movups	150560(%r14,%rax), %xmm0
	movups	150576(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150576(%r12,%rax)
	movups	%xmm2, 150560(%r12,%rax)
	movups	150592(%r14,%rax), %xmm0
	movups	150608(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150608(%r12,%rax)
	movups	%xmm2, 150592(%r12,%rax)
	movups	150624(%r14,%rax), %xmm0
	movups	150640(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150640(%r12,%rax)
	movups	%xmm2, 150624(%r12,%rax)
	movups	150656(%r14,%rax), %xmm0
	movups	150672(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150672(%r12,%rax)
	movups	%xmm2, 150656(%r12,%rax)
	movups	150688(%r14,%rax), %xmm0
	movups	150704(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150704(%r12,%rax)
	movups	%xmm2, 150688(%r12,%rax)
	movups	150720(%r14,%rax), %xmm0
	movups	150736(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150736(%r12,%rax)
	movups	%xmm2, 150720(%r12,%rax)
	movups	150752(%r14,%rax), %xmm0
	movups	150768(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150768(%r12,%rax)
	movups	%xmm2, 150752(%r12,%rax)
	movups	150784(%r14,%rax), %xmm0
	movups	150800(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150800(%r12,%rax)
	movups	%xmm2, 150784(%r12,%rax)
	movups	150816(%r14,%rax), %xmm0
	movups	150832(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150832(%r12,%rax)
	movups	%xmm2, 150816(%r12,%rax)
	movups	150848(%r14,%rax), %xmm0
	movups	150864(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150864(%r12,%rax)
	movups	%xmm2, 150848(%r12,%rax)
	movups	150880(%r14,%rax), %xmm0
	movups	150896(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150896(%r12,%rax)
	movups	%xmm2, 150880(%r12,%rax)
	movups	150912(%r14,%rax), %xmm0
	movups	150928(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150928(%r12,%rax)
	movups	%xmm2, 150912(%r12,%rax)
	movups	150944(%r14,%rax), %xmm0
	movups	150960(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 150960(%r12,%rax)
	movups	%xmm2, 150944(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_9
## %bb.10:                              ## %cond13.preheader.3.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_11:                                ## %cond13.preheader.3.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	200704(%r14,%rax), %xmm0
	movups	200720(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 200720(%r12,%rax)
	movups	%xmm2, 200704(%r12,%rax)
	movups	200736(%r14,%rax), %xmm0
	movups	200752(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 200752(%r12,%rax)
	movups	%xmm2, 200736(%r12,%rax)
	movups	200768(%r14,%rax), %xmm0
	movups	200784(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 200784(%r12,%rax)
	movups	%xmm2, 200768(%r12,%rax)
	movups	200800(%r14,%rax), %xmm0
	movups	200816(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 200816(%r12,%rax)
	movups	%xmm2, 200800(%r12,%rax)
	movups	200832(%r14,%rax), %xmm0
	movups	200848(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 200848(%r12,%rax)
	movups	%xmm2, 200832(%r12,%rax)
	movups	200864(%r14,%rax), %xmm0
	movups	200880(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 200880(%r12,%rax)
	movups	%xmm2, 200864(%r12,%rax)
	movups	200896(%r14,%rax), %xmm0
	movups	200912(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 200912(%r12,%rax)
	movups	%xmm2, 200896(%r12,%rax)
	movups	200928(%r14,%rax), %xmm0
	movups	200944(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 200944(%r12,%rax)
	movups	%xmm2, 200928(%r12,%rax)
	movups	200960(%r14,%rax), %xmm0
	movups	200976(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 200976(%r12,%rax)
	movups	%xmm2, 200960(%r12,%rax)
	movups	200992(%r14,%rax), %xmm0
	movups	201008(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 201008(%r12,%rax)
	movups	%xmm2, 200992(%r12,%rax)
	movups	201024(%r14,%rax), %xmm0
	movups	201040(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 201040(%r12,%rax)
	movups	%xmm2, 201024(%r12,%rax)
	movups	201056(%r14,%rax), %xmm0
	movups	201072(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 201072(%r12,%rax)
	movups	%xmm2, 201056(%r12,%rax)
	movups	201088(%r14,%rax), %xmm0
	movups	201104(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 201104(%r12,%rax)
	movups	%xmm2, 201088(%r12,%rax)
	movups	201120(%r14,%rax), %xmm0
	movups	201136(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 201136(%r12,%rax)
	movups	%xmm2, 201120(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_11
## %bb.12:                              ## %cond13.preheader.4.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_13:                                ## %cond13.preheader.4.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	250880(%r14,%rax), %xmm0
	movups	250896(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 250896(%r12,%rax)
	movups	%xmm2, 250880(%r12,%rax)
	movups	250912(%r14,%rax), %xmm0
	movups	250928(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 250928(%r12,%rax)
	movups	%xmm2, 250912(%r12,%rax)
	movups	250944(%r14,%rax), %xmm0
	movups	250960(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 250960(%r12,%rax)
	movups	%xmm2, 250944(%r12,%rax)
	movups	250976(%r14,%rax), %xmm0
	movups	250992(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 250992(%r12,%rax)
	movups	%xmm2, 250976(%r12,%rax)
	movups	251008(%r14,%rax), %xmm0
	movups	251024(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 251024(%r12,%rax)
	movups	%xmm2, 251008(%r12,%rax)
	movups	251040(%r14,%rax), %xmm0
	movups	251056(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 251056(%r12,%rax)
	movups	%xmm2, 251040(%r12,%rax)
	movups	251072(%r14,%rax), %xmm0
	movups	251088(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 251088(%r12,%rax)
	movups	%xmm2, 251072(%r12,%rax)
	movups	251104(%r14,%rax), %xmm0
	movups	251120(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 251120(%r12,%rax)
	movups	%xmm2, 251104(%r12,%rax)
	movups	251136(%r14,%rax), %xmm0
	movups	251152(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 251152(%r12,%rax)
	movups	%xmm2, 251136(%r12,%rax)
	movups	251168(%r14,%rax), %xmm0
	movups	251184(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 251184(%r12,%rax)
	movups	%xmm2, 251168(%r12,%rax)
	movups	251200(%r14,%rax), %xmm0
	movups	251216(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 251216(%r12,%rax)
	movups	%xmm2, 251200(%r12,%rax)
	movups	251232(%r14,%rax), %xmm0
	movups	251248(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 251248(%r12,%rax)
	movups	%xmm2, 251232(%r12,%rax)
	movups	251264(%r14,%rax), %xmm0
	movups	251280(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 251280(%r12,%rax)
	movups	%xmm2, 251264(%r12,%rax)
	movups	251296(%r14,%rax), %xmm0
	movups	251312(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 251312(%r12,%rax)
	movups	%xmm2, 251296(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_13
## %bb.14:                              ## %cond13.preheader.5.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_15:                                ## %cond13.preheader.5.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	301056(%r14,%rax), %xmm0
	movups	301072(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301072(%r12,%rax)
	movups	%xmm2, 301056(%r12,%rax)
	movups	301088(%r14,%rax), %xmm0
	movups	301104(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301104(%r12,%rax)
	movups	%xmm2, 301088(%r12,%rax)
	movups	301120(%r14,%rax), %xmm0
	movups	301136(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301136(%r12,%rax)
	movups	%xmm2, 301120(%r12,%rax)
	movups	301152(%r14,%rax), %xmm0
	movups	301168(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301168(%r12,%rax)
	movups	%xmm2, 301152(%r12,%rax)
	movups	301184(%r14,%rax), %xmm0
	movups	301200(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301200(%r12,%rax)
	movups	%xmm2, 301184(%r12,%rax)
	movups	301216(%r14,%rax), %xmm0
	movups	301232(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301232(%r12,%rax)
	movups	%xmm2, 301216(%r12,%rax)
	movups	301248(%r14,%rax), %xmm0
	movups	301264(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301264(%r12,%rax)
	movups	%xmm2, 301248(%r12,%rax)
	movups	301280(%r14,%rax), %xmm0
	movups	301296(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301296(%r12,%rax)
	movups	%xmm2, 301280(%r12,%rax)
	movups	301312(%r14,%rax), %xmm0
	movups	301328(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301328(%r12,%rax)
	movups	%xmm2, 301312(%r12,%rax)
	movups	301344(%r14,%rax), %xmm0
	movups	301360(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301360(%r12,%rax)
	movups	%xmm2, 301344(%r12,%rax)
	movups	301376(%r14,%rax), %xmm0
	movups	301392(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301392(%r12,%rax)
	movups	%xmm2, 301376(%r12,%rax)
	movups	301408(%r14,%rax), %xmm0
	movups	301424(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301424(%r12,%rax)
	movups	%xmm2, 301408(%r12,%rax)
	movups	301440(%r14,%rax), %xmm0
	movups	301456(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301456(%r12,%rax)
	movups	%xmm2, 301440(%r12,%rax)
	movups	301472(%r14,%rax), %xmm0
	movups	301488(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 301488(%r12,%rax)
	movups	%xmm2, 301472(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_15
## %bb.16:                              ## %cond13.preheader.6.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_17:                                ## %cond13.preheader.6.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	351232(%r14,%rax), %xmm0
	movups	351248(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351248(%r12,%rax)
	movups	%xmm2, 351232(%r12,%rax)
	movups	351264(%r14,%rax), %xmm0
	movups	351280(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351280(%r12,%rax)
	movups	%xmm2, 351264(%r12,%rax)
	movups	351296(%r14,%rax), %xmm0
	movups	351312(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351312(%r12,%rax)
	movups	%xmm2, 351296(%r12,%rax)
	movups	351328(%r14,%rax), %xmm0
	movups	351344(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351344(%r12,%rax)
	movups	%xmm2, 351328(%r12,%rax)
	movups	351360(%r14,%rax), %xmm0
	movups	351376(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351376(%r12,%rax)
	movups	%xmm2, 351360(%r12,%rax)
	movups	351392(%r14,%rax), %xmm0
	movups	351408(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351408(%r12,%rax)
	movups	%xmm2, 351392(%r12,%rax)
	movups	351424(%r14,%rax), %xmm0
	movups	351440(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351440(%r12,%rax)
	movups	%xmm2, 351424(%r12,%rax)
	movups	351456(%r14,%rax), %xmm0
	movups	351472(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351472(%r12,%rax)
	movups	%xmm2, 351456(%r12,%rax)
	movups	351488(%r14,%rax), %xmm0
	movups	351504(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351504(%r12,%rax)
	movups	%xmm2, 351488(%r12,%rax)
	movups	351520(%r14,%rax), %xmm0
	movups	351536(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351536(%r12,%rax)
	movups	%xmm2, 351520(%r12,%rax)
	movups	351552(%r14,%rax), %xmm0
	movups	351568(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351568(%r12,%rax)
	movups	%xmm2, 351552(%r12,%rax)
	movups	351584(%r14,%rax), %xmm0
	movups	351600(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351600(%r12,%rax)
	movups	%xmm2, 351584(%r12,%rax)
	movups	351616(%r14,%rax), %xmm0
	movups	351632(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351632(%r12,%rax)
	movups	%xmm2, 351616(%r12,%rax)
	movups	351648(%r14,%rax), %xmm0
	movups	351664(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 351664(%r12,%rax)
	movups	%xmm2, 351648(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_17
## %bb.18:                              ## %cond13.preheader.7.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_19:                                ## %cond13.preheader.7.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	401408(%r14,%rax), %xmm0
	movups	401424(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401424(%r12,%rax)
	movups	%xmm2, 401408(%r12,%rax)
	movups	401440(%r14,%rax), %xmm0
	movups	401456(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401456(%r12,%rax)
	movups	%xmm2, 401440(%r12,%rax)
	movups	401472(%r14,%rax), %xmm0
	movups	401488(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401488(%r12,%rax)
	movups	%xmm2, 401472(%r12,%rax)
	movups	401504(%r14,%rax), %xmm0
	movups	401520(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401520(%r12,%rax)
	movups	%xmm2, 401504(%r12,%rax)
	movups	401536(%r14,%rax), %xmm0
	movups	401552(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401552(%r12,%rax)
	movups	%xmm2, 401536(%r12,%rax)
	movups	401568(%r14,%rax), %xmm0
	movups	401584(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401584(%r12,%rax)
	movups	%xmm2, 401568(%r12,%rax)
	movups	401600(%r14,%rax), %xmm0
	movups	401616(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401616(%r12,%rax)
	movups	%xmm2, 401600(%r12,%rax)
	movups	401632(%r14,%rax), %xmm0
	movups	401648(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401648(%r12,%rax)
	movups	%xmm2, 401632(%r12,%rax)
	movups	401664(%r14,%rax), %xmm0
	movups	401680(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401680(%r12,%rax)
	movups	%xmm2, 401664(%r12,%rax)
	movups	401696(%r14,%rax), %xmm0
	movups	401712(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401712(%r12,%rax)
	movups	%xmm2, 401696(%r12,%rax)
	movups	401728(%r14,%rax), %xmm0
	movups	401744(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401744(%r12,%rax)
	movups	%xmm2, 401728(%r12,%rax)
	movups	401760(%r14,%rax), %xmm0
	movups	401776(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401776(%r12,%rax)
	movups	%xmm2, 401760(%r12,%rax)
	movups	401792(%r14,%rax), %xmm0
	movups	401808(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401808(%r12,%rax)
	movups	%xmm2, 401792(%r12,%rax)
	movups	401824(%r14,%rax), %xmm0
	movups	401840(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 401840(%r12,%rax)
	movups	%xmm2, 401824(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_19
## %bb.20:                              ## %cond13.preheader.8.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_21:                                ## %cond13.preheader.8.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	451584(%r14,%rax), %xmm0
	movups	451600(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451600(%r12,%rax)
	movups	%xmm2, 451584(%r12,%rax)
	movups	451616(%r14,%rax), %xmm0
	movups	451632(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451632(%r12,%rax)
	movups	%xmm2, 451616(%r12,%rax)
	movups	451648(%r14,%rax), %xmm0
	movups	451664(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451664(%r12,%rax)
	movups	%xmm2, 451648(%r12,%rax)
	movups	451680(%r14,%rax), %xmm0
	movups	451696(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451696(%r12,%rax)
	movups	%xmm2, 451680(%r12,%rax)
	movups	451712(%r14,%rax), %xmm0
	movups	451728(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451728(%r12,%rax)
	movups	%xmm2, 451712(%r12,%rax)
	movups	451744(%r14,%rax), %xmm0
	movups	451760(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451760(%r12,%rax)
	movups	%xmm2, 451744(%r12,%rax)
	movups	451776(%r14,%rax), %xmm0
	movups	451792(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451792(%r12,%rax)
	movups	%xmm2, 451776(%r12,%rax)
	movups	451808(%r14,%rax), %xmm0
	movups	451824(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451824(%r12,%rax)
	movups	%xmm2, 451808(%r12,%rax)
	movups	451840(%r14,%rax), %xmm0
	movups	451856(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451856(%r12,%rax)
	movups	%xmm2, 451840(%r12,%rax)
	movups	451872(%r14,%rax), %xmm0
	movups	451888(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451888(%r12,%rax)
	movups	%xmm2, 451872(%r12,%rax)
	movups	451904(%r14,%rax), %xmm0
	movups	451920(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451920(%r12,%rax)
	movups	%xmm2, 451904(%r12,%rax)
	movups	451936(%r14,%rax), %xmm0
	movups	451952(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451952(%r12,%rax)
	movups	%xmm2, 451936(%r12,%rax)
	movups	451968(%r14,%rax), %xmm0
	movups	451984(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 451984(%r12,%rax)
	movups	%xmm2, 451968(%r12,%rax)
	movups	452000(%r14,%rax), %xmm0
	movups	452016(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 452016(%r12,%rax)
	movups	%xmm2, 452000(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_21
## %bb.22:                              ## %cond13.preheader.9.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_23:                                ## %cond13.preheader.9.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	501760(%r14,%rax), %xmm0
	movups	501776(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 501776(%r12,%rax)
	movups	%xmm2, 501760(%r12,%rax)
	movups	501792(%r14,%rax), %xmm0
	movups	501808(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 501808(%r12,%rax)
	movups	%xmm2, 501792(%r12,%rax)
	movups	501824(%r14,%rax), %xmm0
	movups	501840(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 501840(%r12,%rax)
	movups	%xmm2, 501824(%r12,%rax)
	movups	501856(%r14,%rax), %xmm0
	movups	501872(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 501872(%r12,%rax)
	movups	%xmm2, 501856(%r12,%rax)
	movups	501888(%r14,%rax), %xmm0
	movups	501904(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 501904(%r12,%rax)
	movups	%xmm2, 501888(%r12,%rax)
	movups	501920(%r14,%rax), %xmm0
	movups	501936(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 501936(%r12,%rax)
	movups	%xmm2, 501920(%r12,%rax)
	movups	501952(%r14,%rax), %xmm0
	movups	501968(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 501968(%r12,%rax)
	movups	%xmm2, 501952(%r12,%rax)
	movups	501984(%r14,%rax), %xmm0
	movups	502000(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 502000(%r12,%rax)
	movups	%xmm2, 501984(%r12,%rax)
	movups	502016(%r14,%rax), %xmm0
	movups	502032(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 502032(%r12,%rax)
	movups	%xmm2, 502016(%r12,%rax)
	movups	502048(%r14,%rax), %xmm0
	movups	502064(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 502064(%r12,%rax)
	movups	%xmm2, 502048(%r12,%rax)
	movups	502080(%r14,%rax), %xmm0
	movups	502096(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 502096(%r12,%rax)
	movups	%xmm2, 502080(%r12,%rax)
	movups	502112(%r14,%rax), %xmm0
	movups	502128(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 502128(%r12,%rax)
	movups	%xmm2, 502112(%r12,%rax)
	movups	502144(%r14,%rax), %xmm0
	movups	502160(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 502160(%r12,%rax)
	movups	%xmm2, 502144(%r12,%rax)
	movups	502176(%r14,%rax), %xmm0
	movups	502192(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 502192(%r12,%rax)
	movups	%xmm2, 502176(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_23
## %bb.24:                              ## %cond13.preheader.10.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_25:                                ## %cond13.preheader.10.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	551936(%r14,%rax), %xmm0
	movups	551952(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 551952(%r12,%rax)
	movups	%xmm2, 551936(%r12,%rax)
	movups	551968(%r14,%rax), %xmm0
	movups	551984(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 551984(%r12,%rax)
	movups	%xmm2, 551968(%r12,%rax)
	movups	552000(%r14,%rax), %xmm0
	movups	552016(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552016(%r12,%rax)
	movups	%xmm2, 552000(%r12,%rax)
	movups	552032(%r14,%rax), %xmm0
	movups	552048(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552048(%r12,%rax)
	movups	%xmm2, 552032(%r12,%rax)
	movups	552064(%r14,%rax), %xmm0
	movups	552080(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552080(%r12,%rax)
	movups	%xmm2, 552064(%r12,%rax)
	movups	552096(%r14,%rax), %xmm0
	movups	552112(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552112(%r12,%rax)
	movups	%xmm2, 552096(%r12,%rax)
	movups	552128(%r14,%rax), %xmm0
	movups	552144(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552144(%r12,%rax)
	movups	%xmm2, 552128(%r12,%rax)
	movups	552160(%r14,%rax), %xmm0
	movups	552176(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552176(%r12,%rax)
	movups	%xmm2, 552160(%r12,%rax)
	movups	552192(%r14,%rax), %xmm0
	movups	552208(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552208(%r12,%rax)
	movups	%xmm2, 552192(%r12,%rax)
	movups	552224(%r14,%rax), %xmm0
	movups	552240(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552240(%r12,%rax)
	movups	%xmm2, 552224(%r12,%rax)
	movups	552256(%r14,%rax), %xmm0
	movups	552272(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552272(%r12,%rax)
	movups	%xmm2, 552256(%r12,%rax)
	movups	552288(%r14,%rax), %xmm0
	movups	552304(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552304(%r12,%rax)
	movups	%xmm2, 552288(%r12,%rax)
	movups	552320(%r14,%rax), %xmm0
	movups	552336(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552336(%r12,%rax)
	movups	%xmm2, 552320(%r12,%rax)
	movups	552352(%r14,%rax), %xmm0
	movups	552368(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 552368(%r12,%rax)
	movups	%xmm2, 552352(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_25
## %bb.26:                              ## %cond13.preheader.11.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_27:                                ## %cond13.preheader.11.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	602112(%r14,%rax), %xmm0
	movups	602128(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602128(%r12,%rax)
	movups	%xmm2, 602112(%r12,%rax)
	movups	602144(%r14,%rax), %xmm0
	movups	602160(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602160(%r12,%rax)
	movups	%xmm2, 602144(%r12,%rax)
	movups	602176(%r14,%rax), %xmm0
	movups	602192(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602192(%r12,%rax)
	movups	%xmm2, 602176(%r12,%rax)
	movups	602208(%r14,%rax), %xmm0
	movups	602224(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602224(%r12,%rax)
	movups	%xmm2, 602208(%r12,%rax)
	movups	602240(%r14,%rax), %xmm0
	movups	602256(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602256(%r12,%rax)
	movups	%xmm2, 602240(%r12,%rax)
	movups	602272(%r14,%rax), %xmm0
	movups	602288(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602288(%r12,%rax)
	movups	%xmm2, 602272(%r12,%rax)
	movups	602304(%r14,%rax), %xmm0
	movups	602320(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602320(%r12,%rax)
	movups	%xmm2, 602304(%r12,%rax)
	movups	602336(%r14,%rax), %xmm0
	movups	602352(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602352(%r12,%rax)
	movups	%xmm2, 602336(%r12,%rax)
	movups	602368(%r14,%rax), %xmm0
	movups	602384(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602384(%r12,%rax)
	movups	%xmm2, 602368(%r12,%rax)
	movups	602400(%r14,%rax), %xmm0
	movups	602416(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602416(%r12,%rax)
	movups	%xmm2, 602400(%r12,%rax)
	movups	602432(%r14,%rax), %xmm0
	movups	602448(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602448(%r12,%rax)
	movups	%xmm2, 602432(%r12,%rax)
	movups	602464(%r14,%rax), %xmm0
	movups	602480(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602480(%r12,%rax)
	movups	%xmm2, 602464(%r12,%rax)
	movups	602496(%r14,%rax), %xmm0
	movups	602512(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602512(%r12,%rax)
	movups	%xmm2, 602496(%r12,%rax)
	movups	602528(%r14,%rax), %xmm0
	movups	602544(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 602544(%r12,%rax)
	movups	%xmm2, 602528(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_27
## %bb.28:                              ## %cond13.preheader.12.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_29:                                ## %cond13.preheader.12.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	652288(%r14,%rax), %xmm0
	movups	652304(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652304(%r12,%rax)
	movups	%xmm2, 652288(%r12,%rax)
	movups	652320(%r14,%rax), %xmm0
	movups	652336(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652336(%r12,%rax)
	movups	%xmm2, 652320(%r12,%rax)
	movups	652352(%r14,%rax), %xmm0
	movups	652368(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652368(%r12,%rax)
	movups	%xmm2, 652352(%r12,%rax)
	movups	652384(%r14,%rax), %xmm0
	movups	652400(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652400(%r12,%rax)
	movups	%xmm2, 652384(%r12,%rax)
	movups	652416(%r14,%rax), %xmm0
	movups	652432(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652432(%r12,%rax)
	movups	%xmm2, 652416(%r12,%rax)
	movups	652448(%r14,%rax), %xmm0
	movups	652464(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652464(%r12,%rax)
	movups	%xmm2, 652448(%r12,%rax)
	movups	652480(%r14,%rax), %xmm0
	movups	652496(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652496(%r12,%rax)
	movups	%xmm2, 652480(%r12,%rax)
	movups	652512(%r14,%rax), %xmm0
	movups	652528(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652528(%r12,%rax)
	movups	%xmm2, 652512(%r12,%rax)
	movups	652544(%r14,%rax), %xmm0
	movups	652560(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652560(%r12,%rax)
	movups	%xmm2, 652544(%r12,%rax)
	movups	652576(%r14,%rax), %xmm0
	movups	652592(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652592(%r12,%rax)
	movups	%xmm2, 652576(%r12,%rax)
	movups	652608(%r14,%rax), %xmm0
	movups	652624(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652624(%r12,%rax)
	movups	%xmm2, 652608(%r12,%rax)
	movups	652640(%r14,%rax), %xmm0
	movups	652656(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652656(%r12,%rax)
	movups	%xmm2, 652640(%r12,%rax)
	movups	652672(%r14,%rax), %xmm0
	movups	652688(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652688(%r12,%rax)
	movups	%xmm2, 652672(%r12,%rax)
	movups	652704(%r14,%rax), %xmm0
	movups	652720(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 652720(%r12,%rax)
	movups	%xmm2, 652704(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_29
## %bb.30:                              ## %cond13.preheader.13.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_31:                                ## %cond13.preheader.13.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	702464(%r14,%rax), %xmm0
	movups	702480(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702480(%r12,%rax)
	movups	%xmm2, 702464(%r12,%rax)
	movups	702496(%r14,%rax), %xmm0
	movups	702512(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702512(%r12,%rax)
	movups	%xmm2, 702496(%r12,%rax)
	movups	702528(%r14,%rax), %xmm0
	movups	702544(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702544(%r12,%rax)
	movups	%xmm2, 702528(%r12,%rax)
	movups	702560(%r14,%rax), %xmm0
	movups	702576(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702576(%r12,%rax)
	movups	%xmm2, 702560(%r12,%rax)
	movups	702592(%r14,%rax), %xmm0
	movups	702608(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702608(%r12,%rax)
	movups	%xmm2, 702592(%r12,%rax)
	movups	702624(%r14,%rax), %xmm0
	movups	702640(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702640(%r12,%rax)
	movups	%xmm2, 702624(%r12,%rax)
	movups	702656(%r14,%rax), %xmm0
	movups	702672(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702672(%r12,%rax)
	movups	%xmm2, 702656(%r12,%rax)
	movups	702688(%r14,%rax), %xmm0
	movups	702704(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702704(%r12,%rax)
	movups	%xmm2, 702688(%r12,%rax)
	movups	702720(%r14,%rax), %xmm0
	movups	702736(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702736(%r12,%rax)
	movups	%xmm2, 702720(%r12,%rax)
	movups	702752(%r14,%rax), %xmm0
	movups	702768(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702768(%r12,%rax)
	movups	%xmm2, 702752(%r12,%rax)
	movups	702784(%r14,%rax), %xmm0
	movups	702800(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702800(%r12,%rax)
	movups	%xmm2, 702784(%r12,%rax)
	movups	702816(%r14,%rax), %xmm0
	movups	702832(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702832(%r12,%rax)
	movups	%xmm2, 702816(%r12,%rax)
	movups	702848(%r14,%rax), %xmm0
	movups	702864(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702864(%r12,%rax)
	movups	%xmm2, 702848(%r12,%rax)
	movups	702880(%r14,%rax), %xmm0
	movups	702896(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 702896(%r12,%rax)
	movups	%xmm2, 702880(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_31
## %bb.32:                              ## %cond13.preheader.14.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_33:                                ## %cond13.preheader.14.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	752640(%r14,%rax), %xmm0
	movups	752656(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752656(%r12,%rax)
	movups	%xmm2, 752640(%r12,%rax)
	movups	752672(%r14,%rax), %xmm0
	movups	752688(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752688(%r12,%rax)
	movups	%xmm2, 752672(%r12,%rax)
	movups	752704(%r14,%rax), %xmm0
	movups	752720(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752720(%r12,%rax)
	movups	%xmm2, 752704(%r12,%rax)
	movups	752736(%r14,%rax), %xmm0
	movups	752752(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752752(%r12,%rax)
	movups	%xmm2, 752736(%r12,%rax)
	movups	752768(%r14,%rax), %xmm0
	movups	752784(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752784(%r12,%rax)
	movups	%xmm2, 752768(%r12,%rax)
	movups	752800(%r14,%rax), %xmm0
	movups	752816(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752816(%r12,%rax)
	movups	%xmm2, 752800(%r12,%rax)
	movups	752832(%r14,%rax), %xmm0
	movups	752848(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752848(%r12,%rax)
	movups	%xmm2, 752832(%r12,%rax)
	movups	752864(%r14,%rax), %xmm0
	movups	752880(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752880(%r12,%rax)
	movups	%xmm2, 752864(%r12,%rax)
	movups	752896(%r14,%rax), %xmm0
	movups	752912(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752912(%r12,%rax)
	movups	%xmm2, 752896(%r12,%rax)
	movups	752928(%r14,%rax), %xmm0
	movups	752944(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752944(%r12,%rax)
	movups	%xmm2, 752928(%r12,%rax)
	movups	752960(%r14,%rax), %xmm0
	movups	752976(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 752976(%r12,%rax)
	movups	%xmm2, 752960(%r12,%rax)
	movups	752992(%r14,%rax), %xmm0
	movups	753008(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 753008(%r12,%rax)
	movups	%xmm2, 752992(%r12,%rax)
	movups	753024(%r14,%rax), %xmm0
	movups	753040(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 753040(%r12,%rax)
	movups	%xmm2, 753024(%r12,%rax)
	movups	753056(%r14,%rax), %xmm0
	movups	753072(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 753072(%r12,%rax)
	movups	%xmm2, 753056(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_33
## %bb.34:                              ## %cond13.preheader.15.i.preheader
	movq	$-50176, %rax           ## imm = 0xFFFF3C00
	.p2align	4, 0x90
LBB0_35:                                ## %cond13.preheader.15.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	802816(%r14,%rax), %xmm0
	movups	802832(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 802832(%r12,%rax)
	movups	%xmm2, 802816(%r12,%rax)
	movups	802848(%r14,%rax), %xmm0
	movups	802864(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 802864(%r12,%rax)
	movups	%xmm2, 802848(%r12,%rax)
	movups	802880(%r14,%rax), %xmm0
	movups	802896(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 802896(%r12,%rax)
	movups	%xmm2, 802880(%r12,%rax)
	movups	802912(%r14,%rax), %xmm0
	movups	802928(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 802928(%r12,%rax)
	movups	%xmm2, 802912(%r12,%rax)
	movups	802944(%r14,%rax), %xmm0
	movups	802960(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 802960(%r12,%rax)
	movups	%xmm2, 802944(%r12,%rax)
	movups	802976(%r14,%rax), %xmm0
	movups	802992(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 802992(%r12,%rax)
	movups	%xmm2, 802976(%r12,%rax)
	movups	803008(%r14,%rax), %xmm0
	movups	803024(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 803024(%r12,%rax)
	movups	%xmm2, 803008(%r12,%rax)
	movups	803040(%r14,%rax), %xmm0
	movups	803056(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 803056(%r12,%rax)
	movups	%xmm2, 803040(%r12,%rax)
	movups	803072(%r14,%rax), %xmm0
	movups	803088(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 803088(%r12,%rax)
	movups	%xmm2, 803072(%r12,%rax)
	movups	803104(%r14,%rax), %xmm0
	movups	803120(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 803120(%r12,%rax)
	movups	%xmm2, 803104(%r12,%rax)
	movups	803136(%r14,%rax), %xmm0
	movups	803152(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 803152(%r12,%rax)
	movups	%xmm2, 803136(%r12,%rax)
	movups	803168(%r14,%rax), %xmm0
	movups	803184(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 803184(%r12,%rax)
	movups	%xmm2, 803168(%r12,%rax)
	movups	803200(%r14,%rax), %xmm0
	movups	803216(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 803216(%r12,%rax)
	movups	%xmm2, 803200(%r12,%rax)
	movups	803232(%r14,%rax), %xmm0
	movups	803248(%r14,%rax), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 803248(%r12,%rax)
	movups	%xmm2, 803232(%r12,%rax)
	addq	$448, %rax              ## imm = 0x1C0
	jne	LBB0_35
## %bb.36:                              ## %exit12.15.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, %rsp
	movq	%r13, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_13(%rip), %xmm0   ## xmm0 = [56,56]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_1(%rip), %xmm0    ## xmm0 = [1,16]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -112(%rdi)
	movq	%r12, -24(%r9)
	movb	$6, -15(%rax)
	movaps	LCPI0_0(%rip), %xmm0    ## xmm0 = [112,112]
	movups	%xmm0, -64(%rdi)
	movups	%xmm1, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_4(%rip), %xmm0    ## xmm0 = [3,3]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_14(%rip), %xmm0   ## xmm0 = [16,1]
	movups	%xmm0, -48(%rdi)
	movaps	1184(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$16, -16(%rdi)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -48(%r11)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movups	%xmm0, -64(%r11)
	movups	%xmm1, -32(%r11)
	movq	$16, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r10
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-16(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	552(%rbx), %r12         ## 8-byte Reload
	movq	%r12, -16(%r10)
	movb	$6, -16(%rax)
	movaps	LCPI0_8(%rip), %xmm2    ## xmm2 = [1,1]
	movups	%xmm2, -48(%rdi)
	movaps	LCPI0_1(%rip), %xmm1    ## xmm1 = [1,16]
	movups	%xmm1, -64(%rdi)
	movq	%r13, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movaps	%xmm0, -16(%r9)
	movaps	LCPI0_13(%rip), %xmm0   ## xmm0 = [56,56]
	movups	%xmm0, -16(%rdi)
	movups	%xmm1, -32(%rdi)
	movaps	%xmm2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$2, %r9d
	pushq	%r14
	callq	_nnc_aten_adaptive_avg_pool2d
	addq	$16, %rsp
	movss	(%r12), %xmm1           ## xmm1 = mem[0],zero,zero,zero
	movss	4(%r12), %xmm2          ## xmm2 = mem[0],zero,zero,zero
	movss	8(%r12), %xmm3          ## xmm3 = mem[0],zero,zero,zero
	movss	12(%r12), %xmm0         ## xmm0 = mem[0],zero,zero,zero
	shufps	$0, %xmm1, %xmm1        ## xmm1 = xmm1[0,0,0,0]
	movq	568(%rbx), %rax         ## 8-byte Reload
	movups	(%rax), %xmm4
	mulps	%xmm1, %xmm4
	movups	16(%rax), %xmm5
	movups	32(%rax), %xmm6
	movups	48(%rax), %xmm7
	xorps	%xmm8, %xmm8
	addps	%xmm8, %xmm4
	shufps	$0, %xmm2, %xmm2        ## xmm2 = xmm2[0,0,0,0]
	mulps	%xmm5, %xmm2
	addps	%xmm4, %xmm2
	shufps	$0, %xmm3, %xmm3        ## xmm3 = xmm3[0,0,0,0]
	mulps	%xmm6, %xmm3
	addps	%xmm2, %xmm3
	shufps	$0, %xmm0, %xmm0        ## xmm0 = xmm0[0,0,0,0]
	mulps	%xmm7, %xmm0
	addps	%xmm3, %xmm0
	movups	64(%rax), %xmm2
	movss	16(%r12), %xmm3         ## xmm3 = mem[0],zero,zero,zero
	shufps	$0, %xmm3, %xmm3        ## xmm3 = xmm3[0,0,0,0]
	mulps	%xmm2, %xmm3
	addps	%xmm0, %xmm3
	movups	80(%rax), %xmm0
	movss	20(%r12), %xmm2         ## xmm2 = mem[0],zero,zero,zero
	shufps	$0, %xmm2, %xmm2        ## xmm2 = xmm2[0,0,0,0]
	mulps	%xmm0, %xmm2
	addps	%xmm3, %xmm2
	movups	96(%rax), %xmm0
	movss	24(%r12), %xmm3         ## xmm3 = mem[0],zero,zero,zero
	shufps	$0, %xmm3, %xmm3        ## xmm3 = xmm3[0,0,0,0]
	mulps	%xmm0, %xmm3
	addps	%xmm2, %xmm3
	movups	112(%rax), %xmm0
	movss	28(%r12), %xmm2         ## xmm2 = mem[0],zero,zero,zero
	shufps	$0, %xmm2, %xmm2        ## xmm2 = xmm2[0,0,0,0]
	mulps	%xmm0, %xmm2
	addps	%xmm3, %xmm2
	movups	128(%rax), %xmm0
	movss	32(%r12), %xmm3         ## xmm3 = mem[0],zero,zero,zero
	shufps	$0, %xmm3, %xmm3        ## xmm3 = xmm3[0,0,0,0]
	mulps	%xmm0, %xmm3
	addps	%xmm2, %xmm3
	movups	144(%rax), %xmm0
	movss	36(%r12), %xmm2         ## xmm2 = mem[0],zero,zero,zero
	shufps	$0, %xmm2, %xmm2        ## xmm2 = xmm2[0,0,0,0]
	mulps	%xmm0, %xmm2
	addps	%xmm3, %xmm2
	movups	160(%rax), %xmm0
	movss	40(%r12), %xmm3         ## xmm3 = mem[0],zero,zero,zero
	shufps	$0, %xmm3, %xmm3        ## xmm3 = xmm3[0,0,0,0]
	mulps	%xmm0, %xmm3
	addps	%xmm2, %xmm3
	movups	176(%rax), %xmm0
	movss	44(%r12), %xmm2         ## xmm2 = mem[0],zero,zero,zero
	shufps	$0, %xmm2, %xmm2        ## xmm2 = xmm2[0,0,0,0]
	mulps	%xmm0, %xmm2
	addps	%xmm3, %xmm2
	movups	192(%rax), %xmm0
	movss	48(%r12), %xmm3         ## xmm3 = mem[0],zero,zero,zero
	shufps	$0, %xmm3, %xmm3        ## xmm3 = xmm3[0,0,0,0]
	mulps	%xmm0, %xmm3
	addps	%xmm2, %xmm3
	movups	208(%rax), %xmm0
	movss	52(%r12), %xmm2         ## xmm2 = mem[0],zero,zero,zero
	shufps	$0, %xmm2, %xmm2        ## xmm2 = xmm2[0,0,0,0]
	mulps	%xmm0, %xmm2
	addps	%xmm3, %xmm2
	movups	224(%rax), %xmm0
	movss	56(%r12), %xmm3         ## xmm3 = mem[0],zero,zero,zero
	shufps	$0, %xmm3, %xmm3        ## xmm3 = xmm3[0,0,0,0]
	mulps	%xmm0, %xmm3
	addps	%xmm2, %xmm3
	movups	240(%rax), %xmm0
	movss	60(%r12), %xmm2         ## xmm2 = mem[0],zero,zero,zero
	shufps	$0, %xmm2, %xmm2        ## xmm2 = xmm2[0,0,0,0]
	mulps	%xmm0, %xmm2
	addps	%xmm3, %xmm2
	movq	560(%rbx), %rax         ## 8-byte Reload
	movups	%xmm2, (%rax)
	movaps	%xmm2, %xmm7
	shufps	$229, %xmm2, %xmm7      ## xmm7 = xmm7[1,1],xmm2[2,3]
	movaps	%xmm2, %xmm4
	shufps	$231, %xmm2, %xmm4      ## xmm4 = xmm4[3,1],xmm2[2,3]
	xorps	%xmm9, %xmm9
	xorps	%xmm10, %xmm10
	maxss	%xmm4, %xmm10
	xorps	%xmm6, %xmm6
	maxss	%xmm2, %xmm6
	movhlps	%xmm2, %xmm2            ## xmm2 = xmm2[1,1]
	xorps	%xmm4, %xmm4
	maxss	%xmm2, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm7, %xmm5
	shufps	$0, %xmm6, %xmm6        ## xmm6 = xmm6[0,0,0,0]
	shufps	$0, %xmm5, %xmm5        ## xmm5 = xmm5[0,0,0,0]
	shufps	$0, %xmm4, %xmm4        ## xmm4 = xmm4[0,0,0,0]
	shufps	$0, %xmm10, %xmm10      ## xmm10 = xmm10[0,0,0,0]
	movq	576(%rbx), %rax         ## 8-byte Reload
	movups	(%rax), %xmm2
	movups	16(%rax), %xmm7
	movups	64(%rax), %xmm1
	movups	80(%rax), %xmm0
	mulps	%xmm6, %xmm2
	mulps	%xmm6, %xmm7
	addps	%xmm8, %xmm7
	addps	%xmm8, %xmm2
	mulps	%xmm5, %xmm0
	addps	%xmm7, %xmm0
	mulps	%xmm5, %xmm1
	addps	%xmm2, %xmm1
	movups	144(%rax), %xmm7
	movups	128(%rax), %xmm3
	mulps	%xmm4, %xmm3
	addps	%xmm1, %xmm3
	mulps	%xmm4, %xmm7
	addps	%xmm0, %xmm7
	movups	192(%rax), %xmm2
	movups	208(%rax), %xmm0
	mulps	%xmm10, %xmm0
	addps	%xmm7, %xmm0
	mulps	%xmm10, %xmm2
	addps	%xmm3, %xmm2
	movq	584(%rbx), %rsi         ## 8-byte Reload
	movups	%xmm0, 16(%rsi)
	movups	%xmm2, (%rsi)
	movups	32(%rax), %xmm0
	movups	48(%rax), %xmm1
	movups	96(%rax), %xmm3
	movups	112(%rax), %xmm7
	mulps	%xmm6, %xmm0
	mulps	%xmm6, %xmm1
	addps	%xmm8, %xmm1
	addps	%xmm8, %xmm0
	mulps	%xmm5, %xmm7
	addps	%xmm1, %xmm7
	mulps	%xmm5, %xmm3
	addps	%xmm0, %xmm3
	movups	176(%rax), %xmm0
	movups	160(%rax), %xmm1
	mulps	%xmm4, %xmm1
	addps	%xmm3, %xmm1
	mulps	%xmm4, %xmm0
	addps	%xmm7, %xmm0
	movups	224(%rax), %xmm3
	movups	240(%rax), %xmm4
	mulps	%xmm10, %xmm4
	addps	%xmm0, %xmm4
	mulps	%xmm10, %xmm3
	addps	%xmm1, %xmm3
	movups	%xmm4, 48(%rsi)
	movups	%xmm3, 32(%rsi)
	movq	64(%rbx), %rax          ## 8-byte Reload
	addq	$192, %rax
	addq	$192, %r13
	xorl	%ecx, %ecx
	movss	LCPI0_16(%rip), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movss	LCPI0_17(%rip), %xmm5   ## xmm5 = mem[0],zero,zero,zero
	movq	896(%rbx), %r12         ## 8-byte Reload
	movq	600(%rbx), %r14         ## 8-byte Reload
	.p2align	4, 0x90
LBB0_37:                                ## %cond31.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_38 Depth 2
	addss	LCPI0_15(%rip), %xmm2
	xorps	%xmm3, %xmm3
	maxss	%xmm2, %xmm3
	movaps	%xmm2, %xmm1
	divss	%xmm0, %xmm1
	cmpltss	%xmm9, %xmm2
	andnps	%xmm1, %xmm2
	movaps	%xmm0, %xmm1
	cmpltss	%xmm3, %xmm1
	movaps	%xmm1, %xmm3
	andnps	%xmm2, %xmm3
	andps	%xmm5, %xmm1
	orps	%xmm3, %xmm1
	shufps	$0, %xmm1, %xmm1        ## xmm1 = xmm1[0,0,0,0]
	movq	$-12544, %rdx           ## imm = 0xCF00
	.p2align	4, 0x90
LBB0_38:                                ## %cond34.preheader.i
                                        ##   Parent Loop BB0_37 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	12352(%r13,%rdx), %xmm2
	movups	12368(%r13,%rdx), %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm1, %xmm2
	xorps	%xmm4, %xmm4
	maxps	%xmm2, %xmm4
	xorps	%xmm2, %xmm2
	maxps	%xmm3, %xmm2
	movups	%xmm2, 12368(%rax,%rdx)
	movups	%xmm4, 12352(%rax,%rdx)
	movups	12384(%r13,%rdx), %xmm2
	movups	12400(%r13,%rdx), %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm1, %xmm2
	xorps	%xmm4, %xmm4
	maxps	%xmm2, %xmm4
	xorps	%xmm2, %xmm2
	maxps	%xmm3, %xmm2
	movups	%xmm2, 12400(%rax,%rdx)
	movups	%xmm4, 12384(%rax,%rdx)
	movups	12416(%r13,%rdx), %xmm2
	movups	12432(%r13,%rdx), %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm1, %xmm2
	xorps	%xmm4, %xmm4
	maxps	%xmm2, %xmm4
	xorps	%xmm2, %xmm2
	maxps	%xmm3, %xmm2
	movups	%xmm2, 12432(%rax,%rdx)
	movups	%xmm4, 12416(%rax,%rdx)
	movups	12448(%r13,%rdx), %xmm2
	movups	12464(%r13,%rdx), %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm1, %xmm2
	xorps	%xmm4, %xmm4
	maxps	%xmm2, %xmm4
	xorps	%xmm2, %xmm2
	maxps	%xmm3, %xmm2
	movups	%xmm2, 12464(%rax,%rdx)
	movups	%xmm4, 12448(%rax,%rdx)
	movups	12480(%r13,%rdx), %xmm2
	movups	12496(%r13,%rdx), %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm1, %xmm2
	xorps	%xmm4, %xmm4
	maxps	%xmm2, %xmm4
	xorps	%xmm2, %xmm2
	maxps	%xmm3, %xmm2
	movups	%xmm2, 12496(%rax,%rdx)
	movups	%xmm4, 12480(%rax,%rdx)
	movups	12512(%r13,%rdx), %xmm2
	movups	12528(%r13,%rdx), %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm1, %xmm2
	xorps	%xmm4, %xmm4
	maxps	%xmm2, %xmm4
	xorps	%xmm2, %xmm2
	maxps	%xmm3, %xmm2
	movups	%xmm2, 12528(%rax,%rdx)
	movups	%xmm4, 12512(%rax,%rdx)
	movups	12544(%r13,%rdx), %xmm2
	movups	12560(%r13,%rdx), %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm1, %xmm2
	xorps	%xmm4, %xmm4
	maxps	%xmm2, %xmm4
	xorps	%xmm2, %xmm2
	maxps	%xmm3, %xmm2
	movups	%xmm2, 12560(%rax,%rdx)
	movups	%xmm4, 12544(%rax,%rdx)
	addq	$224, %rdx
	jne	LBB0_38
## %bb.39:                              ## %exit33.i
                                        ##   in Loop: Header=BB0_37 Depth=1
	leaq	1(%rcx), %rdx
	cmpq	$16, %rdx
	je	LBB0_40
## %bb.153:                             ## %exit33.i.cond31.preheader.i_crit_edge
                                        ##   in Loop: Header=BB0_37 Depth=1
	movss	4(%rsi,%rcx,4), %xmm2   ## xmm2 = mem[0],zero,zero,zero
	addq	$12544, %rax            ## imm = 0x3100
	addq	$12544, %r13            ## imm = 0x3100
	movq	%rdx, %rcx
	jmp	LBB0_37
LBB0_40:                                ## %exit30.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r13
	leaq	-16(%r13), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	208(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%r13)
	movaps	LCPI0_13(%rip), %xmm0   ## xmm0 = [56,56]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_1(%rip), %xmm0    ## xmm0 = [1,16]
	movups	%xmm0, -112(%rdi)
	movq	64(%rbx), %rax          ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r13)
	movups	%xmm1, -64(%rdi)
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r13)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_12(%rip), %xmm0   ## xmm0 = [16,16]
	movups	%xmm0, -48(%rdi)
	movaps	1200(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r13)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$16, -16(%rdi)
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, 64(%rbx)          ## 8-byte Spill
	movq	%r11, %rsp
	movq	592(%rbx), %r13         ## 8-byte Reload
	movq	%r13, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_13(%rip), %xmm1   ## xmm1 = [56,56]
	movups	%xmm1, -96(%rdi)
	movaps	LCPI0_18(%rip), %xmm0   ## xmm0 = [1,72]
	movups	%xmm0, -112(%rdi)
	movq	208(%rbx), %r11         ## 8-byte Reload
	movq	%r11, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm1, -64(%rdi)
	movaps	LCPI0_1(%rip), %xmm0    ## xmm0 = [1,16]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm1    ## xmm1 = [1,1]
	movups	%xmm1, -32(%rdi)
	movaps	LCPI0_19(%rip), %xmm0   ## xmm0 = [72,16]
	movups	%xmm0, -48(%rdi)
	movaps	1216(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$72, -16(%rdi)
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	64(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	movq	%r13, %rsi
	addq	$16, %rsp
	movq	224(%rbx), %rax         ## 8-byte Reload
	addq	$192, %rax
	addq	$192, %rsi
	xorl	%ecx, %ecx
	movq	832(%rbx), %r13         ## 8-byte Reload
	.p2align	4, 0x90
LBB0_41:                                ## %cond40.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_42 Depth 2
	movq	$-12544, %rdx           ## imm = 0xCF00
	.p2align	4, 0x90
LBB0_42:                                ## %cond43.preheader.i
                                        ##   Parent Loop BB0_41 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	12352(%rsi,%rdx), %xmm0
	movups	12368(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 12368(%rax,%rdx)
	movups	%xmm2, 12352(%rax,%rdx)
	movups	12384(%rsi,%rdx), %xmm0
	movups	12400(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 12400(%rax,%rdx)
	movups	%xmm2, 12384(%rax,%rdx)
	movups	12416(%rsi,%rdx), %xmm0
	movups	12432(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 12432(%rax,%rdx)
	movups	%xmm2, 12416(%rax,%rdx)
	movups	12448(%rsi,%rdx), %xmm0
	movups	12464(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 12464(%rax,%rdx)
	movups	%xmm2, 12448(%rax,%rdx)
	movups	12480(%rsi,%rdx), %xmm0
	movups	12496(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 12496(%rax,%rdx)
	movups	%xmm2, 12480(%rax,%rdx)
	movups	12512(%rsi,%rdx), %xmm0
	movups	12528(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 12528(%rax,%rdx)
	movups	%xmm2, 12512(%rax,%rdx)
	movups	12544(%rsi,%rdx), %xmm0
	movups	12560(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 12560(%rax,%rdx)
	movups	%xmm2, 12544(%rax,%rdx)
	addq	$224, %rdx
	jne	LBB0_42
## %bb.43:                              ## %exit42.i
                                        ##   in Loop: Header=BB0_41 Depth=1
	incq	%rcx
	addq	$12544, %rax            ## imm = 0x3100
	addq	$12544, %rsi            ## imm = 0x3100
	cmpq	$72, %rcx
	jne	LBB0_41
## %bb.44:                              ## %exit39.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rax
	movq	%rax, 64(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rcx
	leaq	-16(%rcx), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, 208(%rbx)         ## 8-byte Spill
	movq	%r10, %rsp
	movq	80(%rbx), %rax          ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%rcx)
	movaps	LCPI0_20(%rip), %xmm0   ## xmm0 = [28,28]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_18(%rip), %xmm0   ## xmm0 = [1,72]
	movups	%xmm0, -112(%rdi)
	movq	224(%rbx), %r10         ## 8-byte Reload
	movq	%r10, -24(%r9)
	movb	$6, -15(%rcx)
	movaps	LCPI0_13(%rip), %xmm1   ## xmm1 = [56,56]
	movups	%xmm1, -64(%rdi)
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rcx)
	movaps	LCPI0_4(%rip), %xmm0    ## xmm0 = [3,3]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_21(%rip), %xmm0   ## xmm0 = [72,1]
	movups	%xmm0, -48(%rdi)
	movaps	1232(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rcx)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$72, -16(%rdi)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -48(%r11)
	movaps	LCPI0_9(%rip), %xmm1    ## xmm1 = [2,2]
	movups	%xmm1, -64(%r11)
	movups	%xmm0, -32(%r11)
	movq	$72, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	movq	64(%rbx), %rcx          ## 8-byte Reload
	pushq	208(%rbx)               ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	movq	80(%rbx), %rsi          ## 8-byte Reload
	addq	$16, %rsp
	movq	48(%rbx), %rax          ## 8-byte Reload
	addq	$208, %rax
	addq	$208, %rsi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_45:                                ## %cond49.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_46 Depth 2
	movq	$-3136, %rdx            ## imm = 0xF3C0
	.p2align	4, 0x90
LBB0_46:                                ## %cond52.preheader.i
                                        ##   Parent Loop BB0_45 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	2928(%rsi,%rdx), %xmm0
	movups	2944(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 2944(%rax,%rdx)
	movups	%xmm2, 2928(%rax,%rdx)
	movups	2960(%rsi,%rdx), %xmm0
	movups	2976(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 2976(%rax,%rdx)
	movups	%xmm2, 2960(%rax,%rdx)
	movups	2992(%rsi,%rdx), %xmm0
	movups	3008(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3008(%rax,%rdx)
	movups	%xmm2, 2992(%rax,%rdx)
	movups	3024(%rsi,%rdx), %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm0, %xmm1
	movups	%xmm1, 3024(%rax,%rdx)
	movups	3040(%rsi,%rdx), %xmm0
	movups	3056(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3056(%rax,%rdx)
	movups	%xmm2, 3040(%rax,%rdx)
	movups	3072(%rsi,%rdx), %xmm0
	movups	3088(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3088(%rax,%rdx)
	movups	%xmm2, 3072(%rax,%rdx)
	movups	3104(%rsi,%rdx), %xmm0
	movups	3120(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3120(%rax,%rdx)
	movups	%xmm2, 3104(%rax,%rdx)
	movups	3136(%rsi,%rdx), %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm0, %xmm1
	movups	%xmm1, 3136(%rax,%rdx)
	addq	$224, %rdx
	jne	LBB0_46
## %bb.47:                              ## %exit51.i
                                        ##   in Loop: Header=BB0_45 Depth=1
	incq	%rcx
	addq	$3136, %rax             ## imm = 0xC40
	addq	$3136, %rsi             ## imm = 0xC40
	cmpq	$72, %rcx
	jne	LBB0_45
## %bb.48:                              ## %exit48.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rax
	movq	%rax, 80(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rcx
	leaq	-16(%rcx), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %rax
	movq	%rax, 224(%rbx)         ## 8-byte Spill
	movq	%rax, %rsp
	movq	16(%rbx), %rax          ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%rcx)
	movaps	LCPI0_20(%rip), %xmm0   ## xmm0 = [28,28]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_22(%rip), %xmm1   ## xmm1 = [1,24]
	movups	%xmm1, -112(%rdi)
	movq	48(%rbx), %r10          ## 8-byte Reload
	movq	%r10, -24(%r9)
	movb	$6, -15(%rcx)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_18(%rip), %xmm0   ## xmm0 = [1,72]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rcx)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_23(%rip), %xmm0   ## xmm0 = [24,72]
	movups	%xmm0, -48(%rdi)
	movaps	1248(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rcx)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$24, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	movq	80(%rbx), %rcx          ## 8-byte Reload
	pushq	224(%rbx)               ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rax
	movq	%rax, 80(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rcx
	leaq	-16(%rcx), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, 48(%rbx)          ## 8-byte Spill
	movq	%r11, %rsp
	movq	96(%rbx), %rax          ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%rcx)
	movaps	LCPI0_20(%rip), %xmm1   ## xmm1 = [28,28]
	movups	%xmm1, -96(%rdi)
	movaps	LCPI0_24(%rip), %xmm0   ## xmm0 = [1,88]
	movups	%xmm0, -112(%rdi)
	movq	16(%rbx), %r11          ## 8-byte Reload
	movq	%r11, -24(%r9)
	movb	$6, -15(%rcx)
	movups	%xmm1, -64(%rdi)
	movaps	LCPI0_22(%rip), %xmm0   ## xmm0 = [1,24]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rcx)
	movaps	LCPI0_8(%rip), %xmm1    ## xmm1 = [1,1]
	movups	%xmm1, -32(%rdi)
	movaps	LCPI0_25(%rip), %xmm0   ## xmm0 = [88,24]
	movups	%xmm0, -48(%rdi)
	movaps	1264(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rcx)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$88, -16(%rdi)
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	movq	80(%rbx), %rcx          ## 8-byte Reload
	pushq	48(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	movq	96(%rbx), %rsi          ## 8-byte Reload
	addq	$16, %rsp
	movq	240(%rbx), %rax         ## 8-byte Reload
	addq	$208, %rax
	addq	$208, %rsi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_49:                                ## %cond58.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_50 Depth 2
	movq	$-3136, %rdx            ## imm = 0xF3C0
	.p2align	4, 0x90
LBB0_50:                                ## %cond61.preheader.i
                                        ##   Parent Loop BB0_49 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	2928(%rsi,%rdx), %xmm0
	movups	2944(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 2944(%rax,%rdx)
	movups	%xmm2, 2928(%rax,%rdx)
	movups	2960(%rsi,%rdx), %xmm0
	movups	2976(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 2976(%rax,%rdx)
	movups	%xmm2, 2960(%rax,%rdx)
	movups	2992(%rsi,%rdx), %xmm0
	movups	3008(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3008(%rax,%rdx)
	movups	%xmm2, 2992(%rax,%rdx)
	movups	3024(%rsi,%rdx), %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm0, %xmm1
	movups	%xmm1, 3024(%rax,%rdx)
	movups	3040(%rsi,%rdx), %xmm0
	movups	3056(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3056(%rax,%rdx)
	movups	%xmm2, 3040(%rax,%rdx)
	movups	3072(%rsi,%rdx), %xmm0
	movups	3088(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3088(%rax,%rdx)
	movups	%xmm2, 3072(%rax,%rdx)
	movups	3104(%rsi,%rdx), %xmm0
	movups	3120(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3120(%rax,%rdx)
	movups	%xmm2, 3104(%rax,%rdx)
	movups	3136(%rsi,%rdx), %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm0, %xmm1
	movups	%xmm1, 3136(%rax,%rdx)
	addq	$224, %rdx
	jne	LBB0_50
## %bb.51:                              ## %exit60.i
                                        ##   in Loop: Header=BB0_49 Depth=1
	incq	%rcx
	addq	$3136, %rax             ## imm = 0xC40
	addq	$3136, %rsi             ## imm = 0xC40
	cmpq	$88, %rcx
	jne	LBB0_49
## %bb.52:                              ## %exit57.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rax
	movq	%rax, 48(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rcx
	leaq	-16(%rcx), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, 96(%rbx)          ## 8-byte Spill
	movq	%r11, %rsp
	movq	112(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%rcx)
	movaps	LCPI0_20(%rip), %xmm0   ## xmm0 = [28,28]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_24(%rip), %xmm1   ## xmm1 = [1,88]
	movups	%xmm1, -112(%rdi)
	movq	240(%rbx), %r11         ## 8-byte Reload
	movq	%r11, -24(%r9)
	movb	$6, -15(%rcx)
	movups	%xmm0, -64(%rdi)
	movups	%xmm1, -80(%rdi)
	movb	$6, -14(%rcx)
	movaps	LCPI0_4(%rip), %xmm0    ## xmm0 = [3,3]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_26(%rip), %xmm0   ## xmm0 = [88,1]
	movups	%xmm0, -48(%rdi)
	movaps	1280(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rcx)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$88, -16(%rdi)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -48(%r10)
	movups	%xmm0, -64(%r10)
	movups	%xmm0, -32(%r10)
	movq	$88, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	movq	48(%rbx), %rcx          ## 8-byte Reload
	pushq	96(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	movq	112(%rbx), %rsi         ## 8-byte Reload
	addq	$16, %rsp
	movq	256(%rbx), %rax         ## 8-byte Reload
	addq	$208, %rax
	addq	$208, %rsi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_53:                                ## %cond67.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_54 Depth 2
	movq	$-3136, %rdx            ## imm = 0xF3C0
	.p2align	4, 0x90
LBB0_54:                                ## %cond70.preheader.i
                                        ##   Parent Loop BB0_53 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	2928(%rsi,%rdx), %xmm0
	movups	2944(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 2944(%rax,%rdx)
	movups	%xmm2, 2928(%rax,%rdx)
	movups	2960(%rsi,%rdx), %xmm0
	movups	2976(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 2976(%rax,%rdx)
	movups	%xmm2, 2960(%rax,%rdx)
	movups	2992(%rsi,%rdx), %xmm0
	movups	3008(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3008(%rax,%rdx)
	movups	%xmm2, 2992(%rax,%rdx)
	movups	3024(%rsi,%rdx), %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm0, %xmm1
	movups	%xmm1, 3024(%rax,%rdx)
	movups	3040(%rsi,%rdx), %xmm0
	movups	3056(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3056(%rax,%rdx)
	movups	%xmm2, 3040(%rax,%rdx)
	movups	3072(%rsi,%rdx), %xmm0
	movups	3088(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3088(%rax,%rdx)
	movups	%xmm2, 3072(%rax,%rdx)
	movups	3104(%rsi,%rdx), %xmm0
	movups	3120(%rsi,%rdx), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 3120(%rax,%rdx)
	movups	%xmm2, 3104(%rax,%rdx)
	movups	3136(%rsi,%rdx), %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm0, %xmm1
	movups	%xmm1, 3136(%rax,%rdx)
	addq	$224, %rdx
	jne	LBB0_54
## %bb.55:                              ## %exit69.i
                                        ##   in Loop: Header=BB0_53 Depth=1
	incq	%rcx
	addq	$3136, %rax             ## imm = 0xC40
	addq	$3136, %rsi             ## imm = 0xC40
	cmpq	$88, %rcx
	jne	LBB0_53
## %bb.56:                              ## %exit66.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, 112(%rbx)         ## 8-byte Spill
	movq	%r10, %rsp
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_20(%rip), %xmm0   ## xmm0 = [28,28]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_22(%rip), %xmm1   ## xmm1 = [1,24]
	movups	%xmm1, -112(%rdi)
	movq	256(%rbx), %r10         ## 8-byte Reload
	movq	%r10, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_24(%rip), %xmm0   ## xmm0 = [1,88]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_27(%rip), %xmm0   ## xmm0 = [24,88]
	movups	%xmm0, -48(%rdi)
	movaps	1296(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$24, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	112(%rbx)               ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	272(%rbx), %rax         ## 8-byte Reload
	addq	$208, %rax
	addq	$208, %r14
	movq	16(%rbx), %rsi          ## 8-byte Reload
	addq	$208, %rsi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_57:                                ## %cond76.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_58 Depth 2
	movq	$-3136, %rdx            ## imm = 0xF3C0
	.p2align	4, 0x90
LBB0_58:                                ## %cond79.preheader.i
                                        ##   Parent Loop BB0_57 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	2928(%rsi,%rdx), %xmm0
	movups	2944(%rsi,%rdx), %xmm1
	movups	2928(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	2944(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 2944(%rax,%rdx)
	movups	%xmm2, 2928(%rax,%rdx)
	movups	2960(%rsi,%rdx), %xmm0
	movups	2976(%rsi,%rdx), %xmm1
	movups	2960(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	2976(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 2976(%rax,%rdx)
	movups	%xmm2, 2960(%rax,%rdx)
	movups	2992(%rsi,%rdx), %xmm0
	movups	3008(%rsi,%rdx), %xmm1
	movups	2992(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	3008(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 3008(%rax,%rdx)
	movups	%xmm2, 2992(%rax,%rdx)
	movups	3024(%rsi,%rdx), %xmm0
	movups	3024(%r14,%rdx), %xmm1
	addps	%xmm0, %xmm1
	movups	%xmm1, 3024(%rax,%rdx)
	movups	3040(%rsi,%rdx), %xmm0
	movups	3056(%rsi,%rdx), %xmm1
	movups	3040(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	3056(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 3056(%rax,%rdx)
	movups	%xmm2, 3040(%rax,%rdx)
	movups	3072(%rsi,%rdx), %xmm0
	movups	3088(%rsi,%rdx), %xmm1
	movups	3072(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	3088(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 3088(%rax,%rdx)
	movups	%xmm2, 3072(%rax,%rdx)
	movups	3104(%rsi,%rdx), %xmm0
	movups	3120(%rsi,%rdx), %xmm1
	movups	3104(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	3120(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 3120(%rax,%rdx)
	movups	%xmm2, 3104(%rax,%rdx)
	movups	3136(%rsi,%rdx), %xmm0
	movups	3136(%r14,%rdx), %xmm1
	addps	%xmm0, %xmm1
	movups	%xmm1, 3136(%rax,%rdx)
	addq	$224, %rdx
	jne	LBB0_58
## %bb.59:                              ## %exit78.i
                                        ##   in Loop: Header=BB0_57 Depth=1
	incq	%rcx
	addq	$3136, %rax             ## imm = 0xC40
	addq	$3136, %r14             ## imm = 0xC40
	addq	$3136, %rsi             ## imm = 0xC40
	cmpq	$24, %rcx
	jne	LBB0_57
## %bb.60:                              ## %exit75.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, 16(%rbx)          ## 8-byte Spill
	movq	%r10, %rsp
	movq	608(%rbx), %r14         ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_20(%rip), %xmm0   ## xmm0 = [28,28]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_28(%rip), %xmm0   ## xmm0 = [1,96]
	movups	%xmm0, -112(%rdi)
	movq	272(%rbx), %r10         ## 8-byte Reload
	movq	%r10, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm1, -64(%rdi)
	movaps	LCPI0_22(%rip), %xmm0   ## xmm0 = [1,24]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_29(%rip), %xmm0   ## xmm0 = [96,24]
	movups	%xmm0, -48(%rdi)
	movaps	1312(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$96, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	16(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	32(%rbx), %rax          ## 8-byte Reload
	addq	$96, %rax
	addq	$96, %r14
	xorl	%ecx, %ecx
	movaps	LCPI0_10(%rip), %xmm5   ## xmm5 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	LCPI0_11(%rip), %xmm6   ## xmm6 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	.p2align	4, 0x90
LBB0_61:                                ## %cond85.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_62 Depth 2
	movq	$-3136, %rdx            ## imm = 0xF3C0
	.p2align	4, 0x90
LBB0_62:                                ## %cond88.preheader.i
                                        ##   Parent Loop BB0_61 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	3040(%r14,%rdx), %xmm0
	movups	3056(%r14,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 3056(%rax,%rdx)
	movups	%xmm2, 3040(%rax,%rdx)
	movups	3072(%r14,%rdx), %xmm0
	movups	3088(%r14,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 3088(%rax,%rdx)
	movups	%xmm2, 3072(%rax,%rdx)
	movups	3104(%r14,%rdx), %xmm0
	movups	3120(%r14,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 3120(%rax,%rdx)
	movups	%xmm2, 3104(%rax,%rdx)
	movups	3136(%r14,%rdx), %xmm0
	movaps	%xmm0, %xmm1
	addps	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minps	%xmm2, %xmm1
	mulps	%xmm0, %xmm1
	divps	%xmm6, %xmm1
	movups	%xmm1, 3136(%rax,%rdx)
	addq	$112, %rdx
	jne	LBB0_62
## %bb.63:                              ## %exit87.i
                                        ##   in Loop: Header=BB0_61 Depth=1
	incq	%rcx
	addq	$3136, %rax             ## imm = 0xC40
	addq	$3136, %r14             ## imm = 0xC40
	cmpq	$96, %rcx
	jne	LBB0_61
## %bb.64:                              ## %exit84.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r14
	leaq	-16(%r14), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, %rsp
	movq	128(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%r14)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_28(%rip), %xmm0   ## xmm0 = [1,96]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -112(%rdi)
	movq	32(%rbx), %rax          ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r14)
	movaps	LCPI0_20(%rip), %xmm0   ## xmm0 = [28,28]
	movups	%xmm0, -64(%rdi)
	movups	%xmm1, -80(%rdi)
	movb	$6, -14(%r14)
	movaps	LCPI0_31(%rip), %xmm0   ## xmm0 = [5,5]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_32(%rip), %xmm0   ## xmm0 = [96,1]
	movups	%xmm0, -48(%rdi)
	movaps	1328(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r14)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$96, -16(%rdi)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movups	%xmm0, -48(%r11)
	movups	%xmm0, -64(%r11)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -32(%r11)
	movq	$96, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r10
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rcx
	leaq	-16(%rcx), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rax
	movq	%rax, 16(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r9
	movq	%r9, 32(%rbx)           ## 8-byte Spill
	movq	%r9, %rsp
	movq	616(%rbx), %r14         ## 8-byte Reload
	movq	%r14, -16(%r10)
	movb	$6, -16(%rax)
	movaps	LCPI0_8(%rip), %xmm2    ## xmm2 = [1,1]
	movups	%xmm2, -48(%rdi)
	movaps	LCPI0_28(%rip), %xmm1   ## xmm1 = [1,96]
	movups	%xmm1, -64(%rdi)
	movq	128(%rbx), %r9          ## 8-byte Reload
	movq	%r9, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movaps	%xmm0, -16(%rcx)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -16(%rdi)
	movups	%xmm1, -32(%rdi)
	movaps	%xmm2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$2, %r9d
	movq	16(%rbx), %rcx          ## 8-byte Reload
	pushq	32(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_adaptive_avg_pool2d
	addq	$16, %rsp
	xorl	%eax, %eax
	movq	296(%rbx), %r10         ## 8-byte Reload
	movq	648(%rbx), %r8          ## 8-byte Reload
	movq	632(%rbx), %rsi         ## 8-byte Reload
	movq	624(%rbx), %r9          ## 8-byte Reload
	.p2align	4, 0x90
LBB0_65:                                ## %body92.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_66 Depth 2
	movl	$0, (%r9,%rax,4)
	xorps	%xmm0, %xmm0
	movq	$-384, %rcx             ## imm = 0xFE80
	movq	%rsi, %rdx
	.p2align	4, 0x90
LBB0_66:                                ## %body95.i
                                        ##   Parent Loop BB0_65 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movss	384(%r14,%rcx), %xmm1   ## xmm1 = mem[0],zero,zero,zero
	movss	388(%r14,%rcx), %xmm2   ## xmm2 = mem[0],zero,zero,zero
	mulss	(%rdx), %xmm1
	addss	%xmm0, %xmm1
	mulss	96(%rdx), %xmm2
	addss	%xmm1, %xmm2
	movss	392(%r14,%rcx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	mulss	192(%rdx), %xmm0
	addss	%xmm2, %xmm0
	movss	396(%r14,%rcx), %xmm1   ## xmm1 = mem[0],zero,zero,zero
	mulss	288(%rdx), %xmm1
	addss	%xmm0, %xmm1
	movss	400(%r14,%rcx), %xmm2   ## xmm2 = mem[0],zero,zero,zero
	mulss	384(%rdx), %xmm2
	addss	%xmm1, %xmm2
	movss	404(%r14,%rcx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	mulss	480(%rdx), %xmm0
	addss	%xmm2, %xmm0
	addq	$576, %rdx              ## imm = 0x240
	addq	$24, %rcx
	jne	LBB0_66
## %bb.67:                              ## %exit96.i
                                        ##   in Loop: Header=BB0_65 Depth=1
	movss	%xmm0, (%r9,%rax,4)
	incq	%rax
	addq	$4, %rsi
	cmpq	$24, %rax
	jne	LBB0_65
## %bb.68:                              ## %body98.preheader.i
	xorps	%xmm0, %xmm0
	maxss	92(%r9), %xmm0
	movaps	%xmm0, 16(%rbx)         ## 16-byte Spill
	xorps	%xmm0, %xmm0
	maxss	88(%r9), %xmm0
	movaps	%xmm0, 32(%rbx)         ## 16-byte Spill
	xorps	%xmm0, %xmm0
	maxss	84(%r9), %xmm0
	movaps	%xmm0, 272(%rbx)        ## 16-byte Spill
	xorps	%xmm0, %xmm0
	maxss	80(%r9), %xmm0
	movaps	%xmm0, 112(%rbx)        ## 16-byte Spill
	xorps	%xmm0, %xmm0
	maxss	76(%r9), %xmm0
	movaps	%xmm0, 256(%rbx)        ## 16-byte Spill
	xorps	%xmm0, %xmm0
	maxss	72(%r9), %xmm0
	movaps	%xmm0, 240(%rbx)        ## 16-byte Spill
	xorps	%xmm0, %xmm0
	maxss	68(%r9), %xmm0
	movaps	%xmm0, 96(%rbx)         ## 16-byte Spill
	xorps	%xmm0, %xmm0
	maxss	64(%r9), %xmm0
	movaps	%xmm0, 48(%rbx)         ## 16-byte Spill
	xorps	%xmm4, %xmm4
	maxss	60(%r9), %xmm4
	xorps	%xmm3, %xmm3
	maxss	56(%r9), %xmm3
	xorps	%xmm2, %xmm2
	maxss	52(%r9), %xmm2
	xorps	%xmm1, %xmm1
	maxss	48(%r9), %xmm1
	xorps	%xmm0, %xmm0
	maxss	44(%r9), %xmm0
	xorps	%xmm5, %xmm5
	maxss	40(%r9), %xmm5
	xorps	%xmm6, %xmm6
	maxss	36(%r9), %xmm6
	xorps	%xmm7, %xmm7
	maxss	32(%r9), %xmm7
	xorps	%xmm8, %xmm8
	maxss	28(%r9), %xmm8
	xorps	%xmm9, %xmm9
	maxss	24(%r9), %xmm9
	xorps	%xmm10, %xmm10
	maxss	20(%r9), %xmm10
	xorps	%xmm11, %xmm11
	maxss	16(%r9), %xmm11
	xorps	%xmm12, %xmm12
	maxss	12(%r9), %xmm12
	xorps	%xmm13, %xmm13
	maxss	8(%r9), %xmm13
	xorps	%xmm14, %xmm14
	maxss	4(%r9), %xmm14
	xorps	%xmm15, %xmm15
	maxss	(%r9), %xmm15
	shufps	$0, %xmm15, %xmm15      ## xmm15 = xmm15[0,0,0,0]
	shufps	$0, %xmm14, %xmm14      ## xmm14 = xmm14[0,0,0,0]
	shufps	$0, %xmm13, %xmm13      ## xmm13 = xmm13[0,0,0,0]
	shufps	$0, %xmm12, %xmm12      ## xmm12 = xmm12[0,0,0,0]
	shufps	$0, %xmm11, %xmm11      ## xmm11 = xmm11[0,0,0,0]
	shufps	$0, %xmm10, %xmm10      ## xmm10 = xmm10[0,0,0,0]
	shufps	$0, %xmm9, %xmm9        ## xmm9 = xmm9[0,0,0,0]
	shufps	$0, %xmm8, %xmm8        ## xmm8 = xmm8[0,0,0,0]
	shufps	$0, %xmm7, %xmm7        ## xmm7 = xmm7[0,0,0,0]
	shufps	$0, %xmm6, %xmm6        ## xmm6 = xmm6[0,0,0,0]
	shufps	$0, %xmm5, %xmm5        ## xmm5 = xmm5[0,0,0,0]
	shufps	$0, %xmm0, %xmm0        ## xmm0 = xmm0[0,0,0,0]
	movaps	%xmm0, 528(%rbx)        ## 16-byte Spill
	shufps	$0, %xmm1, %xmm1        ## xmm1 = xmm1[0,0,0,0]
	movaps	%xmm1, 64(%rbx)         ## 16-byte Spill
	shufps	$0, %xmm2, %xmm2        ## xmm2 = xmm2[0,0,0,0]
	movaps	%xmm2, 208(%rbx)        ## 16-byte Spill
	shufps	$0, %xmm3, %xmm3        ## xmm3 = xmm3[0,0,0,0]
	movaps	%xmm3, 224(%rbx)        ## 16-byte Spill
	shufps	$0, %xmm4, %xmm4        ## xmm4 = xmm4[0,0,0,0]
	movaps	%xmm4, 80(%rbx)         ## 16-byte Spill
	movaps	48(%rbx), %xmm0         ## 16-byte Reload
	shufps	$0, %xmm0, %xmm0        ## xmm0 = xmm0[0,0,0,0]
	movaps	%xmm0, 48(%rbx)         ## 16-byte Spill
	movaps	96(%rbx), %xmm0         ## 16-byte Reload
	shufps	$0, %xmm0, %xmm0        ## xmm0 = xmm0[0,0,0,0]
	movaps	%xmm0, 96(%rbx)         ## 16-byte Spill
	movaps	240(%rbx), %xmm0        ## 16-byte Reload
	shufps	$0, %xmm0, %xmm0        ## xmm0 = xmm0[0,0,0,0]
	movaps	%xmm0, 240(%rbx)        ## 16-byte Spill
	movaps	256(%rbx), %xmm0        ## 16-byte Reload
	shufps	$0, %xmm0, %xmm0        ## xmm0 = xmm0[0,0,0,0]
	movaps	%xmm0, 256(%rbx)        ## 16-byte Spill
	movaps	112(%rbx), %xmm0        ## 16-byte Reload
	shufps	$0, %xmm0, %xmm0        ## xmm0 = xmm0[0,0,0,0]
	movaps	%xmm0, 112(%rbx)        ## 16-byte Spill
	movaps	272(%rbx), %xmm0        ## 16-byte Reload
	shufps	$0, %xmm0, %xmm0        ## xmm0 = xmm0[0,0,0,0]
	movaps	%xmm0, 272(%rbx)        ## 16-byte Spill
	movaps	32(%rbx), %xmm0         ## 16-byte Reload
	shufps	$0, %xmm0, %xmm0        ## xmm0 = xmm0[0,0,0,0]
	movaps	%xmm0, 32(%rbx)         ## 16-byte Spill
	movaps	16(%rbx), %xmm0         ## 16-byte Reload
	shufps	$0, %xmm0, %xmm0        ## xmm0 = xmm0[0,0,0,0]
	movaps	%xmm0, 16(%rbx)         ## 16-byte Spill
	movq	640(%rbx), %rcx         ## 8-byte Reload
	addq	$8832, %rcx             ## imm = 0x2280
	movq	$-384, %rax             ## imm = 0xFE80
	xorps	%xmm0, %xmm0
	.p2align	4, 0x90
LBB0_69:                                ## %vector.body995.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	%xmm0, 400(%r8,%rax)
	movups	%xmm0, 384(%r8,%rax)
	movups	-8448(%rcx,%rax), %xmm1
	movups	-8432(%rcx,%rax), %xmm2
	movups	-8048(%rcx,%rax), %xmm3
	mulps	%xmm15, %xmm2
	addps	%xmm0, %xmm2
	mulps	%xmm14, %xmm3
	addps	%xmm2, %xmm3
	movups	-8064(%rcx,%rax), %xmm2
	mulps	%xmm15, %xmm1
	addps	%xmm0, %xmm1
	mulps	%xmm14, %xmm2
	addps	%xmm1, %xmm2
	movups	-7680(%rcx,%rax), %xmm1
	mulps	%xmm13, %xmm1
	addps	%xmm2, %xmm1
	movups	-7664(%rcx,%rax), %xmm2
	mulps	%xmm13, %xmm2
	addps	%xmm3, %xmm2
	movups	-7280(%rcx,%rax), %xmm3
	mulps	%xmm12, %xmm3
	addps	%xmm2, %xmm3
	movups	-7296(%rcx,%rax), %xmm2
	mulps	%xmm12, %xmm2
	addps	%xmm1, %xmm2
	movups	-6912(%rcx,%rax), %xmm1
	mulps	%xmm11, %xmm1
	addps	%xmm2, %xmm1
	movups	-6896(%rcx,%rax), %xmm2
	mulps	%xmm11, %xmm2
	addps	%xmm3, %xmm2
	movups	-6512(%rcx,%rax), %xmm3
	mulps	%xmm10, %xmm3
	addps	%xmm2, %xmm3
	movups	-6528(%rcx,%rax), %xmm2
	mulps	%xmm10, %xmm2
	addps	%xmm1, %xmm2
	movups	-6144(%rcx,%rax), %xmm1
	mulps	%xmm9, %xmm1
	addps	%xmm2, %xmm1
	movups	-6128(%rcx,%rax), %xmm2
	mulps	%xmm9, %xmm2
	addps	%xmm3, %xmm2
	movups	-5744(%rcx,%rax), %xmm3
	mulps	%xmm8, %xmm3
	addps	%xmm2, %xmm3
	movups	-5760(%rcx,%rax), %xmm2
	mulps	%xmm8, %xmm2
	addps	%xmm1, %xmm2
	movups	-5376(%rcx,%rax), %xmm1
	mulps	%xmm7, %xmm1
	addps	%xmm2, %xmm1
	movups	-5360(%rcx,%rax), %xmm2
	mulps	%xmm7, %xmm2
	addps	%xmm3, %xmm2
	movups	-4976(%rcx,%rax), %xmm3
	mulps	%xmm6, %xmm3
	addps	%xmm2, %xmm3
	movups	-4992(%rcx,%rax), %xmm2
	mulps	%xmm6, %xmm2
	addps	%xmm1, %xmm2
	movups	-4608(%rcx,%rax), %xmm1
	mulps	%xmm5, %xmm1
	addps	%xmm2, %xmm1
	movups	-4592(%rcx,%rax), %xmm2
	mulps	%xmm5, %xmm2
	addps	%xmm3, %xmm2
	movups	-4208(%rcx,%rax), %xmm3
	movaps	528(%rbx), %xmm4        ## 16-byte Reload
	mulps	%xmm4, %xmm3
	addps	%xmm2, %xmm3
	movups	-4224(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm1, %xmm2
	movups	-3840(%rcx,%rax), %xmm1
	movaps	64(%rbx), %xmm4         ## 16-byte Reload
	mulps	%xmm4, %xmm1
	addps	%xmm2, %xmm1
	movups	-3824(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm3, %xmm2
	movups	-3440(%rcx,%rax), %xmm3
	movaps	208(%rbx), %xmm4        ## 16-byte Reload
	mulps	%xmm4, %xmm3
	addps	%xmm2, %xmm3
	movups	-3456(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm1, %xmm2
	movups	-3072(%rcx,%rax), %xmm1
	movaps	224(%rbx), %xmm4        ## 16-byte Reload
	mulps	%xmm4, %xmm1
	addps	%xmm2, %xmm1
	movups	-3056(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm3, %xmm2
	movups	-2672(%rcx,%rax), %xmm3
	movaps	80(%rbx), %xmm4         ## 16-byte Reload
	mulps	%xmm4, %xmm3
	addps	%xmm2, %xmm3
	movups	-2688(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm1, %xmm2
	movups	-2304(%rcx,%rax), %xmm1
	movaps	48(%rbx), %xmm4         ## 16-byte Reload
	mulps	%xmm4, %xmm1
	addps	%xmm2, %xmm1
	movups	-2288(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm3, %xmm2
	movups	-1904(%rcx,%rax), %xmm3
	movaps	96(%rbx), %xmm4         ## 16-byte Reload
	mulps	%xmm4, %xmm3
	addps	%xmm2, %xmm3
	movups	-1920(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm1, %xmm2
	movups	-1536(%rcx,%rax), %xmm1
	movaps	240(%rbx), %xmm4        ## 16-byte Reload
	mulps	%xmm4, %xmm1
	addps	%xmm2, %xmm1
	movups	-1520(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm3, %xmm2
	movups	-1136(%rcx,%rax), %xmm3
	movaps	256(%rbx), %xmm4        ## 16-byte Reload
	mulps	%xmm4, %xmm3
	addps	%xmm2, %xmm3
	movups	-1152(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm1, %xmm2
	movups	-768(%rcx,%rax), %xmm1
	movaps	112(%rbx), %xmm4        ## 16-byte Reload
	mulps	%xmm4, %xmm1
	addps	%xmm2, %xmm1
	movups	-752(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm3, %xmm2
	movups	-368(%rcx,%rax), %xmm3
	movaps	272(%rbx), %xmm4        ## 16-byte Reload
	mulps	%xmm4, %xmm3
	addps	%xmm2, %xmm3
	movups	-384(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm1, %xmm2
	movups	(%rcx,%rax), %xmm1
	movaps	32(%rbx), %xmm4         ## 16-byte Reload
	mulps	%xmm4, %xmm1
	addps	%xmm2, %xmm1
	movups	16(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm3, %xmm2
	movups	400(%rcx,%rax), %xmm3
	movaps	16(%rbx), %xmm4         ## 16-byte Reload
	mulps	%xmm4, %xmm3
	addps	%xmm2, %xmm3
	movups	384(%rcx,%rax), %xmm2
	mulps	%xmm4, %xmm2
	addps	%xmm1, %xmm2
	movups	%xmm3, 400(%r8,%rax)
	movups	%xmm2, 384(%r8,%rax)
	addq	$32, %rax
	jne	LBB0_69
## %bb.70:                              ## %cond106.preheader.i.preheader
	leaq	52(%r10), %rax
	movq	128(%rbx), %rsi         ## 8-byte Reload
	addq	$52, %rsi
	xorl	%ecx, %ecx
	xorps	%xmm8, %xmm8
	movaps	LCPI0_10(%rip), %xmm0   ## xmm0 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	%xmm0, %xmm9
	movaps	LCPI0_11(%rip), %xmm0   ## xmm0 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movss	LCPI0_15(%rip), %xmm10  ## xmm10 = mem[0],zero,zero,zero
	movss	LCPI0_16(%rip), %xmm11  ## xmm11 = mem[0],zero,zero,zero
	movss	LCPI0_17(%rip), %xmm12  ## xmm12 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_71:                                ## %cond106.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_72 Depth 2
	movss	(%r8,%rcx,4), %xmm2     ## xmm2 = mem[0],zero,zero,zero
	addss	%xmm10, %xmm2
	xorps	%xmm3, %xmm3
	maxss	%xmm2, %xmm3
	movaps	%xmm2, %xmm1
	divss	%xmm11, %xmm1
	cmpltss	%xmm8, %xmm2
	andnps	%xmm1, %xmm2
	movaps	%xmm11, %xmm1
	cmpltss	%xmm3, %xmm1
	movaps	%xmm1, %xmm3
	andnps	%xmm2, %xmm3
	andps	%xmm12, %xmm1
	orps	%xmm3, %xmm1
	movaps	%xmm1, %xmm2
	shufps	$0, %xmm1, %xmm2        ## xmm2 = xmm2[0,0],xmm1[0,0]
	movq	$-784, %rdx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_72:                                ## %cond109.preheader.i
                                        ##   Parent Loop BB0_71 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	732(%rsi,%rdx), %xmm3
	movups	748(%rsi,%rdx), %xmm4
	mulps	%xmm2, %xmm4
	mulps	%xmm2, %xmm3
	movaps	%xmm3, %xmm5
	addps	%xmm9, %xmm5
	movaps	%xmm4, %xmm6
	addps	%xmm9, %xmm6
	xorps	%xmm7, %xmm7
	maxps	%xmm6, %xmm7
	xorps	%xmm6, %xmm6
	maxps	%xmm5, %xmm6
	movaps	%xmm0, %xmm5
	minps	%xmm6, %xmm5
	movaps	%xmm0, %xmm6
	minps	%xmm7, %xmm6
	mulps	%xmm4, %xmm6
	mulps	%xmm3, %xmm5
	divps	%xmm0, %xmm5
	divps	%xmm0, %xmm6
	movups	%xmm6, 748(%rax,%rdx)
	movups	%xmm5, 732(%rax,%rdx)
	movups	764(%rsi,%rdx), %xmm3
	mulps	%xmm2, %xmm3
	movaps	%xmm3, %xmm4
	addps	%xmm9, %xmm4
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	movaps	%xmm0, %xmm4
	minps	%xmm5, %xmm4
	mulps	%xmm3, %xmm4
	divps	%xmm0, %xmm4
	movups	%xmm4, 764(%rax,%rdx)
	movss	780(%rsi,%rdx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm10, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm11, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm11, %xmm4
	movss	%xmm4, 780(%rax,%rdx)
	movss	784(%rsi,%rdx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm10, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm11, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm11, %xmm4
	movss	%xmm4, 784(%rax,%rdx)
	addq	$56, %rdx
	jne	LBB0_72
## %bb.73:                              ## %exit108.i
                                        ##   in Loop: Header=BB0_71 Depth=1
	incq	%rcx
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %rsi              ## imm = 0x310
	cmpq	$96, %rcx
	jne	LBB0_71
## %bb.74:                              ## %exit105.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r14
	leaq	-16(%r14), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, %rsp
	movq	144(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%r14)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_33(%rip), %xmm1   ## xmm1 = [1,40]
	movups	%xmm1, -112(%rdi)
	movq	296(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r14)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_28(%rip), %xmm0   ## xmm0 = [1,96]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r14)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_34(%rip), %xmm0   ## xmm0 = [40,96]
	movups	%xmm0, -48(%rdi)
	movaps	1344(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r14)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$40, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r10
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, 16(%rbx)          ## 8-byte Spill
	movq	%r11, %rsp
	movq	656(%rbx), %r14         ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_30(%rip), %xmm1   ## xmm1 = [14,14]
	movups	%xmm1, -96(%rdi)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -112(%rdi)
	movq	144(%rbx), %r11         ## 8-byte Reload
	movq	%r11, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm1, -64(%rdi)
	movaps	LCPI0_33(%rip), %xmm0   ## xmm0 = [1,40]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm1    ## xmm1 = [1,1]
	movups	%xmm1, -32(%rdi)
	movaps	LCPI0_36(%rip), %xmm0   ## xmm0 = [240,40]
	movups	%xmm0, -48(%rdi)
	movaps	1360(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$240, -16(%rdi)
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	16(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	movss	LCPI0_16(%rip), %xmm8   ## xmm8 = mem[0],zero,zero,zero
	movss	LCPI0_15(%rip), %xmm7   ## xmm7 = mem[0],zero,zero,zero
	movaps	LCPI0_11(%rip), %xmm6   ## xmm6 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm5   ## xmm5 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	addq	$16, %rsp
	movq	304(%rbx), %rax         ## 8-byte Reload
	addq	$52, %rax
	addq	$52, %r14
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_75:                                ## %cond115.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_76 Depth 2
	movq	$-784, %rdx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_76:                                ## %cond118.preheader.i
                                        ##   Parent Loop BB0_75 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	732(%r14,%rdx), %xmm0
	movups	748(%r14,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 748(%rax,%rdx)
	movups	%xmm2, 732(%rax,%rdx)
	movups	764(%r14,%rdx), %xmm0
	movaps	%xmm0, %xmm1
	addps	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minps	%xmm2, %xmm1
	mulps	%xmm0, %xmm1
	divps	%xmm6, %xmm1
	movups	%xmm1, 764(%rax,%rdx)
	movss	780(%r14,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm7, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm8, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm8, %xmm1
	movss	%xmm1, 780(%rax,%rdx)
	movss	784(%r14,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm7, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm8, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm8, %xmm1
	movss	%xmm1, 784(%rax,%rdx)
	addq	$56, %rdx
	jne	LBB0_76
## %bb.77:                              ## %exit117.i
                                        ##   in Loop: Header=BB0_75 Depth=1
	incq	%rcx
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %r14              ## imm = 0x310
	cmpq	$240, %rcx
	jne	LBB0_75
## %bb.78:                              ## %exit114.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r14
	leaq	-16(%r14), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	136(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%r14)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -112(%rdi)
	movq	304(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r14)
	movups	%xmm1, -64(%rdi)
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r14)
	movaps	LCPI0_31(%rip), %xmm0   ## xmm0 = [5,5]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_37(%rip), %xmm0   ## xmm0 = [240,1]
	movups	%xmm0, -48(%rdi)
	movaps	1376(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r14)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$240, -16(%rdi)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movups	%xmm0, -48(%r10)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -64(%r10)
	movups	%xmm0, -32(%r10)
	movq	$240, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	leaq	-16(%rdx), %rax
	movq	%rax, 32(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rax
	movq	%rax, 16(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	312(%rbx), %rcx         ## 8-byte Reload
	movq	%rcx, -16(%r10)
	movb	$6, -16(%rax)
	movaps	LCPI0_8(%rip), %xmm2    ## xmm2 = [1,1]
	movups	%xmm2, -48(%rdi)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -64(%rdi)
	movq	136(%rbx), %r9          ## 8-byte Reload
	movq	%r9, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_7(%rip), %xmm1    ## xmm1 = [4,4]
	movaps	%xmm1, -16(%rdx)
	movaps	LCPI0_30(%rip), %xmm1   ## xmm1 = [14,14]
	movups	%xmm1, -16(%rdi)
	movups	%xmm0, -32(%rdi)
	movaps	%xmm2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$2, %r9d
	movq	32(%rbx), %rdx          ## 8-byte Reload
	movq	16(%rbx), %rcx          ## 8-byte Reload
	pushq	%r14
	callq	_nnc_aten_adaptive_avg_pool2d
	addq	$16, %rsp
	movl	$960, %edx              ## imm = 0x3C0
	movq	664(%rbx), %r14         ## 8-byte Reload
	movq	%r14, %rdi
	movq	312(%rbx), %rsi         ## 8-byte Reload
	callq	_memcpy
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	320(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -32(%r10)
	movb	$6, -16(%rax)
	movq	%r14, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_38(%rip), %xmm0   ## xmm0 = [1,60]
	movups	%xmm0, -48(%r11)
	movq	672(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_39(%rip), %xmm0   ## xmm0 = [240,60]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	leaq	8(%rbx), %rax
	xorl	%r14d, %r14d
	movl	$3, %edi
	xorl	%r9d, %r9d
	pushq	%rax
	callq	_nnc_aten_matmul
	addq	$16, %rsp
	movq	320(%rbx), %rax         ## 8-byte Reload
	movups	(%rax), %xmm1
	movups	16(%rax), %xmm2
	xorps	%xmm0, %xmm0
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movq	680(%rbx), %rdi         ## 8-byte Reload
	movups	%xmm1, 16(%rdi)
	movups	%xmm3, (%rdi)
	movups	32(%rax), %xmm1
	movups	48(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 48(%rdi)
	movups	%xmm3, 32(%rdi)
	movups	64(%rax), %xmm1
	movups	80(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 80(%rdi)
	movups	%xmm3, 64(%rdi)
	movups	96(%rax), %xmm1
	movups	112(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 112(%rdi)
	movups	%xmm3, 96(%rdi)
	movups	128(%rax), %xmm1
	movups	144(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 144(%rdi)
	movups	%xmm3, 128(%rdi)
	movups	160(%rax), %xmm1
	movups	176(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 176(%rdi)
	movups	%xmm3, 160(%rdi)
	movups	192(%rax), %xmm1
	movups	208(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 208(%rdi)
	movups	%xmm3, 192(%rdi)
	movups	224(%rax), %xmm1
	maxps	%xmm1, %xmm0
	movups	%xmm0, 224(%rdi)
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rax
	movq	%rax, 16(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	328(%rbx), %rcx         ## 8-byte Reload
	movq	%rcx, -32(%r10)
	movb	$6, -16(%rax)
	movq	%rdi, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_38(%rip), %xmm0   ## xmm0 = [1,60]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -48(%r11)
	movq	688(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_40(%rip), %xmm0   ## xmm0 = [60,240]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	movl	$3, %edi
	movq	16(%rbx), %rcx          ## 8-byte Reload
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	movq	328(%rbx), %rsi         ## 8-byte Reload
	movq	136(%rbx), %rdx         ## 8-byte Reload
	movss	LCPI0_16(%rip), %xmm11  ## xmm11 = mem[0],zero,zero,zero
	movss	LCPI0_15(%rip), %xmm10  ## xmm10 = mem[0],zero,zero,zero
	movaps	LCPI0_11(%rip), %xmm9   ## xmm9 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm0   ## xmm0 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	addq	$16, %rsp
	movq	336(%rbx), %rax         ## 8-byte Reload
	addq	$52, %rax
	addq	$52, %rdx
	xorps	%xmm8, %xmm8
	movss	LCPI0_17(%rip), %xmm12  ## xmm12 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_79:                                ## %cond130.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_80 Depth 2
	movss	(%rsi,%r14,4), %xmm2    ## xmm2 = mem[0],zero,zero,zero
	addss	%xmm10, %xmm2
	xorps	%xmm3, %xmm3
	maxss	%xmm2, %xmm3
	movaps	%xmm2, %xmm1
	divss	%xmm11, %xmm1
	cmpltss	%xmm8, %xmm2
	andnps	%xmm1, %xmm2
	movaps	%xmm11, %xmm1
	cmpltss	%xmm3, %xmm1
	movaps	%xmm1, %xmm3
	andnps	%xmm2, %xmm3
	andps	%xmm12, %xmm1
	orps	%xmm3, %xmm1
	movaps	%xmm1, %xmm2
	shufps	$0, %xmm1, %xmm2        ## xmm2 = xmm2[0,0],xmm1[0,0]
	movq	$-784, %rcx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_80:                                ## %cond133.preheader.i
                                        ##   Parent Loop BB0_79 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	732(%rdx,%rcx), %xmm3
	movups	748(%rdx,%rcx), %xmm4
	mulps	%xmm2, %xmm4
	mulps	%xmm2, %xmm3
	movaps	%xmm3, %xmm5
	addps	%xmm0, %xmm5
	movaps	%xmm4, %xmm6
	addps	%xmm0, %xmm6
	xorps	%xmm7, %xmm7
	maxps	%xmm6, %xmm7
	xorps	%xmm6, %xmm6
	maxps	%xmm5, %xmm6
	movaps	%xmm9, %xmm5
	minps	%xmm6, %xmm5
	movaps	%xmm9, %xmm6
	minps	%xmm7, %xmm6
	mulps	%xmm4, %xmm6
	mulps	%xmm3, %xmm5
	divps	%xmm9, %xmm5
	divps	%xmm9, %xmm6
	movups	%xmm6, 748(%rax,%rcx)
	movups	%xmm5, 732(%rax,%rcx)
	movups	764(%rdx,%rcx), %xmm3
	mulps	%xmm2, %xmm3
	movaps	%xmm3, %xmm4
	addps	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	movaps	%xmm9, %xmm4
	minps	%xmm5, %xmm4
	mulps	%xmm3, %xmm4
	divps	%xmm9, %xmm4
	movups	%xmm4, 764(%rax,%rcx)
	movss	780(%rdx,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm10, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm11, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm11, %xmm4
	movss	%xmm4, 780(%rax,%rcx)
	movss	784(%rdx,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm10, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm11, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm11, %xmm4
	movss	%xmm4, 784(%rax,%rcx)
	addq	$56, %rcx
	jne	LBB0_80
## %bb.81:                              ## %exit132.i
                                        ##   in Loop: Header=BB0_79 Depth=1
	incq	%r14
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %rdx              ## imm = 0x310
	cmpq	$240, %r14
	jne	LBB0_79
## %bb.82:                              ## %exit129.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, 16(%rbx)          ## 8-byte Spill
	movq	%r10, %rsp
	movq	696(%rbx), %r14         ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_33(%rip), %xmm1   ## xmm1 = [1,40]
	movups	%xmm1, -112(%rdi)
	movq	336(%rbx), %r10         ## 8-byte Reload
	movq	%r10, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_41(%rip), %xmm0   ## xmm0 = [40,240]
	movups	%xmm0, -48(%rdi)
	movaps	1392(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$40, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	16(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	160(%rbx), %rax         ## 8-byte Reload
	addq	$108, %rax
	addq	$108, %r14
	movq	144(%rbx), %rsi         ## 8-byte Reload
	addq	$108, %rsi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_83:                                ## %cond139.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_84 Depth 2
	movq	$-784, %rdx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_84:                                ## %cond142.preheader.i
                                        ##   Parent Loop BB0_83 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	676(%rsi,%rdx), %xmm0
	movups	692(%rsi,%rdx), %xmm1
	movups	676(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	692(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 692(%rax,%rdx)
	movups	%xmm2, 676(%rax,%rdx)
	movups	708(%rsi,%rdx), %xmm0
	movups	708(%r14,%rdx), %xmm1
	addps	%xmm0, %xmm1
	movups	%xmm1, 708(%rax,%rdx)
	movss	724(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	724(%r14,%rdx), %xmm0
	movss	%xmm0, 724(%rax,%rdx)
	movss	728(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	728(%r14,%rdx), %xmm0
	movss	%xmm0, 728(%rax,%rdx)
	movups	732(%rsi,%rdx), %xmm0
	movups	748(%rsi,%rdx), %xmm1
	movups	732(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	748(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 748(%rax,%rdx)
	movups	%xmm2, 732(%rax,%rdx)
	movups	764(%rsi,%rdx), %xmm0
	movups	764(%r14,%rdx), %xmm1
	addps	%xmm0, %xmm1
	movups	%xmm1, 764(%rax,%rdx)
	movss	780(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	780(%r14,%rdx), %xmm0
	movss	%xmm0, 780(%rax,%rdx)
	movss	784(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	784(%r14,%rdx), %xmm0
	movss	%xmm0, 784(%rax,%rdx)
	addq	$112, %rdx
	jne	LBB0_84
## %bb.85:                              ## %exit141.i
                                        ##   in Loop: Header=BB0_83 Depth=1
	incq	%rcx
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %r14              ## imm = 0x310
	addq	$784, %rsi              ## imm = 0x310
	cmpq	$40, %rcx
	jne	LBB0_83
## %bb.86:                              ## %exit138.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r14
	leaq	-16(%r14), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	344(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%r14)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_35(%rip), %xmm1   ## xmm1 = [1,240]
	movups	%xmm1, -112(%rdi)
	movq	160(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r14)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_33(%rip), %xmm0   ## xmm0 = [1,40]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r14)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_36(%rip), %xmm0   ## xmm0 = [240,40]
	movups	%xmm0, -48(%rdi)
	movaps	1408(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r14)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$240, -16(%rdi)
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	movq	344(%rbx), %rsi         ## 8-byte Reload
	addq	$16, %rsp
	movq	352(%rbx), %rax         ## 8-byte Reload
	addq	$52, %rax
	addq	$52, %rsi
	xorl	%ecx, %ecx
	movaps	LCPI0_10(%rip), %xmm5   ## xmm5 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	LCPI0_11(%rip), %xmm6   ## xmm6 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movss	LCPI0_15(%rip), %xmm7   ## xmm7 = mem[0],zero,zero,zero
	movaps	%xmm7, %xmm8
	movss	LCPI0_16(%rip), %xmm7   ## xmm7 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_87:                                ## %cond148.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_88 Depth 2
	movq	$-784, %rdx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_88:                                ## %cond151.preheader.i
                                        ##   Parent Loop BB0_87 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	732(%rsi,%rdx), %xmm0
	movups	748(%rsi,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 748(%rax,%rdx)
	movups	%xmm2, 732(%rax,%rdx)
	movups	764(%rsi,%rdx), %xmm0
	movaps	%xmm0, %xmm1
	addps	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minps	%xmm2, %xmm1
	mulps	%xmm0, %xmm1
	divps	%xmm6, %xmm1
	movups	%xmm1, 764(%rax,%rdx)
	movss	780(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm8, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm7, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm7, %xmm1
	movss	%xmm1, 780(%rax,%rdx)
	movss	784(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm8, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm7, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm7, %xmm1
	movss	%xmm1, 784(%rax,%rdx)
	addq	$56, %rdx
	jne	LBB0_88
## %bb.89:                              ## %exit150.i
                                        ##   in Loop: Header=BB0_87 Depth=1
	incq	%rcx
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %rsi              ## imm = 0x310
	cmpq	$240, %rcx
	jne	LBB0_87
## %bb.90:                              ## %exit147.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r14
	leaq	-16(%r14), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	152(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%r14)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -112(%rdi)
	movq	352(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r14)
	movups	%xmm1, -64(%rdi)
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r14)
	movaps	LCPI0_31(%rip), %xmm0   ## xmm0 = [5,5]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_37(%rip), %xmm0   ## xmm0 = [240,1]
	movups	%xmm0, -48(%rdi)
	movaps	1424(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r14)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$240, -16(%rdi)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movups	%xmm0, -48(%r10)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -64(%r10)
	movups	%xmm0, -32(%r10)
	movq	$240, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	leaq	-16(%rdx), %rax
	movq	%rax, 32(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rax
	movq	%rax, 16(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	360(%rbx), %rcx         ## 8-byte Reload
	movq	%rcx, -16(%r10)
	movb	$6, -16(%rax)
	movaps	LCPI0_8(%rip), %xmm2    ## xmm2 = [1,1]
	movups	%xmm2, -48(%rdi)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -64(%rdi)
	movq	152(%rbx), %r9          ## 8-byte Reload
	movq	%r9, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_7(%rip), %xmm1    ## xmm1 = [4,4]
	movaps	%xmm1, -16(%rdx)
	movaps	LCPI0_30(%rip), %xmm1   ## xmm1 = [14,14]
	movups	%xmm1, -16(%rdi)
	movups	%xmm0, -32(%rdi)
	movaps	%xmm2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$2, %r9d
	movq	32(%rbx), %rdx          ## 8-byte Reload
	movq	16(%rbx), %rcx          ## 8-byte Reload
	pushq	%r14
	callq	_nnc_aten_adaptive_avg_pool2d
	addq	$16, %rsp
	movl	$960, %edx              ## imm = 0x3C0
	movq	704(%rbx), %r14         ## 8-byte Reload
	movq	%r14, %rdi
	movq	360(%rbx), %rsi         ## 8-byte Reload
	callq	_memcpy
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	368(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -32(%r10)
	movb	$6, -16(%rax)
	movq	%r14, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_38(%rip), %xmm0   ## xmm0 = [1,60]
	movups	%xmm0, -48(%r11)
	movq	712(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_39(%rip), %xmm0   ## xmm0 = [240,60]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	xorl	%r14d, %r14d
	movl	$3, %edi
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	addq	$16, %rsp
	movq	368(%rbx), %rax         ## 8-byte Reload
	movups	(%rax), %xmm1
	movups	16(%rax), %xmm2
	xorps	%xmm0, %xmm0
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movq	720(%rbx), %rdi         ## 8-byte Reload
	movups	%xmm1, 16(%rdi)
	movups	%xmm3, (%rdi)
	movups	32(%rax), %xmm1
	movups	48(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 48(%rdi)
	movups	%xmm3, 32(%rdi)
	movups	64(%rax), %xmm1
	movups	80(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 80(%rdi)
	movups	%xmm3, 64(%rdi)
	movups	96(%rax), %xmm1
	movups	112(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 112(%rdi)
	movups	%xmm3, 96(%rdi)
	movups	128(%rax), %xmm1
	movups	144(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 144(%rdi)
	movups	%xmm3, 128(%rdi)
	movups	160(%rax), %xmm1
	movups	176(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 176(%rdi)
	movups	%xmm3, 160(%rdi)
	movups	192(%rax), %xmm1
	movups	208(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 208(%rdi)
	movups	%xmm3, 192(%rdi)
	movups	224(%rax), %xmm1
	maxps	%xmm1, %xmm0
	movups	%xmm0, 224(%rdi)
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rax
	movq	%rax, 16(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	376(%rbx), %rcx         ## 8-byte Reload
	movq	%rcx, -32(%r10)
	movb	$6, -16(%rax)
	movq	%rdi, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_38(%rip), %xmm0   ## xmm0 = [1,60]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -48(%r11)
	movq	728(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_40(%rip), %xmm0   ## xmm0 = [60,240]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	movl	$3, %edi
	movq	16(%rbx), %rcx          ## 8-byte Reload
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	movq	376(%rbx), %rsi         ## 8-byte Reload
	movq	152(%rbx), %rdx         ## 8-byte Reload
	movss	LCPI0_16(%rip), %xmm11  ## xmm11 = mem[0],zero,zero,zero
	movss	LCPI0_15(%rip), %xmm10  ## xmm10 = mem[0],zero,zero,zero
	movaps	LCPI0_11(%rip), %xmm9   ## xmm9 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm0   ## xmm0 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	addq	$16, %rsp
	movq	384(%rbx), %rax         ## 8-byte Reload
	addq	$52, %rax
	addq	$52, %rdx
	xorps	%xmm8, %xmm8
	movss	LCPI0_17(%rip), %xmm12  ## xmm12 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_91:                                ## %cond163.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_92 Depth 2
	movss	(%rsi,%r14,4), %xmm2    ## xmm2 = mem[0],zero,zero,zero
	addss	%xmm10, %xmm2
	xorps	%xmm3, %xmm3
	maxss	%xmm2, %xmm3
	movaps	%xmm2, %xmm1
	divss	%xmm11, %xmm1
	cmpltss	%xmm8, %xmm2
	andnps	%xmm1, %xmm2
	movaps	%xmm11, %xmm1
	cmpltss	%xmm3, %xmm1
	movaps	%xmm1, %xmm3
	andnps	%xmm2, %xmm3
	andps	%xmm12, %xmm1
	orps	%xmm3, %xmm1
	movaps	%xmm1, %xmm2
	shufps	$0, %xmm1, %xmm2        ## xmm2 = xmm2[0,0],xmm1[0,0]
	movq	$-784, %rcx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_92:                                ## %cond166.preheader.i
                                        ##   Parent Loop BB0_91 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	732(%rdx,%rcx), %xmm3
	movups	748(%rdx,%rcx), %xmm4
	mulps	%xmm2, %xmm4
	mulps	%xmm2, %xmm3
	movaps	%xmm3, %xmm5
	addps	%xmm0, %xmm5
	movaps	%xmm4, %xmm6
	addps	%xmm0, %xmm6
	xorps	%xmm7, %xmm7
	maxps	%xmm6, %xmm7
	xorps	%xmm6, %xmm6
	maxps	%xmm5, %xmm6
	movaps	%xmm9, %xmm5
	minps	%xmm6, %xmm5
	movaps	%xmm9, %xmm6
	minps	%xmm7, %xmm6
	mulps	%xmm4, %xmm6
	mulps	%xmm3, %xmm5
	divps	%xmm9, %xmm5
	divps	%xmm9, %xmm6
	movups	%xmm6, 748(%rax,%rcx)
	movups	%xmm5, 732(%rax,%rcx)
	movups	764(%rdx,%rcx), %xmm3
	mulps	%xmm2, %xmm3
	movaps	%xmm3, %xmm4
	addps	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	movaps	%xmm9, %xmm4
	minps	%xmm5, %xmm4
	mulps	%xmm3, %xmm4
	divps	%xmm9, %xmm4
	movups	%xmm4, 764(%rax,%rcx)
	movss	780(%rdx,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm10, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm11, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm11, %xmm4
	movss	%xmm4, 780(%rax,%rcx)
	movss	784(%rdx,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm10, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm11, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm11, %xmm4
	movss	%xmm4, 784(%rax,%rcx)
	addq	$56, %rcx
	jne	LBB0_92
## %bb.93:                              ## %exit165.i
                                        ##   in Loop: Header=BB0_91 Depth=1
	incq	%r14
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %rdx              ## imm = 0x310
	cmpq	$240, %r14
	jne	LBB0_91
## %bb.94:                              ## %exit162.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, 16(%rbx)          ## 8-byte Spill
	movq	%r11, %rsp
	movq	736(%rbx), %r14         ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_33(%rip), %xmm1   ## xmm1 = [1,40]
	movups	%xmm1, -112(%rdi)
	movq	384(%rbx), %r11         ## 8-byte Reload
	movq	%r11, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_35(%rip), %xmm0   ## xmm0 = [1,240]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_41(%rip), %xmm0   ## xmm0 = [40,240]
	movups	%xmm0, -48(%rdi)
	movaps	1440(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$40, -16(%rdi)
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	16(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	392(%rbx), %rax         ## 8-byte Reload
	addq	$108, %rax
	addq	$108, %r14
	movq	160(%rbx), %rsi         ## 8-byte Reload
	addq	$108, %rsi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_95:                                ## %cond172.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_96 Depth 2
	movq	$-784, %rdx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_96:                                ## %cond175.preheader.i
                                        ##   Parent Loop BB0_95 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	676(%rsi,%rdx), %xmm0
	movups	692(%rsi,%rdx), %xmm1
	movups	676(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	692(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 692(%rax,%rdx)
	movups	%xmm2, 676(%rax,%rdx)
	movups	708(%rsi,%rdx), %xmm0
	movups	708(%r14,%rdx), %xmm1
	addps	%xmm0, %xmm1
	movups	%xmm1, 708(%rax,%rdx)
	movss	724(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	724(%r14,%rdx), %xmm0
	movss	%xmm0, 724(%rax,%rdx)
	movss	728(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	728(%r14,%rdx), %xmm0
	movss	%xmm0, 728(%rax,%rdx)
	movups	732(%rsi,%rdx), %xmm0
	movups	748(%rsi,%rdx), %xmm1
	movups	732(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	748(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 748(%rax,%rdx)
	movups	%xmm2, 732(%rax,%rdx)
	movups	764(%rsi,%rdx), %xmm0
	movups	764(%r14,%rdx), %xmm1
	addps	%xmm0, %xmm1
	movups	%xmm1, 764(%rax,%rdx)
	movss	780(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	780(%r14,%rdx), %xmm0
	movss	%xmm0, 780(%rax,%rdx)
	movss	784(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	784(%r14,%rdx), %xmm0
	movss	%xmm0, 784(%rax,%rdx)
	addq	$112, %rdx
	jne	LBB0_96
## %bb.97:                              ## %exit174.i
                                        ##   in Loop: Header=BB0_95 Depth=1
	incq	%rcx
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %r14              ## imm = 0x310
	addq	$784, %rsi              ## imm = 0x310
	cmpq	$40, %rcx
	jne	LBB0_95
## %bb.98:                              ## %exit171.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, 16(%rbx)          ## 8-byte Spill
	movq	%r10, %rsp
	movq	744(%rbx), %r14         ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_42(%rip), %xmm1   ## xmm1 = [1,120]
	movups	%xmm1, -112(%rdi)
	movq	392(%rbx), %r10         ## 8-byte Reload
	movq	%r10, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_33(%rip), %xmm0   ## xmm0 = [1,40]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_43(%rip), %xmm0   ## xmm0 = [120,40]
	movups	%xmm0, -48(%rdi)
	movaps	1456(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$120, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	16(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	400(%rbx), %rax         ## 8-byte Reload
	addq	$52, %rax
	addq	$52, %r14
	xorl	%ecx, %ecx
	movaps	LCPI0_10(%rip), %xmm5   ## xmm5 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	LCPI0_11(%rip), %xmm6   ## xmm6 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movss	LCPI0_15(%rip), %xmm7   ## xmm7 = mem[0],zero,zero,zero
	movaps	%xmm7, %xmm8
	movss	LCPI0_16(%rip), %xmm7   ## xmm7 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_99:                                ## %cond181.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_100 Depth 2
	movq	$-784, %rdx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_100:                               ## %cond184.preheader.i
                                        ##   Parent Loop BB0_99 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	732(%r14,%rdx), %xmm0
	movups	748(%r14,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 748(%rax,%rdx)
	movups	%xmm2, 732(%rax,%rdx)
	movups	764(%r14,%rdx), %xmm0
	movaps	%xmm0, %xmm1
	addps	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minps	%xmm2, %xmm1
	mulps	%xmm0, %xmm1
	divps	%xmm6, %xmm1
	movups	%xmm1, 764(%rax,%rdx)
	movss	780(%r14,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm8, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm7, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm7, %xmm1
	movss	%xmm1, 780(%rax,%rdx)
	movss	784(%r14,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm8, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm7, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm7, %xmm1
	movss	%xmm1, 784(%rax,%rdx)
	addq	$56, %rdx
	jne	LBB0_100
## %bb.101:                             ## %exit183.i
                                        ##   in Loop: Header=BB0_99 Depth=1
	incq	%rcx
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %r14              ## imm = 0x310
	cmpq	$120, %rcx
	jne	LBB0_99
## %bb.102:                             ## %exit180.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r14
	leaq	-16(%r14), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	168(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%r14)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_42(%rip), %xmm0   ## xmm0 = [1,120]
	movups	%xmm0, -112(%rdi)
	movq	400(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r14)
	movups	%xmm1, -64(%rdi)
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r14)
	movaps	LCPI0_31(%rip), %xmm0   ## xmm0 = [5,5]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_44(%rip), %xmm0   ## xmm0 = [120,1]
	movups	%xmm0, -48(%rdi)
	movaps	1472(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r14)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$120, -16(%rdi)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movups	%xmm0, -48(%r10)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -64(%r10)
	movups	%xmm0, -32(%r10)
	movq	$120, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	leaq	-16(%rdx), %rax
	movq	%rax, 32(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rax
	movq	%rax, 16(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	408(%rbx), %rcx         ## 8-byte Reload
	movq	%rcx, -16(%r10)
	movb	$6, -16(%rax)
	movaps	LCPI0_8(%rip), %xmm2    ## xmm2 = [1,1]
	movups	%xmm2, -48(%rdi)
	movaps	LCPI0_42(%rip), %xmm0   ## xmm0 = [1,120]
	movups	%xmm0, -64(%rdi)
	movq	168(%rbx), %r9          ## 8-byte Reload
	movq	%r9, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_7(%rip), %xmm1    ## xmm1 = [4,4]
	movaps	%xmm1, -16(%rdx)
	movaps	LCPI0_30(%rip), %xmm1   ## xmm1 = [14,14]
	movups	%xmm1, -16(%rdi)
	movups	%xmm0, -32(%rdi)
	movaps	%xmm2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$2, %r9d
	movq	32(%rbx), %rdx          ## 8-byte Reload
	movq	16(%rbx), %rcx          ## 8-byte Reload
	pushq	%r14
	callq	_nnc_aten_adaptive_avg_pool2d
	addq	$16, %rsp
	movl	$480, %edx              ## imm = 0x1E0
	movq	752(%rbx), %r14         ## 8-byte Reload
	movq	%r14, %rdi
	movq	408(%rbx), %rsi         ## 8-byte Reload
	callq	_memcpy
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	416(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -32(%r10)
	movb	$6, -16(%rax)
	movq	%r14, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_42(%rip), %xmm0   ## xmm0 = [1,120]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_45(%rip), %xmm0   ## xmm0 = [1,30]
	movups	%xmm0, -48(%r11)
	movq	760(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_46(%rip), %xmm0   ## xmm0 = [120,30]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	xorl	%r14d, %r14d
	movl	$3, %edi
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	addq	$16, %rsp
	movq	416(%rbx), %rax         ## 8-byte Reload
	movups	(%rax), %xmm0
	movups	16(%rax), %xmm1
	xorps	%xmm2, %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm0, %xmm3
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movq	768(%rbx), %rdi         ## 8-byte Reload
	movups	%xmm0, 16(%rdi)
	movups	%xmm3, (%rdi)
	movups	32(%rax), %xmm0
	movups	48(%rax), %xmm1
	xorps	%xmm3, %xmm3
	maxps	%xmm0, %xmm3
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 48(%rdi)
	movups	%xmm3, 32(%rdi)
	movups	64(%rax), %xmm0
	movups	80(%rax), %xmm1
	xorps	%xmm3, %xmm3
	maxps	%xmm0, %xmm3
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 80(%rdi)
	movups	%xmm3, 64(%rdi)
	movups	96(%rax), %xmm0
	maxps	%xmm0, %xmm2
	movups	%xmm2, 96(%rdi)
	xorps	%xmm0, %xmm0
	maxss	112(%rax), %xmm0
	movss	%xmm0, 112(%rdi)
	xorps	%xmm0, %xmm0
	maxss	116(%rax), %xmm0
	movss	%xmm0, 116(%rdi)
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rax
	movq	%rax, 16(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	424(%rbx), %rcx         ## 8-byte Reload
	movq	%rcx, -32(%r10)
	movb	$6, -16(%rax)
	movq	%rdi, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_45(%rip), %xmm0   ## xmm0 = [1,30]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_42(%rip), %xmm0   ## xmm0 = [1,120]
	movups	%xmm0, -48(%r11)
	movq	776(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_47(%rip), %xmm0   ## xmm0 = [30,120]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	movl	$3, %edi
	movq	16(%rbx), %rcx          ## 8-byte Reload
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	xorps	%xmm12, %xmm12
	movq	424(%rbx), %rsi         ## 8-byte Reload
	movq	168(%rbx), %rdx         ## 8-byte Reload
	movss	LCPI0_16(%rip), %xmm10  ## xmm10 = mem[0],zero,zero,zero
	movss	LCPI0_15(%rip), %xmm9   ## xmm9 = mem[0],zero,zero,zero
	movaps	LCPI0_11(%rip), %xmm8   ## xmm8 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm7   ## xmm7 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	addq	$16, %rsp
	movq	432(%rbx), %rax         ## 8-byte Reload
	addq	$52, %rax
	addq	$52, %rdx
	movss	LCPI0_17(%rip), %xmm11  ## xmm11 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_103:                               ## %cond196.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_104 Depth 2
	movss	(%rsi,%r14,4), %xmm1    ## xmm1 = mem[0],zero,zero,zero
	addss	%xmm9, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm1, %xmm0
	divss	%xmm10, %xmm0
	cmpltss	%xmm12, %xmm1
	andnps	%xmm0, %xmm1
	movaps	%xmm10, %xmm0
	cmpltss	%xmm2, %xmm0
	movaps	%xmm0, %xmm2
	andnps	%xmm1, %xmm2
	andps	%xmm11, %xmm0
	orps	%xmm2, %xmm0
	movaps	%xmm0, %xmm1
	shufps	$0, %xmm0, %xmm1        ## xmm1 = xmm1[0,0],xmm0[0,0]
	movq	$-784, %rcx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_104:                               ## %cond199.preheader.i
                                        ##   Parent Loop BB0_103 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	732(%rdx,%rcx), %xmm2
	movups	748(%rdx,%rcx), %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm1, %xmm2
	movaps	%xmm2, %xmm4
	addps	%xmm7, %xmm4
	movaps	%xmm3, %xmm5
	addps	%xmm7, %xmm5
	xorps	%xmm6, %xmm6
	maxps	%xmm5, %xmm6
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	movaps	%xmm8, %xmm4
	minps	%xmm5, %xmm4
	movaps	%xmm8, %xmm5
	minps	%xmm6, %xmm5
	mulps	%xmm3, %xmm5
	mulps	%xmm2, %xmm4
	divps	%xmm8, %xmm4
	divps	%xmm8, %xmm5
	movups	%xmm5, 748(%rax,%rcx)
	movups	%xmm4, 732(%rax,%rcx)
	movups	764(%rdx,%rcx), %xmm2
	mulps	%xmm1, %xmm2
	movaps	%xmm2, %xmm3
	addps	%xmm7, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	movaps	%xmm8, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm2, %xmm3
	divps	%xmm8, %xmm3
	movups	%xmm3, 764(%rax,%rcx)
	movss	780(%rdx,%rcx), %xmm2   ## xmm2 = mem[0],zero,zero,zero
	mulss	%xmm0, %xmm2
	movaps	%xmm2, %xmm3
	addss	%xmm9, %xmm3
	xorps	%xmm4, %xmm4
	maxss	%xmm3, %xmm4
	movaps	%xmm10, %xmm3
	minss	%xmm4, %xmm3
	mulss	%xmm2, %xmm3
	divss	%xmm10, %xmm3
	movss	%xmm3, 780(%rax,%rcx)
	movss	784(%rdx,%rcx), %xmm2   ## xmm2 = mem[0],zero,zero,zero
	mulss	%xmm0, %xmm2
	movaps	%xmm2, %xmm3
	addss	%xmm9, %xmm3
	xorps	%xmm4, %xmm4
	maxss	%xmm3, %xmm4
	movaps	%xmm10, %xmm3
	minss	%xmm4, %xmm3
	mulss	%xmm2, %xmm3
	divss	%xmm10, %xmm3
	movss	%xmm3, 784(%rax,%rcx)
	addq	$56, %rcx
	jne	LBB0_104
## %bb.105:                             ## %exit198.i
                                        ##   in Loop: Header=BB0_103 Depth=1
	incq	%r14
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %rdx              ## imm = 0x310
	cmpq	$120, %r14
	jne	LBB0_103
## %bb.106:                             ## %exit195.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r14
	leaq	-16(%r14), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, %rsp
	movq	184(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%r14)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_48(%rip), %xmm1   ## xmm1 = [1,48]
	movups	%xmm1, -112(%rdi)
	movq	432(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r14)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_42(%rip), %xmm0   ## xmm0 = [1,120]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r14)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_49(%rip), %xmm0   ## xmm0 = [48,120]
	movups	%xmm0, -48(%rdi)
	movaps	1488(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r14)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$48, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r10
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, 16(%rbx)          ## 8-byte Spill
	movq	%r11, %rsp
	movq	784(%rbx), %r14         ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_30(%rip), %xmm1   ## xmm1 = [14,14]
	movups	%xmm1, -96(%rdi)
	movaps	LCPI0_50(%rip), %xmm0   ## xmm0 = [1,144]
	movups	%xmm0, -112(%rdi)
	movq	184(%rbx), %r11         ## 8-byte Reload
	movq	%r11, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm1, -64(%rdi)
	movaps	LCPI0_48(%rip), %xmm0   ## xmm0 = [1,48]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm1    ## xmm1 = [1,1]
	movups	%xmm1, -32(%rdi)
	movaps	LCPI0_51(%rip), %xmm0   ## xmm0 = [144,48]
	movups	%xmm0, -48(%rdi)
	movaps	1504(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$144, -16(%rdi)
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	16(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	movss	LCPI0_16(%rip), %xmm8   ## xmm8 = mem[0],zero,zero,zero
	movss	LCPI0_15(%rip), %xmm7   ## xmm7 = mem[0],zero,zero,zero
	movaps	LCPI0_11(%rip), %xmm6   ## xmm6 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm5   ## xmm5 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	addq	$16, %rsp
	movq	440(%rbx), %rax         ## 8-byte Reload
	addq	$52, %rax
	addq	$52, %r14
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_107:                               ## %cond205.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_108 Depth 2
	movq	$-784, %rdx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_108:                               ## %cond208.preheader.i
                                        ##   Parent Loop BB0_107 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	732(%r14,%rdx), %xmm0
	movups	748(%r14,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 748(%rax,%rdx)
	movups	%xmm2, 732(%rax,%rdx)
	movups	764(%r14,%rdx), %xmm0
	movaps	%xmm0, %xmm1
	addps	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minps	%xmm2, %xmm1
	mulps	%xmm0, %xmm1
	divps	%xmm6, %xmm1
	movups	%xmm1, 764(%rax,%rdx)
	movss	780(%r14,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm7, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm8, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm8, %xmm1
	movss	%xmm1, 780(%rax,%rdx)
	movss	784(%r14,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm7, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm8, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm8, %xmm1
	movss	%xmm1, 784(%rax,%rdx)
	addq	$56, %rdx
	jne	LBB0_108
## %bb.109:                             ## %exit207.i
                                        ##   in Loop: Header=BB0_107 Depth=1
	incq	%rcx
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %r14              ## imm = 0x310
	cmpq	$144, %rcx
	jne	LBB0_107
## %bb.110:                             ## %exit204.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r14
	leaq	-16(%r14), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	176(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%r14)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_50(%rip), %xmm0   ## xmm0 = [1,144]
	movups	%xmm0, -112(%rdi)
	movq	440(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r14)
	movups	%xmm1, -64(%rdi)
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r14)
	movaps	LCPI0_31(%rip), %xmm0   ## xmm0 = [5,5]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_52(%rip), %xmm0   ## xmm0 = [144,1]
	movups	%xmm0, -48(%rdi)
	movaps	1520(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r14)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$144, -16(%rdi)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movups	%xmm0, -48(%r10)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -64(%r10)
	movups	%xmm0, -32(%r10)
	movq	$144, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	leaq	-16(%rdx), %rax
	movq	%rax, 32(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rax
	movq	%rax, 16(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	448(%rbx), %rcx         ## 8-byte Reload
	movq	%rcx, -16(%r10)
	movb	$6, -16(%rax)
	movaps	LCPI0_8(%rip), %xmm2    ## xmm2 = [1,1]
	movups	%xmm2, -48(%rdi)
	movaps	LCPI0_50(%rip), %xmm0   ## xmm0 = [1,144]
	movups	%xmm0, -64(%rdi)
	movq	176(%rbx), %r9          ## 8-byte Reload
	movq	%r9, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_7(%rip), %xmm1    ## xmm1 = [4,4]
	movaps	%xmm1, -16(%rdx)
	movaps	LCPI0_30(%rip), %xmm1   ## xmm1 = [14,14]
	movups	%xmm1, -16(%rdi)
	movups	%xmm0, -32(%rdi)
	movaps	%xmm2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$2, %r9d
	movq	32(%rbx), %rdx          ## 8-byte Reload
	movq	16(%rbx), %rcx          ## 8-byte Reload
	pushq	%r14
	callq	_nnc_aten_adaptive_avg_pool2d
	addq	$16, %rsp
	movl	$576, %edx              ## imm = 0x240
	movq	792(%rbx), %r14         ## 8-byte Reload
	movq	%r14, %rdi
	movq	448(%rbx), %rsi         ## 8-byte Reload
	callq	_memcpy
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	456(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -32(%r10)
	movb	$6, -16(%rax)
	movq	%r14, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_50(%rip), %xmm0   ## xmm0 = [1,144]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_53(%rip), %xmm0   ## xmm0 = [1,36]
	movups	%xmm0, -48(%r11)
	movq	808(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_54(%rip), %xmm0   ## xmm0 = [144,36]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	xorl	%r14d, %r14d
	movl	$3, %edi
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	addq	$16, %rsp
	movq	456(%rbx), %rax         ## 8-byte Reload
	movups	(%rax), %xmm1
	movups	16(%rax), %xmm2
	xorps	%xmm0, %xmm0
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movq	800(%rbx), %rdi         ## 8-byte Reload
	movups	%xmm1, 16(%rdi)
	movups	%xmm3, (%rdi)
	movups	32(%rax), %xmm1
	movups	48(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 48(%rdi)
	movups	%xmm3, 32(%rdi)
	movups	64(%rax), %xmm1
	movups	80(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 80(%rdi)
	movups	%xmm3, 64(%rdi)
	movups	96(%rax), %xmm1
	movups	112(%rax), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 112(%rdi)
	movups	%xmm3, 96(%rdi)
	movups	128(%rax), %xmm1
	maxps	%xmm1, %xmm0
	movups	%xmm0, 128(%rdi)
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rax
	movq	%rax, 16(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	472(%rbx), %rcx         ## 8-byte Reload
	movq	%rcx, -32(%r10)
	movb	$6, -16(%rax)
	movq	%rdi, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_53(%rip), %xmm0   ## xmm0 = [1,36]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_50(%rip), %xmm0   ## xmm0 = [1,144]
	movups	%xmm0, -48(%r11)
	movq	816(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_55(%rip), %xmm0   ## xmm0 = [36,144]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	movl	$3, %edi
	movq	16(%rbx), %rcx          ## 8-byte Reload
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	movss	LCPI0_16(%rip), %xmm11  ## xmm11 = mem[0],zero,zero,zero
	movss	LCPI0_15(%rip), %xmm10  ## xmm10 = mem[0],zero,zero,zero
	movq	176(%rbx), %rsi         ## 8-byte Reload
	movq	472(%rbx), %rdx         ## 8-byte Reload
	movaps	LCPI0_11(%rip), %xmm9   ## xmm9 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm0   ## xmm0 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	addq	$16, %rsp
	movq	464(%rbx), %rax         ## 8-byte Reload
	addq	$52, %rax
	addq	$52, %rsi
	xorps	%xmm8, %xmm8
	movss	LCPI0_17(%rip), %xmm12  ## xmm12 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_111:                               ## %cond220.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_112 Depth 2
	movss	(%rdx,%r14,4), %xmm2    ## xmm2 = mem[0],zero,zero,zero
	addss	%xmm10, %xmm2
	xorps	%xmm3, %xmm3
	maxss	%xmm2, %xmm3
	movaps	%xmm2, %xmm1
	divss	%xmm11, %xmm1
	cmpltss	%xmm8, %xmm2
	andnps	%xmm1, %xmm2
	movaps	%xmm11, %xmm1
	cmpltss	%xmm3, %xmm1
	movaps	%xmm1, %xmm3
	andnps	%xmm2, %xmm3
	andps	%xmm12, %xmm1
	orps	%xmm3, %xmm1
	movaps	%xmm1, %xmm2
	shufps	$0, %xmm1, %xmm2        ## xmm2 = xmm2[0,0],xmm1[0,0]
	movq	$-784, %rcx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_112:                               ## %cond223.preheader.i
                                        ##   Parent Loop BB0_111 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	732(%rsi,%rcx), %xmm3
	movups	748(%rsi,%rcx), %xmm4
	mulps	%xmm2, %xmm4
	mulps	%xmm2, %xmm3
	movaps	%xmm3, %xmm5
	addps	%xmm0, %xmm5
	movaps	%xmm4, %xmm6
	addps	%xmm0, %xmm6
	xorps	%xmm7, %xmm7
	maxps	%xmm6, %xmm7
	xorps	%xmm6, %xmm6
	maxps	%xmm5, %xmm6
	movaps	%xmm9, %xmm5
	minps	%xmm6, %xmm5
	movaps	%xmm9, %xmm6
	minps	%xmm7, %xmm6
	mulps	%xmm4, %xmm6
	mulps	%xmm3, %xmm5
	divps	%xmm9, %xmm5
	divps	%xmm9, %xmm6
	movups	%xmm6, 748(%rax,%rcx)
	movups	%xmm5, 732(%rax,%rcx)
	movups	764(%rsi,%rcx), %xmm3
	mulps	%xmm2, %xmm3
	movaps	%xmm3, %xmm4
	addps	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	movaps	%xmm9, %xmm4
	minps	%xmm5, %xmm4
	mulps	%xmm3, %xmm4
	divps	%xmm9, %xmm4
	movups	%xmm4, 764(%rax,%rcx)
	movss	780(%rsi,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm10, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm11, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm11, %xmm4
	movss	%xmm4, 780(%rax,%rcx)
	movss	784(%rsi,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm10, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm11, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm11, %xmm4
	movss	%xmm4, 784(%rax,%rcx)
	addq	$56, %rcx
	jne	LBB0_112
## %bb.113:                             ## %exit222.i
                                        ##   in Loop: Header=BB0_111 Depth=1
	incq	%r14
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %rsi              ## imm = 0x310
	cmpq	$144, %r14
	jne	LBB0_111
## %bb.114:                             ## %exit219.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, 16(%rbx)          ## 8-byte Spill
	movq	%r10, %rsp
	movq	824(%rbx), %r14         ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_48(%rip), %xmm1   ## xmm1 = [1,48]
	movups	%xmm1, -112(%rdi)
	movq	464(%rbx), %r10         ## 8-byte Reload
	movq	%r10, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_50(%rip), %xmm0   ## xmm0 = [1,144]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_56(%rip), %xmm0   ## xmm0 = [48,144]
	movups	%xmm0, -48(%rdi)
	movaps	1536(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$48, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	16(%rbx)                ## 8-byte Folded Reload
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	480(%rbx), %rax         ## 8-byte Reload
	addq	$108, %rax
	addq	$108, %r14
	movq	184(%rbx), %rsi         ## 8-byte Reload
	addq	$108, %rsi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_115:                               ## %cond229.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_116 Depth 2
	movq	$-784, %rdx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_116:                               ## %cond232.preheader.i
                                        ##   Parent Loop BB0_115 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	676(%rsi,%rdx), %xmm0
	movups	692(%rsi,%rdx), %xmm1
	movups	676(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	692(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 692(%rax,%rdx)
	movups	%xmm2, 676(%rax,%rdx)
	movups	708(%rsi,%rdx), %xmm0
	movups	708(%r14,%rdx), %xmm1
	addps	%xmm0, %xmm1
	movups	%xmm1, 708(%rax,%rdx)
	movss	724(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	724(%r14,%rdx), %xmm0
	movss	%xmm0, 724(%rax,%rdx)
	movss	728(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	728(%r14,%rdx), %xmm0
	movss	%xmm0, 728(%rax,%rdx)
	movups	732(%rsi,%rdx), %xmm0
	movups	748(%rsi,%rdx), %xmm1
	movups	732(%r14,%rdx), %xmm2
	addps	%xmm0, %xmm2
	movups	748(%r14,%rdx), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 748(%rax,%rdx)
	movups	%xmm2, 732(%rax,%rdx)
	movups	764(%rsi,%rdx), %xmm0
	movups	764(%r14,%rdx), %xmm1
	addps	%xmm0, %xmm1
	movups	%xmm1, 764(%rax,%rdx)
	movss	780(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	780(%r14,%rdx), %xmm0
	movss	%xmm0, 780(%rax,%rdx)
	movss	784(%rsi,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	addss	784(%r14,%rdx), %xmm0
	movss	%xmm0, 784(%rax,%rdx)
	addq	$112, %rdx
	jne	LBB0_116
## %bb.117:                             ## %exit231.i
                                        ##   in Loop: Header=BB0_115 Depth=1
	incq	%rcx
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %r14              ## imm = 0x310
	addq	$784, %rsi              ## imm = 0x310
	cmpq	$48, %rcx
	jne	LBB0_115
## %bb.118:                             ## %exit228.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, %rsp
	movq	%r13, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_57(%rip), %xmm1   ## xmm1 = [1,288]
	movups	%xmm1, -112(%rdi)
	movq	480(%rbx), %r14         ## 8-byte Reload
	movq	%r14, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_48(%rip), %xmm0   ## xmm0 = [1,48]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_58(%rip), %xmm0   ## xmm0 = [288,48]
	movups	%xmm0, -48(%rdi)
	movaps	1552(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$288, -16(%rdi)         ## imm = 0x120
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r10
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	840(%rbx), %r14         ## 8-byte Reload
	leaq	52(%r14), %rax
	addq	$52, %r13
	xorl	%ecx, %ecx
	movaps	LCPI0_10(%rip), %xmm5   ## xmm5 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	LCPI0_11(%rip), %xmm6   ## xmm6 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movss	LCPI0_15(%rip), %xmm7   ## xmm7 = mem[0],zero,zero,zero
	movaps	%xmm7, %xmm8
	movss	LCPI0_16(%rip), %xmm7   ## xmm7 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_119:                               ## %cond238.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_120 Depth 2
	movq	$-784, %rdx             ## imm = 0xFCF0
	.p2align	4, 0x90
LBB0_120:                               ## %cond241.preheader.i
                                        ##   Parent Loop BB0_119 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	732(%r13,%rdx), %xmm0
	movups	748(%r13,%rdx), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 748(%rax,%rdx)
	movups	%xmm2, 732(%rax,%rdx)
	movups	764(%r13,%rdx), %xmm0
	movaps	%xmm0, %xmm1
	addps	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minps	%xmm2, %xmm1
	mulps	%xmm0, %xmm1
	divps	%xmm6, %xmm1
	movups	%xmm1, 764(%rax,%rdx)
	movss	780(%r13,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm8, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm7, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm7, %xmm1
	movss	%xmm1, 780(%rax,%rdx)
	movss	784(%r13,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm8, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm7, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm7, %xmm1
	movss	%xmm1, 784(%rax,%rdx)
	addq	$56, %rdx
	jne	LBB0_120
## %bb.121:                             ## %exit240.i
                                        ##   in Loop: Header=BB0_119 Depth=1
	incq	%rcx
	addq	$784, %rax              ## imm = 0x310
	addq	$784, %r13              ## imm = 0x310
	cmpq	$288, %rcx              ## imm = 0x120
	jne	LBB0_119
## %bb.122:                             ## %exit237.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r13
	leaq	-16(%r13), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, %rsp
	movq	192(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -32(%r9)
	movb	$6, -16(%r13)
	movaps	LCPI0_59(%rip), %xmm0   ## xmm0 = [7,7]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_57(%rip), %xmm0   ## xmm0 = [1,288]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -112(%rdi)
	movq	%r14, -24(%r9)
	movb	$6, -15(%r13)
	movaps	LCPI0_30(%rip), %xmm0   ## xmm0 = [14,14]
	movups	%xmm0, -64(%rdi)
	movups	%xmm1, -80(%rdi)
	movb	$6, -14(%r13)
	movaps	LCPI0_31(%rip), %xmm0   ## xmm0 = [5,5]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_60(%rip), %xmm0   ## xmm0 = [288,1]
	movups	%xmm0, -48(%rdi)
	movaps	1568(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r13)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$288, -16(%rdi)         ## imm = 0x120
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movups	%xmm0, -48(%r11)
	movups	%xmm0, -64(%r11)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -32(%r11)
	movq	$288, -16(%r11)         ## imm = 0x120
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r10
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-16(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rax
	movq	%rax, 16(%rbx)          ## 8-byte Spill
	movq	%rax, %rsp
	movq	%rsp, %rcx
	leaq	-16(%rcx), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	488(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -16(%r10)
	movb	$6, -16(%rcx)
	movaps	LCPI0_8(%rip), %xmm2    ## xmm2 = [1,1]
	movups	%xmm2, -48(%rdi)
	movaps	LCPI0_57(%rip), %xmm0   ## xmm0 = [1,288]
	movups	%xmm0, -64(%rdi)
	movq	192(%rbx), %r13         ## 8-byte Reload
	movq	%r13, -8(%r10)
	movb	$6, -15(%rcx)
	movaps	LCPI0_7(%rip), %xmm1    ## xmm1 = [4,4]
	movaps	%xmm1, -16(%r9)
	movaps	LCPI0_59(%rip), %xmm1   ## xmm1 = [7,7]
	movups	%xmm1, -16(%rdi)
	movups	%xmm0, -32(%rdi)
	movaps	%xmm2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$2, %r9d
	movq	16(%rbx), %rcx          ## 8-byte Reload
	pushq	%r14
	callq	_nnc_aten_adaptive_avg_pool2d
	addq	$16, %rsp
	movl	$1152, %edx             ## imm = 0x480
	movq	848(%rbx), %r14         ## 8-byte Reload
	movq	%r14, %rdi
	movq	488(%rbx), %rsi         ## 8-byte Reload
	callq	_memcpy
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	872(%rbx), %r13         ## 8-byte Reload
	movq	%r13, -32(%r10)
	movb	$6, -16(%rax)
	movq	%r14, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_57(%rip), %xmm0   ## xmm0 = [1,288]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_18(%rip), %xmm0   ## xmm0 = [1,72]
	movups	%xmm0, -48(%r11)
	movq	864(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_61(%rip), %xmm0   ## xmm0 = [288,72]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	xorl	%r14d, %r14d
	movl	$3, %edi
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	addq	$16, %rsp
	movups	(%r13), %xmm1
	movups	16(%r13), %xmm2
	xorps	%xmm0, %xmm0
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movq	856(%rbx), %rdi         ## 8-byte Reload
	movups	%xmm1, 16(%rdi)
	movups	%xmm3, (%rdi)
	movups	32(%r13), %xmm1
	movups	48(%r13), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 48(%rdi)
	movups	%xmm3, 32(%rdi)
	movups	64(%r13), %xmm1
	movups	80(%r13), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 80(%rdi)
	movups	%xmm3, 64(%rdi)
	movups	96(%r13), %xmm1
	movups	112(%r13), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 112(%rdi)
	movups	%xmm3, 96(%rdi)
	movups	128(%r13), %xmm1
	movups	144(%r13), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 144(%rdi)
	movups	%xmm3, 128(%rdi)
	movups	160(%r13), %xmm1
	movups	176(%r13), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 176(%rdi)
	movups	%xmm3, 160(%rdi)
	movups	192(%r13), %xmm1
	movups	208(%r13), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 208(%rdi)
	movups	%xmm3, 192(%rdi)
	movups	224(%r13), %xmm1
	movups	240(%r13), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	movups	%xmm1, 240(%rdi)
	movups	%xmm3, 224(%rdi)
	movups	256(%r13), %xmm1
	movups	272(%r13), %xmm2
	xorps	%xmm3, %xmm3
	maxps	%xmm1, %xmm3
	maxps	%xmm2, %xmm0
	movups	%xmm0, 272(%rdi)
	movups	%xmm3, 256(%rdi)
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	880(%rbx), %r13         ## 8-byte Reload
	movq	%r13, -32(%r10)
	movb	$6, -16(%rax)
	movq	%rdi, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_18(%rip), %xmm0   ## xmm0 = [1,72]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_57(%rip), %xmm0   ## xmm0 = [1,288]
	movups	%xmm0, -48(%r11)
	movq	888(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_62(%rip), %xmm0   ## xmm0 = [72,288]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	movl	$3, %edi
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	movss	LCPI0_16(%rip), %xmm2   ## xmm2 = mem[0],zero,zero,zero
	movss	LCPI0_15(%rip), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movq	%r13, %rsi
	movq	192(%rbx), %rdx         ## 8-byte Reload
	movaps	LCPI0_11(%rip), %xmm7   ## xmm7 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm6   ## xmm6 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	%xmm6, %xmm9
	addq	$16, %rsp
	movq	496(%rbx), %rax         ## 8-byte Reload
	addq	$24, %rax
	addq	$24, %rdx
	xorps	%xmm8, %xmm8
	movss	LCPI0_17(%rip), %xmm10  ## xmm10 = mem[0],zero,zero,zero
	movq	976(%rbx), %r13         ## 8-byte Reload
	.p2align	4, 0x90
LBB0_123:                               ## %cond253.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_124 Depth 2
	movss	(%rsi,%r14,4), %xmm4    ## xmm4 = mem[0],zero,zero,zero
	addss	%xmm0, %xmm4
	xorps	%xmm3, %xmm3
	maxss	%xmm4, %xmm3
	movaps	%xmm4, %xmm1
	divss	%xmm2, %xmm1
	cmpltss	%xmm8, %xmm4
	andnps	%xmm1, %xmm4
	movaps	%xmm2, %xmm1
	cmpltss	%xmm3, %xmm1
	movaps	%xmm1, %xmm3
	andnps	%xmm4, %xmm3
	andps	%xmm10, %xmm1
	orps	%xmm3, %xmm1
	movaps	%xmm1, %xmm6
	shufps	$0, %xmm1, %xmm6        ## xmm6 = xmm6[0,0],xmm1[0,0]
	movq	$-196, %rcx
	.p2align	4, 0x90
LBB0_124:                               ## %cond256.preheader.i
                                        ##   Parent Loop BB0_123 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	172(%rdx,%rcx), %xmm3
	mulps	%xmm6, %xmm3
	movaps	%xmm3, %xmm4
	addps	%xmm9, %xmm4
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	movaps	%xmm7, %xmm4
	minps	%xmm5, %xmm4
	mulps	%xmm3, %xmm4
	divps	%xmm7, %xmm4
	movups	%xmm4, 172(%rax,%rcx)
	movss	188(%rdx,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm2, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm2, %xmm4
	movss	%xmm4, 188(%rax,%rcx)
	movss	192(%rdx,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm2, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm2, %xmm4
	movss	%xmm4, 192(%rax,%rcx)
	movss	196(%rdx,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm2, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm2, %xmm4
	movss	%xmm4, 196(%rax,%rcx)
	addq	$28, %rcx
	jne	LBB0_124
## %bb.125:                             ## %exit255.i
                                        ##   in Loop: Header=BB0_123 Depth=1
	incq	%r14
	addq	$196, %rax
	addq	$196, %rdx
	cmpq	$288, %r14              ## imm = 0x120
	jne	LBB0_123
## %bb.126:                             ## %exit252.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r14
	leaq	-16(%r14), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, %rsp
	movq	%r13, -32(%r9)
	movb	$6, -16(%r14)
	movaps	LCPI0_59(%rip), %xmm0   ## xmm0 = [7,7]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_28(%rip), %xmm0   ## xmm0 = [1,96]
	movups	%xmm0, -112(%rdi)
	movq	496(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r14)
	movups	%xmm1, -64(%rdi)
	movaps	LCPI0_57(%rip), %xmm0   ## xmm0 = [1,288]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r14)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_63(%rip), %xmm0   ## xmm0 = [96,288]
	movups	%xmm0, -48(%rdi)
	movaps	1584(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r14)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$96, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r10
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	%r12, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_59(%rip), %xmm1   ## xmm1 = [7,7]
	movups	%xmm1, -96(%rdi)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -112(%rdi)
	movq	%r13, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm1, -64(%rdi)
	movaps	LCPI0_28(%rip), %xmm0   ## xmm0 = [1,96]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm1    ## xmm1 = [1,1]
	movups	%xmm1, -32(%rdi)
	movaps	LCPI0_65(%rip), %xmm0   ## xmm0 = [576,96]
	movups	%xmm0, -48(%rdi)
	movaps	1600(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$576, -16(%rdi)         ## imm = 0x240
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	movss	LCPI0_16(%rip), %xmm6   ## xmm6 = mem[0],zero,zero,zero
	movss	LCPI0_15(%rip), %xmm5   ## xmm5 = mem[0],zero,zero,zero
	movaps	LCPI0_11(%rip), %xmm4   ## xmm4 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm3   ## xmm3 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	addq	$16, %rsp
	movq	904(%rbx), %r14         ## 8-byte Reload
	leaq	24(%r14), %rax
	addq	$24, %r12
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_127:                               ## %cond262.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_128 Depth 2
	movq	$-196, %rdx
	.p2align	4, 0x90
LBB0_128:                               ## %cond265.preheader.i
                                        ##   Parent Loop BB0_127 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	172(%r12,%rdx), %xmm0
	movaps	%xmm0, %xmm1
	addps	%xmm3, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm1, %xmm2
	movaps	%xmm4, %xmm1
	minps	%xmm2, %xmm1
	mulps	%xmm0, %xmm1
	divps	%xmm4, %xmm1
	movups	%xmm1, 172(%rax,%rdx)
	movss	188(%r12,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm6, %xmm1
	movss	%xmm1, 188(%rax,%rdx)
	movss	192(%r12,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm6, %xmm1
	movss	%xmm1, 192(%rax,%rdx)
	movss	196(%r12,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm6, %xmm1
	movss	%xmm1, 196(%rax,%rdx)
	addq	$28, %rdx
	jne	LBB0_128
## %bb.129:                             ## %exit264.i
                                        ##   in Loop: Header=BB0_127 Depth=1
	incq	%rcx
	addq	$196, %rax
	addq	$196, %r12
	cmpq	$576, %rcx              ## imm = 0x240
	jne	LBB0_127
## %bb.130:                             ## %exit261.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	%r15, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_59(%rip), %xmm0   ## xmm0 = [7,7]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -112(%rdi)
	movq	%r14, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm1, -64(%rdi)
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_31(%rip), %xmm0   ## xmm0 = [5,5]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_66(%rip), %xmm0   ## xmm0 = [576,1]
	movups	%xmm0, -48(%rdi)
	movaps	1616(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$576, -16(%rdi)         ## imm = 0x240
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movups	%xmm0, -48(%r10)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -64(%r10)
	movups	%xmm0, -32(%r10)
	movq	$576, -16(%r10)         ## imm = 0x240
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-16(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	912(%rbx), %r12         ## 8-byte Reload
	movq	%r12, -16(%r10)
	movb	$6, -16(%rax)
	movaps	LCPI0_8(%rip), %xmm2    ## xmm2 = [1,1]
	movups	%xmm2, -48(%rdi)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -64(%rdi)
	movq	%r15, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_7(%rip), %xmm1    ## xmm1 = [4,4]
	movaps	%xmm1, -16(%r9)
	movaps	LCPI0_59(%rip), %xmm1   ## xmm1 = [7,7]
	movups	%xmm1, -16(%rdi)
	movups	%xmm0, -32(%rdi)
	movaps	%xmm2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$2, %r9d
	pushq	%r14
	callq	_nnc_aten_adaptive_avg_pool2d
	addq	$16, %rsp
	movl	$2304, %edx             ## imm = 0x900
	movq	920(%rbx), %r14         ## 8-byte Reload
	movq	%r14, %rdi
	movq	%r12, %rsi
	callq	_memcpy
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	936(%rbx), %r12         ## 8-byte Reload
	movq	%r12, -32(%r10)
	movb	$6, -16(%rax)
	movq	%r14, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_50(%rip), %xmm0   ## xmm0 = [1,144]
	movups	%xmm0, -48(%r11)
	movq	928(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_67(%rip), %xmm0   ## xmm0 = [576,144]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	xorl	%r14d, %r14d
	movl	$3, %edi
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	addq	$16, %rsp
	movups	(%r12), %xmm1
	movups	16(%r12), %xmm2
	movups	32(%r12), %xmm3
	movups	48(%r12), %xmm4
	movups	64(%r12), %xmm5
	movups	80(%r12), %xmm6
	movups	96(%r12), %xmm9
	movups	112(%r12), %xmm0
	xorps	%xmm8, %xmm8
	xorps	%xmm7, %xmm7
	maxps	%xmm1, %xmm7
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm4, %xmm2
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm6, %xmm3
	xorps	%xmm6, %xmm6
	maxps	%xmm5, %xmm6
	xorps	%xmm5, %xmm5
	maxps	%xmm0, %xmm5
	xorps	%xmm0, %xmm0
	maxps	%xmm9, %xmm0
	movq	944(%rbx), %rdi         ## 8-byte Reload
	movups	%xmm1, 16(%rdi)
	movups	%xmm7, (%rdi)
	movups	%xmm4, 32(%rdi)
	movups	%xmm2, 48(%rdi)
	movups	%xmm6, 64(%rdi)
	movups	%xmm3, 80(%rdi)
	movups	%xmm0, 96(%rdi)
	movups	%xmm5, 112(%rdi)
	movups	128(%r12), %xmm0
	movups	144(%r12), %xmm1
	movups	160(%r12), %xmm2
	movups	176(%r12), %xmm3
	movups	192(%r12), %xmm4
	movups	208(%r12), %xmm5
	movups	224(%r12), %xmm9
	movups	240(%r12), %xmm7
	xorps	%xmm6, %xmm6
	maxps	%xmm0, %xmm6
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm3, %xmm1
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	xorps	%xmm2, %xmm2
	maxps	%xmm5, %xmm2
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	xorps	%xmm4, %xmm4
	maxps	%xmm7, %xmm4
	xorps	%xmm7, %xmm7
	maxps	%xmm9, %xmm7
	movups	%xmm0, 144(%rdi)
	movups	%xmm6, 128(%rdi)
	movups	%xmm3, 160(%rdi)
	movups	%xmm1, 176(%rdi)
	movups	%xmm5, 192(%rdi)
	movups	%xmm2, 208(%rdi)
	movups	%xmm7, 224(%rdi)
	movups	%xmm4, 240(%rdi)
	movups	256(%r12), %xmm0
	movups	272(%r12), %xmm1
	movups	288(%r12), %xmm2
	movups	304(%r12), %xmm3
	movups	320(%r12), %xmm4
	movups	336(%r12), %xmm5
	movups	352(%r12), %xmm9
	movups	368(%r12), %xmm7
	xorps	%xmm6, %xmm6
	maxps	%xmm0, %xmm6
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm3, %xmm1
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	xorps	%xmm2, %xmm2
	maxps	%xmm5, %xmm2
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	xorps	%xmm4, %xmm4
	maxps	%xmm7, %xmm4
	xorps	%xmm7, %xmm7
	maxps	%xmm9, %xmm7
	movups	%xmm0, 272(%rdi)
	movups	%xmm6, 256(%rdi)
	movups	%xmm3, 288(%rdi)
	movups	%xmm1, 304(%rdi)
	movups	%xmm5, 320(%rdi)
	movups	%xmm2, 336(%rdi)
	movups	%xmm7, 352(%rdi)
	movups	%xmm4, 368(%rdi)
	movups	384(%r12), %xmm0
	movups	400(%r12), %xmm1
	movups	416(%r12), %xmm2
	movups	432(%r12), %xmm3
	movups	448(%r12), %xmm4
	movups	464(%r12), %xmm5
	movups	480(%r12), %xmm9
	movups	496(%r12), %xmm7
	xorps	%xmm6, %xmm6
	maxps	%xmm0, %xmm6
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm3, %xmm1
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	xorps	%xmm2, %xmm2
	maxps	%xmm5, %xmm2
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	xorps	%xmm4, %xmm4
	maxps	%xmm7, %xmm4
	xorps	%xmm7, %xmm7
	maxps	%xmm9, %xmm7
	movups	%xmm0, 400(%rdi)
	movups	%xmm6, 384(%rdi)
	movups	%xmm3, 416(%rdi)
	movups	%xmm1, 432(%rdi)
	movups	%xmm5, 448(%rdi)
	movups	%xmm2, 464(%rdi)
	movups	%xmm7, 480(%rdi)
	movups	%xmm4, 496(%rdi)
	movups	512(%r12), %xmm0
	movups	528(%r12), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 528(%rdi)
	movups	%xmm2, 512(%rdi)
	movups	544(%r12), %xmm0
	movups	560(%r12), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	maxps	%xmm1, %xmm8
	movups	%xmm8, 560(%rdi)
	movups	%xmm2, 544(%rdi)
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	952(%rbx), %r12         ## 8-byte Reload
	movq	%r12, -32(%r10)
	movb	$6, -16(%rax)
	movq	%rdi, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_50(%rip), %xmm0   ## xmm0 = [1,144]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -48(%r11)
	movq	968(%rbx), %rdi         ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_68(%rip), %xmm0   ## xmm0 = [144,576]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	movl	$3, %edi
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	movss	LCPI0_16(%rip), %xmm2   ## xmm2 = mem[0],zero,zero,zero
	movss	LCPI0_15(%rip), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movq	%r12, %rdx
	movaps	LCPI0_11(%rip), %xmm7   ## xmm7 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm6   ## xmm6 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	%xmm6, %xmm9
	addq	$16, %rsp
	movq	504(%rbx), %rax         ## 8-byte Reload
	addq	$24, %rax
	addq	$24, %r15
	xorps	%xmm8, %xmm8
	movq	1080(%rbx), %r12        ## 8-byte Reload
	movss	LCPI0_17(%rip), %xmm10  ## xmm10 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_131:                               ## %cond277.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_132 Depth 2
	movss	(%rdx,%r14,4), %xmm4    ## xmm4 = mem[0],zero,zero,zero
	addss	%xmm0, %xmm4
	xorps	%xmm3, %xmm3
	maxss	%xmm4, %xmm3
	movaps	%xmm4, %xmm1
	divss	%xmm2, %xmm1
	cmpltss	%xmm8, %xmm4
	andnps	%xmm1, %xmm4
	movaps	%xmm2, %xmm1
	cmpltss	%xmm3, %xmm1
	movaps	%xmm1, %xmm3
	andnps	%xmm4, %xmm3
	andps	%xmm10, %xmm1
	orps	%xmm3, %xmm1
	movaps	%xmm1, %xmm6
	shufps	$0, %xmm1, %xmm6        ## xmm6 = xmm6[0,0],xmm1[0,0]
	movq	$-196, %rcx
	.p2align	4, 0x90
LBB0_132:                               ## %cond280.preheader.i
                                        ##   Parent Loop BB0_131 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	172(%r15,%rcx), %xmm3
	mulps	%xmm6, %xmm3
	movaps	%xmm3, %xmm4
	addps	%xmm9, %xmm4
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	movaps	%xmm7, %xmm4
	minps	%xmm5, %xmm4
	mulps	%xmm3, %xmm4
	divps	%xmm7, %xmm4
	movups	%xmm4, 172(%rax,%rcx)
	movss	188(%r15,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm2, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm2, %xmm4
	movss	%xmm4, 188(%rax,%rcx)
	movss	192(%r15,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm2, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm2, %xmm4
	movss	%xmm4, 192(%rax,%rcx)
	movss	196(%r15,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm2, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm2, %xmm4
	movss	%xmm4, 196(%rax,%rcx)
	addq	$28, %rcx
	jne	LBB0_132
## %bb.133:                             ## %exit279.i
                                        ##   in Loop: Header=BB0_131 Depth=1
	incq	%r14
	addq	$196, %rax
	addq	$196, %r15
	cmpq	$576, %r14              ## imm = 0x240
	jne	LBB0_131
## %bb.134:                             ## %exit276.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, %rsp
	movq	984(%rbx), %r14         ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_59(%rip), %xmm0   ## xmm0 = [7,7]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_28(%rip), %xmm0   ## xmm0 = [1,96]
	movups	%xmm0, -112(%rdi)
	movq	504(%rbx), %r15         ## 8-byte Reload
	movq	%r15, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm1, -64(%rdi)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_69(%rip), %xmm0   ## xmm0 = [96,576]
	movups	%xmm0, -48(%rdi)
	movaps	1632(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$96, -16(%rdi)
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r10
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	$-18816, %rax           ## imm = 0xB680
	movq	520(%rbx), %rcx         ## 8-byte Reload
	.p2align	4, 0x90
LBB0_135:                               ## %cond286.preheader.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	18816(%r13,%rax), %xmm0
	movups	18832(%r13,%rax), %xmm1
	movups	18816(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18832(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18832(%rcx,%rax)
	movups	%xmm2, 18816(%rcx,%rax)
	movups	18848(%r13,%rax), %xmm0
	movups	18864(%r13,%rax), %xmm1
	movups	18848(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18864(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18864(%rcx,%rax)
	movups	%xmm2, 18848(%rcx,%rax)
	movups	18880(%r13,%rax), %xmm0
	movups	18896(%r13,%rax), %xmm1
	movups	18880(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18896(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18896(%rcx,%rax)
	movups	%xmm2, 18880(%rcx,%rax)
	movups	18912(%r13,%rax), %xmm0
	movups	18928(%r13,%rax), %xmm1
	movups	18912(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18928(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18928(%rcx,%rax)
	movups	%xmm2, 18912(%rcx,%rax)
	movups	18944(%r13,%rax), %xmm0
	movups	18960(%r13,%rax), %xmm1
	movups	18944(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18960(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18960(%rcx,%rax)
	movups	%xmm2, 18944(%rcx,%rax)
	movups	18976(%r13,%rax), %xmm0
	movups	18992(%r13,%rax), %xmm1
	movups	18976(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18992(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18992(%rcx,%rax)
	movups	%xmm2, 18976(%rcx,%rax)
	movss	19008(%r13,%rax), %xmm0 ## xmm0 = mem[0],zero,zero,zero
	addss	19008(%r14,%rax), %xmm0
	movss	%xmm0, 19008(%rcx,%rax)
	addq	$196, %rax
	jne	LBB0_135
## %bb.136:                             ## %exit285.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	movq	%rcx, %r14
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	992(%rbx), %r15         ## 8-byte Reload
	movq	%r15, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_59(%rip), %xmm0   ## xmm0 = [7,7]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_64(%rip), %xmm1   ## xmm1 = [1,576]
	movups	%xmm1, -112(%rdi)
	movq	%r14, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_28(%rip), %xmm0   ## xmm0 = [1,96]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_65(%rip), %xmm0   ## xmm0 = [576,96]
	movups	%xmm0, -48(%rdi)
	movaps	1648(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$576, -16(%rdi)         ## imm = 0x240
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	1000(%rbx), %r14        ## 8-byte Reload
	leaq	24(%r14), %rax
	addq	$24, %r15
	xorl	%ecx, %ecx
	movaps	LCPI0_10(%rip), %xmm3   ## xmm3 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	LCPI0_11(%rip), %xmm4   ## xmm4 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movss	LCPI0_15(%rip), %xmm5   ## xmm5 = mem[0],zero,zero,zero
	movss	LCPI0_16(%rip), %xmm6   ## xmm6 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_137:                               ## %cond295.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_138 Depth 2
	movq	$-196, %rdx
	.p2align	4, 0x90
LBB0_138:                               ## %cond298.preheader.i
                                        ##   Parent Loop BB0_137 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	172(%r15,%rdx), %xmm0
	movaps	%xmm0, %xmm1
	addps	%xmm3, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm1, %xmm2
	movaps	%xmm4, %xmm1
	minps	%xmm2, %xmm1
	mulps	%xmm0, %xmm1
	divps	%xmm4, %xmm1
	movups	%xmm1, 172(%rax,%rdx)
	movss	188(%r15,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm6, %xmm1
	movss	%xmm1, 188(%rax,%rdx)
	movss	192(%r15,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm6, %xmm1
	movss	%xmm1, 192(%rax,%rdx)
	movss	196(%r15,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm6, %xmm1
	movss	%xmm1, 196(%rax,%rdx)
	addq	$28, %rdx
	jne	LBB0_138
## %bb.139:                             ## %exit297.i
                                        ##   in Loop: Header=BB0_137 Depth=1
	incq	%rcx
	addq	$196, %rax
	addq	$196, %r15
	cmpq	$576, %rcx              ## imm = 0x240
	jne	LBB0_137
## %bb.140:                             ## %exit294.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	1064(%rbx), %r13        ## 8-byte Reload
	movq	%r13, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_59(%rip), %xmm0   ## xmm0 = [7,7]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -112(%rdi)
	movq	%r14, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm1, -64(%rdi)
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_31(%rip), %xmm0   ## xmm0 = [5,5]
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_66(%rip), %xmm0   ## xmm0 = [576,1]
	movups	%xmm0, -48(%rdi)
	movaps	1664(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$576, -16(%rdi)         ## imm = 0x240
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movups	%xmm0, -48(%r10)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -64(%r10)
	movups	%xmm0, -32(%r10)
	movq	$576, -16(%r10)         ## imm = 0x240
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-16(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	1016(%rbx), %r15        ## 8-byte Reload
	movq	%r15, -16(%r10)
	movb	$6, -16(%rax)
	movaps	LCPI0_8(%rip), %xmm2    ## xmm2 = [1,1]
	movups	%xmm2, -48(%rdi)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -64(%rdi)
	movq	%r13, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_7(%rip), %xmm1    ## xmm1 = [4,4]
	movaps	%xmm1, -16(%r9)
	movaps	LCPI0_59(%rip), %xmm1   ## xmm1 = [7,7]
	movups	%xmm1, -16(%rdi)
	movups	%xmm0, -32(%rdi)
	movaps	%xmm2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$2, %r9d
	pushq	%r14
	callq	_nnc_aten_adaptive_avg_pool2d
	addq	$16, %rsp
	movl	$2304, %edx             ## imm = 0x900
	movq	1008(%rbx), %r14        ## 8-byte Reload
	movq	%r14, %rdi
	movq	%r15, %rsi
	callq	_memcpy
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	1024(%rbx), %r15        ## 8-byte Reload
	movq	%r15, -32(%r10)
	movb	$6, -16(%rax)
	movq	%r14, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_50(%rip), %xmm0   ## xmm0 = [1,144]
	movups	%xmm0, -48(%r11)
	movq	1032(%rbx), %rdi        ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_67(%rip), %xmm0   ## xmm0 = [576,144]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	xorl	%r14d, %r14d
	movl	$3, %edi
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	addq	$16, %rsp
	movups	(%r15), %xmm1
	movups	16(%r15), %xmm2
	movups	32(%r15), %xmm3
	movups	48(%r15), %xmm4
	movups	64(%r15), %xmm5
	movups	80(%r15), %xmm6
	movups	96(%r15), %xmm9
	movups	112(%r15), %xmm0
	xorps	%xmm8, %xmm8
	xorps	%xmm7, %xmm7
	maxps	%xmm1, %xmm7
	xorps	%xmm1, %xmm1
	maxps	%xmm2, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm4, %xmm2
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm6, %xmm3
	xorps	%xmm6, %xmm6
	maxps	%xmm5, %xmm6
	xorps	%xmm5, %xmm5
	maxps	%xmm0, %xmm5
	xorps	%xmm0, %xmm0
	maxps	%xmm9, %xmm0
	movq	1040(%rbx), %rdi        ## 8-byte Reload
	movups	%xmm1, 16(%rdi)
	movups	%xmm7, (%rdi)
	movups	%xmm4, 32(%rdi)
	movups	%xmm2, 48(%rdi)
	movups	%xmm6, 64(%rdi)
	movups	%xmm3, 80(%rdi)
	movups	%xmm0, 96(%rdi)
	movups	%xmm5, 112(%rdi)
	movups	128(%r15), %xmm0
	movups	144(%r15), %xmm1
	movups	160(%r15), %xmm2
	movups	176(%r15), %xmm3
	movups	192(%r15), %xmm4
	movups	208(%r15), %xmm5
	movups	224(%r15), %xmm9
	movups	240(%r15), %xmm7
	xorps	%xmm6, %xmm6
	maxps	%xmm0, %xmm6
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm3, %xmm1
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	xorps	%xmm2, %xmm2
	maxps	%xmm5, %xmm2
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	xorps	%xmm4, %xmm4
	maxps	%xmm7, %xmm4
	xorps	%xmm7, %xmm7
	maxps	%xmm9, %xmm7
	movups	%xmm0, 144(%rdi)
	movups	%xmm6, 128(%rdi)
	movups	%xmm3, 160(%rdi)
	movups	%xmm1, 176(%rdi)
	movups	%xmm5, 192(%rdi)
	movups	%xmm2, 208(%rdi)
	movups	%xmm7, 224(%rdi)
	movups	%xmm4, 240(%rdi)
	movups	256(%r15), %xmm0
	movups	272(%r15), %xmm1
	movups	288(%r15), %xmm2
	movups	304(%r15), %xmm3
	movups	320(%r15), %xmm4
	movups	336(%r15), %xmm5
	movups	352(%r15), %xmm9
	movups	368(%r15), %xmm7
	xorps	%xmm6, %xmm6
	maxps	%xmm0, %xmm6
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm3, %xmm1
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	xorps	%xmm2, %xmm2
	maxps	%xmm5, %xmm2
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	xorps	%xmm4, %xmm4
	maxps	%xmm7, %xmm4
	xorps	%xmm7, %xmm7
	maxps	%xmm9, %xmm7
	movups	%xmm0, 272(%rdi)
	movups	%xmm6, 256(%rdi)
	movups	%xmm3, 288(%rdi)
	movups	%xmm1, 304(%rdi)
	movups	%xmm5, 320(%rdi)
	movups	%xmm2, 336(%rdi)
	movups	%xmm7, 352(%rdi)
	movups	%xmm4, 368(%rdi)
	movups	384(%r15), %xmm0
	movups	400(%r15), %xmm1
	movups	416(%r15), %xmm2
	movups	432(%r15), %xmm3
	movups	448(%r15), %xmm4
	movups	464(%r15), %xmm5
	movups	480(%r15), %xmm9
	movups	496(%r15), %xmm7
	xorps	%xmm6, %xmm6
	maxps	%xmm0, %xmm6
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	xorps	%xmm1, %xmm1
	maxps	%xmm3, %xmm1
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	xorps	%xmm2, %xmm2
	maxps	%xmm5, %xmm2
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	xorps	%xmm4, %xmm4
	maxps	%xmm7, %xmm4
	xorps	%xmm7, %xmm7
	maxps	%xmm9, %xmm7
	movups	%xmm0, 400(%rdi)
	movups	%xmm6, 384(%rdi)
	movups	%xmm3, 416(%rdi)
	movups	%xmm1, 432(%rdi)
	movups	%xmm5, 448(%rdi)
	movups	%xmm2, 464(%rdi)
	movups	%xmm7, 480(%rdi)
	movups	%xmm4, 496(%rdi)
	movups	512(%r15), %xmm0
	movups	528(%r15), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	xorps	%xmm0, %xmm0
	maxps	%xmm1, %xmm0
	movups	%xmm0, 528(%rdi)
	movups	%xmm2, 512(%rdi)
	movups	544(%r15), %xmm0
	movups	560(%r15), %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm0, %xmm2
	maxps	%xmm1, %xmm8
	movups	%xmm8, 560(%rdi)
	movups	%xmm2, 544(%rdi)
	movq	%rsp, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r11
	leaq	-48(%r11), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	1048(%rbx), %r15        ## 8-byte Reload
	movq	%r15, -32(%r10)
	movb	$6, -16(%rax)
	movq	%rdi, -24(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movaps	%xmm0, -32(%r9)
	movaps	LCPI0_50(%rip), %xmm0   ## xmm0 = [1,144]
	movups	%xmm0, -32(%r11)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -48(%r11)
	movq	1056(%rbx), %rdi        ## 8-byte Reload
	movq	%rdi, -16(%r10)
	movb	$6, -14(%rax)
	movq	$2, -16(%r9)
	movaps	LCPI0_68(%rip), %xmm0   ## xmm0 = [144,576]
	movups	%xmm0, -16(%r11)
	subq	$8, %rsp
	movl	$3, %edi
	xorl	%r9d, %r9d
	leaq	8(%rbx), %rax
	pushq	%rax
	callq	_nnc_aten_matmul
	movss	LCPI0_16(%rip), %xmm2   ## xmm2 = mem[0],zero,zero,zero
	movss	LCPI0_15(%rip), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movq	%r15, %rdx
	movaps	LCPI0_11(%rip), %xmm7   ## xmm7 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm6   ## xmm6 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	%xmm6, %xmm9
	addq	$16, %rsp
	movq	512(%rbx), %rax         ## 8-byte Reload
	addq	$24, %rax
	addq	$24, %r13
	xorps	%xmm8, %xmm8
	movq	1120(%rbx), %r15        ## 8-byte Reload
	movss	LCPI0_17(%rip), %xmm10  ## xmm10 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_141:                               ## %cond310.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_142 Depth 2
	movss	(%rdx,%r14,4), %xmm4    ## xmm4 = mem[0],zero,zero,zero
	addss	%xmm0, %xmm4
	xorps	%xmm3, %xmm3
	maxss	%xmm4, %xmm3
	movaps	%xmm4, %xmm1
	divss	%xmm2, %xmm1
	cmpltss	%xmm8, %xmm4
	andnps	%xmm1, %xmm4
	movaps	%xmm2, %xmm1
	cmpltss	%xmm3, %xmm1
	movaps	%xmm1, %xmm3
	andnps	%xmm4, %xmm3
	andps	%xmm10, %xmm1
	orps	%xmm3, %xmm1
	movaps	%xmm1, %xmm6
	shufps	$0, %xmm1, %xmm6        ## xmm6 = xmm6[0,0],xmm1[0,0]
	movq	$-196, %rcx
	.p2align	4, 0x90
LBB0_142:                               ## %cond313.preheader.i
                                        ##   Parent Loop BB0_141 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	172(%r13,%rcx), %xmm3
	mulps	%xmm6, %xmm3
	movaps	%xmm3, %xmm4
	addps	%xmm9, %xmm4
	xorps	%xmm5, %xmm5
	maxps	%xmm4, %xmm5
	movaps	%xmm7, %xmm4
	minps	%xmm5, %xmm4
	mulps	%xmm3, %xmm4
	divps	%xmm7, %xmm4
	movups	%xmm4, 172(%rax,%rcx)
	movss	188(%r13,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm2, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm2, %xmm4
	movss	%xmm4, 188(%rax,%rcx)
	movss	192(%r13,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm2, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm2, %xmm4
	movss	%xmm4, 192(%rax,%rcx)
	movss	196(%r13,%rcx), %xmm3   ## xmm3 = mem[0],zero,zero,zero
	mulss	%xmm1, %xmm3
	movaps	%xmm3, %xmm4
	addss	%xmm0, %xmm4
	xorps	%xmm5, %xmm5
	maxss	%xmm4, %xmm5
	movaps	%xmm2, %xmm4
	minss	%xmm5, %xmm4
	mulss	%xmm3, %xmm4
	divss	%xmm2, %xmm4
	movss	%xmm4, 196(%rax,%rcx)
	addq	$28, %rcx
	jne	LBB0_142
## %bb.143:                             ## %exit312.i
                                        ##   in Loop: Header=BB0_141 Depth=1
	incq	%r14
	addq	$196, %rax
	addq	$196, %r13
	cmpq	$576, %r14              ## imm = 0x240
	jne	LBB0_141
## %bb.144:                             ## %exit309.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %r13
	leaq	-16(%r13), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	1072(%rbx), %r14        ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%r13)
	movaps	LCPI0_59(%rip), %xmm0   ## xmm0 = [7,7]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_28(%rip), %xmm0   ## xmm0 = [1,96]
	movups	%xmm0, -112(%rdi)
	movq	512(%rbx), %rax         ## 8-byte Reload
	movq	%rax, -24(%r9)
	movb	$6, -15(%r13)
	movups	%xmm1, -64(%rdi)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%r13)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_69(%rip), %xmm0   ## xmm0 = [96,576]
	movups	%xmm0, -48(%rdi)
	movaps	1680(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%r13)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$96, -16(%rdi)
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	$-18816, %rax           ## imm = 0xB680
	movq	520(%rbx), %rcx         ## 8-byte Reload
	.p2align	4, 0x90
LBB0_145:                               ## %cond319.preheader.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	18816(%rcx,%rax), %xmm0
	movups	18832(%rcx,%rax), %xmm1
	movups	18816(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18832(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18832(%r12,%rax)
	movups	%xmm2, 18816(%r12,%rax)
	movups	18848(%rcx,%rax), %xmm0
	movups	18864(%rcx,%rax), %xmm1
	movups	18848(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18864(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18864(%r12,%rax)
	movups	%xmm2, 18848(%r12,%rax)
	movups	18880(%rcx,%rax), %xmm0
	movups	18896(%rcx,%rax), %xmm1
	movups	18880(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18896(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18896(%r12,%rax)
	movups	%xmm2, 18880(%r12,%rax)
	movups	18912(%rcx,%rax), %xmm0
	movups	18928(%rcx,%rax), %xmm1
	movups	18912(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18928(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18928(%r12,%rax)
	movups	%xmm2, 18912(%r12,%rax)
	movups	18944(%rcx,%rax), %xmm0
	movups	18960(%rcx,%rax), %xmm1
	movups	18944(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18960(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18960(%r12,%rax)
	movups	%xmm2, 18944(%r12,%rax)
	movups	18976(%rcx,%rax), %xmm0
	movups	18992(%rcx,%rax), %xmm1
	movups	18976(%r14,%rax), %xmm2
	addps	%xmm0, %xmm2
	movups	18992(%r14,%rax), %xmm0
	addps	%xmm1, %xmm0
	movups	%xmm0, 18992(%r12,%rax)
	movups	%xmm2, 18976(%r12,%rax)
	movss	19008(%rcx,%rax), %xmm0 ## xmm0 = mem[0],zero,zero,zero
	addss	19008(%r14,%rax), %xmm0
	movss	%xmm0, 19008(%r12,%rax)
	addq	$196, %rax
	jne	LBB0_145
## %bb.146:                             ## %exit318.i
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-64(%r10), %r11
	movq	%r11, %rsp
	movq	1088(%rbx), %r14        ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_59(%rip), %xmm0   ## xmm0 = [7,7]
	movups	%xmm0, -96(%rdi)
	movaps	LCPI0_64(%rip), %xmm1   ## xmm1 = [1,576]
	movups	%xmm1, -112(%rdi)
	movq	%r12, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_28(%rip), %xmm0   ## xmm0 = [1,96]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -32(%rdi)
	movaps	LCPI0_65(%rip), %xmm0   ## xmm0 = [576,96]
	movups	%xmm0, -48(%rdi)
	movaps	1696(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$576, -16(%rdi)         ## imm = 0x240
	movaps	%xmm1, -64(%r10)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r10)
	movaps	%xmm1, -32(%r10)
	movq	$1, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r11
	callq	_nnc_aten_conv2d
	addq	$16, %rsp
	movq	1096(%rbx), %r13        ## 8-byte Reload
	leaq	24(%r13), %rax
	addq	$24, %r14
	xorl	%ecx, %ecx
	movaps	LCPI0_10(%rip), %xmm3   ## xmm3 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	movaps	LCPI0_11(%rip), %xmm4   ## xmm4 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movss	LCPI0_15(%rip), %xmm5   ## xmm5 = mem[0],zero,zero,zero
	movss	LCPI0_16(%rip), %xmm6   ## xmm6 = mem[0],zero,zero,zero
	.p2align	4, 0x90
LBB0_147:                               ## %cond328.preheader.i
                                        ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_148 Depth 2
	movq	$-196, %rdx
	.p2align	4, 0x90
LBB0_148:                               ## %cond331.preheader.i
                                        ##   Parent Loop BB0_147 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movups	172(%r14,%rdx), %xmm0
	movaps	%xmm0, %xmm1
	addps	%xmm3, %xmm1
	xorps	%xmm2, %xmm2
	maxps	%xmm1, %xmm2
	movaps	%xmm4, %xmm1
	minps	%xmm2, %xmm1
	mulps	%xmm0, %xmm1
	divps	%xmm4, %xmm1
	movups	%xmm1, 172(%rax,%rdx)
	movss	188(%r14,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm6, %xmm1
	movss	%xmm1, 188(%rax,%rdx)
	movss	192(%r14,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm6, %xmm1
	movss	%xmm1, 192(%rax,%rdx)
	movss	196(%r14,%rdx), %xmm0   ## xmm0 = mem[0],zero,zero,zero
	movaps	%xmm0, %xmm1
	addss	%xmm5, %xmm1
	xorps	%xmm2, %xmm2
	maxss	%xmm1, %xmm2
	movaps	%xmm6, %xmm1
	minss	%xmm2, %xmm1
	mulss	%xmm0, %xmm1
	divss	%xmm6, %xmm1
	movss	%xmm1, 196(%rax,%rdx)
	addq	$28, %rdx
	jne	LBB0_148
## %bb.149:                             ## %exit330.i
                                        ##   in Loop: Header=BB0_147 Depth=1
	incq	%rcx
	addq	$196, %rax
	addq	$196, %r14
	cmpq	$576, %rcx              ## imm = 0x240
	jne	LBB0_147
## %bb.150:                             ## %exit327.i
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-16(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	1112(%rbx), %r12        ## 8-byte Reload
	movq	%r12, -16(%r10)
	movb	$6, -16(%rax)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, %xmm2
	movups	%xmm0, -48(%rdi)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movaps	%xmm0, %xmm1
	movups	%xmm0, -64(%rdi)
	movq	%r13, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movaps	%xmm0, -16(%r9)
	movaps	LCPI0_59(%rip), %xmm0   ## xmm0 = [7,7]
	movups	%xmm0, -16(%rdi)
	movups	%xmm1, -32(%rdi)
	movaps	%xmm2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$2, %r9d
	pushq	%r14
	callq	_nnc_aten_adaptive_avg_pool2d
	addq	$16, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-112(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-64(%r11), %r10
	movq	%r10, %rsp
	movq	1104(%rbx), %r14        ## 8-byte Reload
	movq	%r14, -32(%r9)
	movb	$6, -16(%rax)
	movaps	LCPI0_8(%rip), %xmm1    ## xmm1 = [1,1]
	movups	%xmm1, -96(%rdi)
	movaps	LCPI0_70(%rip), %xmm0   ## xmm0 = [1,1280]
	movups	%xmm0, -112(%rdi)
	movq	%r12, -24(%r9)
	movb	$6, -15(%rax)
	movups	%xmm1, -64(%rdi)
	movaps	LCPI0_64(%rip), %xmm0   ## xmm0 = [1,576]
	movups	%xmm0, -80(%rdi)
	movb	$6, -14(%rax)
	movups	%xmm1, -32(%rdi)
	movaps	LCPI0_71(%rip), %xmm0   ## xmm0 = [1280,576]
	movups	%xmm0, -48(%rdi)
	movaps	1712(%rbx), %xmm0       ## 16-byte Reload
	movups	%xmm0, -16(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_6(%rip), %xmm0    ## xmm0 = [4,1]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_7(%rip), %xmm0    ## xmm0 = [4,4]
	movups	%xmm0, (%rdx)
	movq	$1280, -16(%rdi)        ## imm = 0x500
	movaps	%xmm1, -64(%r11)
	xorps	%xmm0, %xmm0
	movaps	%xmm0, -48(%r11)
	movaps	%xmm1, -32(%r11)
	movq	$1, -16(%r11)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$7, %r9d
	pushq	%r10
	callq	_nnc_aten_conv2d
	movaps	LCPI0_11(%rip), %xmm6   ## xmm6 = [6.0E+0,6.0E+0,6.0E+0,6.0E+0]
	movaps	LCPI0_10(%rip), %xmm5   ## xmm5 = [3.0E+0,3.0E+0,3.0E+0,3.0E+0]
	addq	$16, %rsp
	movq	$-5120, %rax            ## imm = 0xEC00
	.p2align	4, 0x90
LBB0_151:                               ## %vector.body1150.i
                                        ## =>This Inner Loop Header: Depth=1
	movups	5120(%r14,%rax), %xmm0
	movups	5136(%r14,%rax), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 5136(%r15,%rax)
	movups	%xmm2, 5120(%r15,%rax)
	movups	5152(%r14,%rax), %xmm0
	movups	5168(%r14,%rax), %xmm1
	movaps	%xmm0, %xmm2
	addps	%xmm5, %xmm2
	movaps	%xmm1, %xmm3
	addps	%xmm5, %xmm3
	xorps	%xmm4, %xmm4
	maxps	%xmm3, %xmm4
	xorps	%xmm3, %xmm3
	maxps	%xmm2, %xmm3
	movaps	%xmm6, %xmm2
	minps	%xmm3, %xmm2
	movaps	%xmm6, %xmm3
	minps	%xmm4, %xmm3
	mulps	%xmm1, %xmm3
	mulps	%xmm0, %xmm2
	divps	%xmm6, %xmm2
	divps	%xmm6, %xmm3
	movups	%xmm3, 5168(%r15,%rax)
	movups	%xmm2, 5152(%r15,%rax)
	addq	$64, %rax
	jne	LBB0_151
## %bb.152:                             ## %pytorch.exit
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-16(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-64(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	1128(%rbx), %r12        ## 8-byte Reload
	movq	%r12, -16(%r10)
	movb	$6, -16(%rax)
	movq	%r15, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_72(%rip), %xmm0   ## xmm0 = [3,4]
	movaps	%xmm0, -16(%r9)
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movups	%xmm0, -48(%rdi)
	movaps	LCPI0_70(%rip), %xmm0   ## xmm0 = [1,1280]
	movups	%xmm0, -64(%rdi)
	movaps	LCPI0_73(%rip), %xmm0   ## xmm0 = [1280,1]
	movups	%xmm0, -32(%rdi)
	movq	$1, -16(%rdi)
	movq	$3, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$1, %r9d
	pushq	%r14
	callq	_nnc_aten_mean
	addq	$16, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %r9
	leaq	-16(%r9), %rdx
	movq	%rdx, %rsp
	movq	%rsp, %rdi
	leaq	-48(%rdi), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r11
	leaq	-16(%r11), %r14
	movq	%r14, %rsp
	movq	1136(%rbx), %r15        ## 8-byte Reload
	movq	%r15, -16(%r10)
	movb	$6, -16(%rax)
	movq	%r12, -8(%r10)
	movb	$6, -15(%rax)
	movaps	LCPI0_74(%rip), %xmm0   ## xmm0 = [2,3]
	movaps	%xmm0, -16(%r9)
	movaps	LCPI0_70(%rip), %xmm0   ## xmm0 = [1,1280]
	movups	%xmm0, -32(%rdi)
	movups	%xmm0, -48(%rdi)
	movq	$1, -16(%rdi)
	movq	$2, -16(%r11)
	subq	$8, %rsp
	movl	$2, %edi
	movl	$1, %r9d
	pushq	%r14
	callq	_nnc_aten_mean
	addq	$16, %rsp
	movq	%rsp, %r9
	leaq	-32(%r9), %rsi
	movq	%rsi, %rsp
	movq	%rsp, %rdx
	addq	$-32, %rdx
	andq	$-32, %rdx
	movq	%rdx, %rsp
	movq	%rsp, %r14
	leaq	-64(%r14), %rcx
	movq	%rcx, %rsp
	movq	%rsp, %rax
	leaq	-16(%rax), %r8
	movq	%r8, %rsp
	movq	%rsp, %r10
	leaq	-16(%r10), %r11
	movq	%r11, %rsp
	movq	1152(%rbx), %rdi        ## 8-byte Reload
	movq	%rdi, -32(%r9)
	movb	$6, -16(%rax)
	movq	1144(%rbx), %rdi        ## 8-byte Reload
	movq	%rdi, -24(%r9)
	movb	$6, -15(%rax)
	movq	%r15, -16(%r9)
	movb	$6, -14(%rax)
	movaps	LCPI0_75(%rip), %xmm0   ## xmm0 = [1000,1]
	movups	%xmm0, -48(%r14)
	movaps	LCPI0_76(%rip), %xmm0   ## xmm0 = [1,1000]
	movups	%xmm0, -64(%r14)
	movq	1160(%rbx), %rdi        ## 8-byte Reload
	movq	%rdi, -8(%r9)
	movb	$6, -13(%rax)
	movaps	LCPI0_9(%rip), %xmm0    ## xmm0 = [2,2]
	movups	%xmm0, 16(%rdx)
	movaps	LCPI0_77(%rip), %xmm0   ## xmm0 = [2,1]
	movups	%xmm0, (%rdx)
	movaps	LCPI0_78(%rip), %xmm0   ## xmm0 = [1280,1280]
	movups	%xmm0, -32(%r14)
	movq	$1000, -16(%r14)        ## imm = 0x3E8
	movaps	LCPI0_8(%rip), %xmm0    ## xmm0 = [1,1]
	movaps	%xmm0, -16(%r10)
	subq	$8, %rsp
	movl	$4, %edi
	movl	$2, %r9d
	pushq	%r11
	callq	_nnc_aten_addmm
	addq	$16, %rsp
	xorl	%eax, %eax
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
                                        ## -- End function

.subsections_via_symbols
